# Comparing `tmp/RegScale_CLI-4.25.0-py3-none-any.whl.zip` & `tmp/RegScale_CLI-4.25.1-py3-none-any.whl.zip`

## zipinfo {}

```diff
@@ -1,85 +1,94 @@
-Zip file size: 201432 bytes, number of entries: 83
--rw-r--r--  2.0 unx    14547 b- defN 23-Apr-12 13:37 regscale.py
--rw-r--r--  2.0 unx       47 b- defN 23-Apr-12 13:37 app/__init__.py
--rw-r--r--  2.0 unx       73 b- defN 23-Apr-12 13:37 app/_version.py
--rw-r--r--  2.0 unx    14197 b- defN 23-Apr-12 13:37 app/api.py
--rw-r--r--  2.0 unx    13397 b- defN 23-Apr-12 13:37 app/application.py
--rw-r--r--  2.0 unx     1287 b- defN 23-Apr-12 13:37 app/logz.py
--rw-r--r--  2.0 unx        0 b- defN 23-Apr-12 13:37 app/commercial/__init__.py
--rw-r--r--  2.0 unx    16359 b- defN 23-Apr-12 13:37 app/commercial/ad.py
--rw-r--r--  2.0 unx    45796 b- defN 23-Apr-12 13:37 app/commercial/defender.py
--rw-r--r--  2.0 unx     8007 b- defN 23-Apr-12 13:37 app/commercial/jira.py
--rw-r--r--  2.0 unx    27240 b- defN 23-Apr-12 13:37 app/commercial/okta.py
--rw-r--r--  2.0 unx    27892 b- defN 23-Apr-12 13:37 app/commercial/qualys.py
--rw-r--r--  2.0 unx    11689 b- defN 23-Apr-12 13:37 app/commercial/servicenow.py
--rw-r--r--  2.0 unx    22634 b- defN 23-Apr-12 13:37 app/commercial/tenable.py
--rw-r--r--  2.0 unx    56457 b- defN 23-Apr-12 13:37 app/commercial/wiz.py
--rw-r--r--  2.0 unx        0 b- defN 23-Apr-12 13:37 app/internal/__init__.py
--rw-r--r--  2.0 unx    26998 b- defN 23-Apr-12 13:37 app/internal/admin_actions.py
--rw-r--r--  2.0 unx    31042 b- defN 23-Apr-12 13:37 app/internal/assessments_editor.py
--rw-r--r--  2.0 unx    16114 b- defN 23-Apr-12 13:37 app/internal/comparison.py
--rw-r--r--  2.0 unx    15277 b- defN 23-Apr-12 13:37 app/internal/control_editor.py
--rw-r--r--  2.0 unx     5912 b- defN 23-Apr-12 13:37 app/internal/encrypt.py
--rw-r--r--  2.0 unx    39915 b- defN 23-Apr-12 13:37 app/internal/evidence.py
--rw-r--r--  2.0 unx     2325 b- defN 23-Apr-12 13:37 app/internal/healthcheck.py
--rw-r--r--  2.0 unx     6397 b- defN 23-Apr-12 13:37 app/internal/login.py
--rw-r--r--  2.0 unx     9419 b- defN 23-Apr-12 13:37 app/internal/migrations.py
--rw-r--r--  2.0 unx        0 b- defN 23-Apr-12 13:37 app/public/__init__.py
--rw-r--r--  2.0 unx    18601 b- defN 23-Apr-12 13:37 app/public/cisa.py
--rw-r--r--  2.0 unx    10193 b- defN 23-Apr-12 13:37 app/public/emass.py
--rw-r--r--  2.0 unx    63918 b- defN 23-Apr-12 13:37 app/public/fedramp.py
--rw-r--r--  2.0 unx     7946 b- defN 23-Apr-12 13:37 app/public/nist_catalog.py
--rw-r--r--  2.0 unx    71111 b- defN 23-Apr-12 13:37 app/public/oscal.py
--rw-r--r--  2.0 unx     6081 b- defN 23-Apr-12 13:37 app/public/otx.py
--rw-r--r--  2.0 unx        0 b- defN 23-Apr-12 13:37 app/utils/__init__.py
--rw-r--r--  2.0 unx    19408 b- defN 23-Apr-12 13:37 app/utils/app_utils.py
--rw-r--r--  2.0 unx    10375 b- defN 23-Apr-12 13:37 app/utils/regscale_utils.py
--rw-r--r--  2.0 unx     1591 b- defN 23-Apr-12 13:37 app/utils/threadhandler.py
--rw-r--r--  2.0 unx        0 b- defN 23-Apr-12 13:37 exceptions/__init__.py
--rw-r--r--  2.0 unx      195 b- defN 23-Apr-12 13:37 exceptions/license_exception.py
--rw-r--r--  2.0 unx       79 b- defN 23-Apr-12 13:37 models/__init__.py
--rw-r--r--  2.0 unx        0 b- defN 23-Apr-12 13:37 models/app_models/__init__.py
--rw-r--r--  2.0 unx     3997 b- defN 23-Apr-12 13:37 models/app_models/click.py
--rw-r--r--  2.0 unx    13863 b- defN 23-Apr-12 13:37 models/app_models/control_editor.py
--rw-r--r--  2.0 unx      889 b- defN 23-Apr-12 13:37 models/app_models/pipeline.py
--rw-r--r--  2.0 unx        0 b- defN 23-Apr-12 13:37 models/integration_models/__init__.py
--rw-r--r--  2.0 unx     7858 b- defN 23-Apr-12 13:37 models/integration_models/azure_alerts.py
--rw-r--r--  2.0 unx      872 b- defN 23-Apr-12 13:37 models/integration_models/recommendations.py
--rw-r--r--  2.0 unx     8319 b- defN 23-Apr-12 13:37 models/integration_models/tenable.py
--rw-r--r--  2.0 unx     1833 b- defN 23-Apr-12 13:37 models/integration_models/wiz.py
--rw-r--r--  2.0 unx        0 b- defN 23-Apr-12 13:37 models/regscale_models/__init__.py
--rw-r--r--  2.0 unx     6688 b- defN 23-Apr-12 13:37 models/regscale_models/assessment.py
--rw-r--r--  2.0 unx     5433 b- defN 23-Apr-12 13:37 models/regscale_models/asset.py
--rw-r--r--  2.0 unx     1237 b- defN 23-Apr-12 13:37 models/regscale_models/components.py
--rw-r--r--  2.0 unx     7805 b- defN 23-Apr-12 13:37 models/regscale_models/control_implementation.py
--rw-r--r--  2.0 unx     2850 b- defN 23-Apr-12 13:37 models/regscale_models/interconnects.py
--rw-r--r--  2.0 unx     4175 b- defN 23-Apr-12 13:37 models/regscale_models/issue.py
--rw-r--r--  2.0 unx     4878 b- defN 23-Apr-12 13:37 models/regscale_models/modules.py
--rw-r--r--  2.0 unx     2353 b- defN 23-Apr-12 13:37 models/regscale_models/ports_protocols.py
--rw-r--r--  2.0 unx     2415 b- defN 23-Apr-12 13:37 models/regscale_models/requirements.py
--rw-r--r--  2.0 unx     5886 b- defN 23-Apr-12 13:37 models/regscale_models/securityplans.py
--rw-r--r--  2.0 unx     1398 b- defN 23-Apr-12 13:37 models/regscale_models/threat.py
--rw-r--r--  2.0 unx     2242 b- defN 23-Apr-12 13:37 models/regscale_models/user.py
--rw-r--r--  2.0 unx        0 b- defN 23-Apr-12 13:37 tests/__init__.py
--rw-r--r--  2.0 unx     1818 b- defN 23-Apr-12 13:37 tests/conftest.py
--rw-r--r--  2.0 unx     1334 b- defN 23-Apr-12 13:37 tests/test_app_utils.py
--rw-r--r--  2.0 unx     1930 b- defN 23-Apr-12 13:37 tests/test_assessments_editor.py
--rw-r--r--  2.0 unx     1687 b- defN 23-Apr-12 13:37 tests/test_cisa.py
--rw-r--r--  2.0 unx     1747 b- defN 23-Apr-12 13:37 tests/test_control_editor.py
--rw-r--r--  2.0 unx     1425 b- defN 23-Apr-12 13:37 tests/test_dependabot.py
--rw-r--r--  2.0 unx     2811 b- defN 23-Apr-12 13:37 tests/test_emass.py
--rw-r--r--  2.0 unx    14035 b- defN 23-Apr-12 13:37 tests/test_evidence.py
--rw-r--r--  2.0 unx     1186 b- defN 23-Apr-12 13:37 tests/test_login.py
--rw-r--r--  2.0 unx     1416 b- defN 23-Apr-12 13:37 tests/test_npm_audit.py
--rw-r--r--  2.0 unx     9248 b- defN 23-Apr-12 13:37 tests/test_oscal.py
--rw-r--r--  2.0 unx      866 b- defN 23-Apr-12 13:37 tests/test_snow.py
--rw-r--r--  2.0 unx     1245 b- defN 23-Apr-12 13:37 tests/test_sonarcloud.py
--rw-r--r--  2.0 unx     1666 b- defN 23-Apr-12 13:37 tests/test_tenable.py
--rw-r--r--  2.0 unx     1254 b- defN 23-Apr-12 13:37 tests/test_update_regscale_config.py
--rw-r--r--  2.0 unx     1076 b- defN 23-Apr-12 13:37 RegScale_CLI-4.25.0.dist-info/LICENSE
--rw-r--r--  2.0 unx     6330 b- defN 23-Apr-12 13:37 RegScale_CLI-4.25.0.dist-info/METADATA
--rw-r--r--  2.0 unx       92 b- defN 23-Apr-12 13:37 RegScale_CLI-4.25.0.dist-info/WHEEL
--rw-r--r--  2.0 unx       43 b- defN 23-Apr-12 13:37 RegScale_CLI-4.25.0.dist-info/entry_points.txt
--rw-r--r--  2.0 unx       37 b- defN 23-Apr-12 13:37 RegScale_CLI-4.25.0.dist-info/top_level.txt
-?rw-rw-r--  2.0 unx     6896 b- defN 23-Apr-12 13:37 RegScale_CLI-4.25.0.dist-info/RECORD
-83 files, 765652 bytes uncompressed, 190624 bytes compressed:  75.1%
+Zip file size: 230112 bytes, number of entries: 92
+-rw-r--r--  2.0 unx    14485 b- defN 23-Apr-14 00:04 regscale.py
+-rw-r--r--  2.0 unx       47 b- defN 23-Apr-14 00:04 app/__init__.py
+-rw-r--r--  2.0 unx       73 b- defN 23-Apr-14 00:04 app/_version.py
+-rw-r--r--  2.0 unx    14497 b- defN 23-Apr-14 00:04 app/api.py
+-rw-r--r--  2.0 unx    13397 b- defN 23-Apr-14 00:04 app/application.py
+-rw-r--r--  2.0 unx     1287 b- defN 23-Apr-14 00:04 app/logz.py
+-rw-r--r--  2.0 unx        0 b- defN 23-Apr-14 00:04 app/commercial/__init__.py
+-rw-r--r--  2.0 unx    16359 b- defN 23-Apr-14 00:04 app/commercial/ad.py
+-rw-r--r--  2.0 unx    45796 b- defN 23-Apr-14 00:04 app/commercial/defender.py
+-rw-r--r--  2.0 unx     8007 b- defN 23-Apr-14 00:04 app/commercial/jira.py
+-rw-r--r--  2.0 unx    27240 b- defN 23-Apr-14 00:04 app/commercial/okta.py
+-rw-r--r--  2.0 unx    29595 b- defN 23-Apr-14 00:04 app/commercial/qualys.py
+-rw-r--r--  2.0 unx    11689 b- defN 23-Apr-14 00:04 app/commercial/servicenow.py
+-rw-r--r--  2.0 unx    62786 b- defN 23-Apr-14 00:04 app/commercial/stig.py
+-rw-r--r--  2.0 unx    22634 b- defN 23-Apr-14 00:04 app/commercial/tenable.py
+-rw-r--r--  2.0 unx    56457 b- defN 23-Apr-14 00:04 app/commercial/wiz.py
+-rw-r--r--  2.0 unx        0 b- defN 23-Apr-14 00:04 app/internal/__init__.py
+-rw-r--r--  2.0 unx    26998 b- defN 23-Apr-14 00:04 app/internal/admin_actions.py
+-rw-r--r--  2.0 unx    31042 b- defN 23-Apr-14 00:04 app/internal/assessments_editor.py
+-rw-r--r--  2.0 unx    16114 b- defN 23-Apr-14 00:04 app/internal/comparison.py
+-rw-r--r--  2.0 unx    15277 b- defN 23-Apr-14 00:04 app/internal/control_editor.py
+-rw-r--r--  2.0 unx     5912 b- defN 23-Apr-14 00:04 app/internal/encrypt.py
+-rw-r--r--  2.0 unx    40122 b- defN 23-Apr-14 00:04 app/internal/evidence.py
+-rw-r--r--  2.0 unx     2325 b- defN 23-Apr-14 00:04 app/internal/healthcheck.py
+-rw-r--r--  2.0 unx     6397 b- defN 23-Apr-14 00:04 app/internal/login.py
+-rw-r--r--  2.0 unx     9419 b- defN 23-Apr-14 00:04 app/internal/migrations.py
+-rw-r--r--  2.0 unx        0 b- defN 23-Apr-14 00:04 app/public/__init__.py
+-rw-r--r--  2.0 unx    18601 b- defN 23-Apr-14 00:04 app/public/cisa.py
+-rw-r--r--  2.0 unx    11186 b- defN 23-Apr-14 00:04 app/public/emass.py
+-rw-r--r--  2.0 unx    63918 b- defN 23-Apr-14 00:04 app/public/fedramp.py
+-rw-r--r--  2.0 unx     7946 b- defN 23-Apr-14 00:04 app/public/nist_catalog.py
+-rw-r--r--  2.0 unx    71111 b- defN 23-Apr-14 00:04 app/public/oscal.py
+-rw-r--r--  2.0 unx     6081 b- defN 23-Apr-14 00:04 app/public/otx.py
+-rw-r--r--  2.0 unx        0 b- defN 23-Apr-14 00:04 app/utils/__init__.py
+-rw-r--r--  2.0 unx    21592 b- defN 23-Apr-14 00:04 app/utils/app_utils.py
+-rw-r--r--  2.0 unx    10409 b- defN 23-Apr-14 00:04 app/utils/regscale_utils.py
+-rw-r--r--  2.0 unx     1591 b- defN 23-Apr-14 00:04 app/utils/threadhandler.py
+-rw-r--r--  2.0 unx        0 b- defN 23-Apr-14 00:04 exceptions/__init__.py
+-rw-r--r--  2.0 unx      195 b- defN 23-Apr-14 00:04 exceptions/license_exception.py
+-rw-r--r--  2.0 unx       79 b- defN 23-Apr-14 00:04 models/__init__.py
+-rw-r--r--  2.0 unx        0 b- defN 23-Apr-14 00:04 models/app_models/__init__.py
+-rw-r--r--  2.0 unx     3997 b- defN 23-Apr-14 00:04 models/app_models/click.py
+-rw-r--r--  2.0 unx    13863 b- defN 23-Apr-14 00:04 models/app_models/control_editor.py
+-rw-r--r--  2.0 unx      889 b- defN 23-Apr-14 00:04 models/app_models/pipeline.py
+-rw-r--r--  2.0 unx        0 b- defN 23-Apr-14 00:04 models/integration_models/__init__.py
+-rw-r--r--  2.0 unx     7858 b- defN 23-Apr-14 00:04 models/integration_models/azure_alerts.py
+-rw-r--r--  2.0 unx      872 b- defN 23-Apr-14 00:04 models/integration_models/recommendations.py
+-rw-r--r--  2.0 unx     8319 b- defN 23-Apr-14 00:04 models/integration_models/tenable.py
+-rw-r--r--  2.0 unx     1833 b- defN 23-Apr-14 00:04 models/integration_models/wiz.py
+-rw-r--r--  2.0 unx        0 b- defN 23-Apr-14 00:04 models/regscale_models/__init__.py
+-rw-r--r--  2.0 unx     6688 b- defN 23-Apr-14 00:04 models/regscale_models/assessment.py
+-rw-r--r--  2.0 unx     7726 b- defN 23-Apr-14 00:04 models/regscale_models/asset.py
+-rw-r--r--  2.0 unx     4327 b- defN 23-Apr-14 00:04 models/regscale_models/checklist.py
+-rw-r--r--  2.0 unx     1877 b- defN 23-Apr-14 00:04 models/regscale_models/components.py
+-rw-r--r--  2.0 unx    10070 b- defN 23-Apr-14 00:04 models/regscale_models/control_implementation.py
+-rw-r--r--  2.0 unx     1441 b- defN 23-Apr-14 00:04 models/regscale_models/control_objective.py
+-rw-r--r--  2.0 unx     6294 b- defN 23-Apr-14 00:04 models/regscale_models/implementation_objective.py
+-rw-r--r--  2.0 unx     2981 b- defN 23-Apr-14 00:04 models/regscale_models/implementation_option.py
+-rw-r--r--  2.0 unx     2850 b- defN 23-Apr-14 00:04 models/regscale_models/interconnects.py
+-rw-r--r--  2.0 unx     4175 b- defN 23-Apr-14 00:04 models/regscale_models/issue.py
+-rw-r--r--  2.0 unx     4878 b- defN 23-Apr-14 00:04 models/regscale_models/modules.py
+-rw-r--r--  2.0 unx      232 b- defN 23-Apr-14 00:04 models/regscale_models/objective.py
+-rw-r--r--  2.0 unx     2353 b- defN 23-Apr-14 00:04 models/regscale_models/ports_protocols.py
+-rw-r--r--  2.0 unx     2415 b- defN 23-Apr-14 00:04 models/regscale_models/requirements.py
+-rw-r--r--  2.0 unx     5886 b- defN 23-Apr-14 00:04 models/regscale_models/securityplans.py
+-rw-r--r--  2.0 unx    25813 b- defN 23-Apr-14 00:04 models/regscale_models/stig.py
+-rw-r--r--  2.0 unx     1425 b- defN 23-Apr-14 00:04 models/regscale_models/threat.py
+-rw-r--r--  2.0 unx     2242 b- defN 23-Apr-14 00:04 models/regscale_models/user.py
+-rw-r--r--  2.0 unx        0 b- defN 23-Apr-14 00:04 tests/__init__.py
+-rw-r--r--  2.0 unx     1818 b- defN 23-Apr-14 00:04 tests/conftest.py
+-rw-r--r--  2.0 unx      368 b- defN 23-Apr-14 00:04 tests/mock_api_service.py
+-rw-r--r--  2.0 unx     1334 b- defN 23-Apr-14 00:04 tests/test_app_utils.py
+-rw-r--r--  2.0 unx     1930 b- defN 23-Apr-14 00:04 tests/test_assessments_editor.py
+-rw-r--r--  2.0 unx     1687 b- defN 23-Apr-14 00:04 tests/test_cisa.py
+-rw-r--r--  2.0 unx     1747 b- defN 23-Apr-14 00:04 tests/test_control_editor.py
+-rw-r--r--  2.0 unx     1425 b- defN 23-Apr-14 00:04 tests/test_dependabot.py
+-rw-r--r--  2.0 unx     2827 b- defN 23-Apr-14 00:04 tests/test_emass.py
+-rw-r--r--  2.0 unx    14137 b- defN 23-Apr-14 00:04 tests/test_evidence.py
+-rw-r--r--  2.0 unx     1186 b- defN 23-Apr-14 00:04 tests/test_login.py
+-rw-r--r--  2.0 unx     1416 b- defN 23-Apr-14 00:04 tests/test_npm_audit.py
+-rw-r--r--  2.0 unx     9248 b- defN 23-Apr-14 00:04 tests/test_oscal.py
+-rw-r--r--  2.0 unx      866 b- defN 23-Apr-14 00:04 tests/test_snow.py
+-rw-r--r--  2.0 unx     1245 b- defN 23-Apr-14 00:04 tests/test_sonarcloud.py
+-rw-r--r--  2.0 unx     1258 b- defN 23-Apr-14 00:04 tests/test_stig.py
+-rw-r--r--  2.0 unx     1666 b- defN 23-Apr-14 00:04 tests/test_tenable.py
+-rw-r--r--  2.0 unx     1254 b- defN 23-Apr-14 00:04 tests/test_update_regscale_config.py
+-rw-r--r--  2.0 unx     1076 b- defN 23-Apr-14 00:05 RegScale_CLI-4.25.1.dist-info/LICENSE
+-rw-r--r--  2.0 unx     6330 b- defN 23-Apr-14 00:05 RegScale_CLI-4.25.1.dist-info/METADATA
+-rw-r--r--  2.0 unx       92 b- defN 23-Apr-14 00:05 RegScale_CLI-4.25.1.dist-info/WHEEL
+-rw-r--r--  2.0 unx       43 b- defN 23-Apr-14 00:05 RegScale_CLI-4.25.1.dist-info/entry_points.txt
+-rw-r--r--  2.0 unx       37 b- defN 23-Apr-14 00:05 RegScale_CLI-4.25.1.dist-info/top_level.txt
+?rw-rw-r--  2.0 unx     7715 b- defN 23-Apr-14 00:05 RegScale_CLI-4.25.1.dist-info/RECORD
+92 files, 882673 bytes uncompressed, 218010 bytes compressed:  75.3%
```

## zipnote {}

```diff
@@ -33,14 +33,17 @@
 
 Filename: app/commercial/qualys.py
 Comment: 
 
 Filename: app/commercial/servicenow.py
 Comment: 
 
+Filename: app/commercial/stig.py
+Comment: 
+
 Filename: app/commercial/tenable.py
 Comment: 
 
 Filename: app/commercial/wiz.py
 Comment: 
 
 Filename: app/internal/__init__.py
@@ -147,50 +150,71 @@
 
 Filename: models/regscale_models/assessment.py
 Comment: 
 
 Filename: models/regscale_models/asset.py
 Comment: 
 
+Filename: models/regscale_models/checklist.py
+Comment: 
+
 Filename: models/regscale_models/components.py
 Comment: 
 
 Filename: models/regscale_models/control_implementation.py
 Comment: 
 
+Filename: models/regscale_models/control_objective.py
+Comment: 
+
+Filename: models/regscale_models/implementation_objective.py
+Comment: 
+
+Filename: models/regscale_models/implementation_option.py
+Comment: 
+
 Filename: models/regscale_models/interconnects.py
 Comment: 
 
 Filename: models/regscale_models/issue.py
 Comment: 
 
 Filename: models/regscale_models/modules.py
 Comment: 
 
+Filename: models/regscale_models/objective.py
+Comment: 
+
 Filename: models/regscale_models/ports_protocols.py
 Comment: 
 
 Filename: models/regscale_models/requirements.py
 Comment: 
 
 Filename: models/regscale_models/securityplans.py
 Comment: 
 
+Filename: models/regscale_models/stig.py
+Comment: 
+
 Filename: models/regscale_models/threat.py
 Comment: 
 
 Filename: models/regscale_models/user.py
 Comment: 
 
 Filename: tests/__init__.py
 Comment: 
 
 Filename: tests/conftest.py
 Comment: 
 
+Filename: tests/mock_api_service.py
+Comment: 
+
 Filename: tests/test_app_utils.py
 Comment: 
 
 Filename: tests/test_assessments_editor.py
 Comment: 
 
 Filename: tests/test_cisa.py
@@ -219,32 +243,35 @@
 
 Filename: tests/test_snow.py
 Comment: 
 
 Filename: tests/test_sonarcloud.py
 Comment: 
 
+Filename: tests/test_stig.py
+Comment: 
+
 Filename: tests/test_tenable.py
 Comment: 
 
 Filename: tests/test_update_regscale_config.py
 Comment: 
 
-Filename: RegScale_CLI-4.25.0.dist-info/LICENSE
+Filename: RegScale_CLI-4.25.1.dist-info/LICENSE
 Comment: 
 
-Filename: RegScale_CLI-4.25.0.dist-info/METADATA
+Filename: RegScale_CLI-4.25.1.dist-info/METADATA
 Comment: 
 
-Filename: RegScale_CLI-4.25.0.dist-info/WHEEL
+Filename: RegScale_CLI-4.25.1.dist-info/WHEEL
 Comment: 
 
-Filename: RegScale_CLI-4.25.0.dist-info/entry_points.txt
+Filename: RegScale_CLI-4.25.1.dist-info/entry_points.txt
 Comment: 
 
-Filename: RegScale_CLI-4.25.0.dist-info/top_level.txt
+Filename: RegScale_CLI-4.25.1.dist-info/top_level.txt
 Comment: 
 
-Filename: RegScale_CLI-4.25.0.dist-info/RECORD
+Filename: RegScale_CLI-4.25.1.dist-info/RECORD
 Comment: 
 
 Zip file comment:
```

## regscale.py

```diff
@@ -33,14 +33,15 @@
 from app.commercial.ad import ad
 from app.commercial.defender import defender
 from app.commercial.jira import jira
 from app.commercial.okta import okta
 from app.commercial.qualys import qualys
 from app.commercial.servicenow import servicenow
 from app.commercial.tenable import tenable
+from app.commercial.stig import stig
 from app.commercial.wiz import wiz
 
 ############################################################
 # Internal Integrations
 ############################################################
 import app.internal.healthcheck as hc
 import app.internal.login as lg
@@ -92,18 +93,14 @@
 def about_display():
     """Provides information about the CLI and its current version."""
     console.print(f"[red]RegScale[/red] CLI Version: {__version__}")
     console.print("Author: J. Travis Howerton (thowerton@regscale.com)")
     console.print("Copyright: RegScale Incorporated")
     console.print("Website: https://www.regscale.com")
     console.print("Read the CLI Docs: https://regscale.readme.io/docs/overview")
-    java = app.get_java()
-    matches = ["not found", "internal or external"]
-    if all(x not in java for x in matches):
-        console.print(f"Java: {java}")
     console.print(
         "\n[red]DISCLAIMER: RegScale does not conduct any form of security scanning for data imported by the customer. "
         + "It is the customer's responsibility to ensure that data imported into the platform using "
         + "the Command Line Interface meets industry standard, minimum security screening requirements. "
         + "RegScale has no liability for failing to scan any such data or for any data imported by "
         + "the customer that fails to meet such requirements.[red]\n"
     )
@@ -276,14 +273,15 @@
 @cli.command(name="validate_token")
 def validate_token():
     """Check to see if token is valid."""
     if lg.is_valid(app=app):
         sys.exit(0)
     else:
         logger.warning("RegScale token is invalid, please login.")
+        sys.exit(1)
 
 
 # Check the health of the RegScale Application
 @cli.command()
 def healthcheck():
     """Monitoring tool to check the health of the RegScale instance."""
     hc.status()
@@ -429,14 +427,17 @@
 
 # add ServiceNow support
 cli.add_command(servicenow)
 
 # add Tenable support
 cli.add_command(tenable)
 
+# add STIG support
+cli.add_command(stig)
+
 # add Wiz support
 cli.add_command(wiz)
 
 # add Control Editor Feature
 cli.add_command(control_editor)
 
 # add Assessments Editor Feature
```

## app/_version.py

```diff
@@ -1,4 +1,4 @@
 #!/usr/bin/env python3
 # standard python imports
 
-__version__ = "4.25.0"
+__version__ = "4.25.1"
```

## app/api.py

```diff
@@ -15,36 +15,38 @@
 from app.application import Application
 from app.logz import create_logger
 
 
 class Api:
     """Wrapper for interacting with the RegScale API"""
 
-    def __init__(self, app: Application):
+    def __init__(self, app: Application, timeout: int = 10, retry=5):
         """
         Initialize API object
         :param app: Application object
+        :param timeout: timeout for API calls, defaults to 10
+        :param retry: number of retries for API calls, defaults to 5
         """
         logger = create_logger()
         self.app = app
-        self.timeout = 10
+        self.timeout = timeout
         config = app.config
         self.config = config
         self.accept = "application/json"
         self.content_type = "application/json"
         self.logger = logger
         r_session = requests.Session()
         self.pool_connections = 200
         self.pool_maxsize = 200
         if "ssl_verify" in self.config:
             r_session.verify = self.config["ssl_verify"]
         if "timeout" in self.config:
             self.timeout = self.config["timeout"]
         retries = Retry(
-            total=5, backoff_factor=0.1, status_forcelist=[500, 502, 503, 504]
+            total=retry, backoff_factor=0.1, status_forcelist=[500, 502, 503, 504]
         )
         # get the user's domain prefix eg https:// or http://
         domain = config["domain"]
         domain = domain[: (domain.find("://") + 3)]
         r_session.mount(
             domain,
             HTTPAdapter(
@@ -279,15 +281,14 @@
         if pagination_flag:
             # recall the function with the new query and extend the data with the results
             response_data = self.graph(
                 url=url, headers=headers, query=query, res_data=data
             )
             # set the data to the pagination data
             data = response_data
-        self.logger.debug(data)
         # return the data
         return data
 
     def update_server(
         self,
         url: str,
         headers: dict = None,
@@ -341,15 +342,18 @@
                                 json_list,
                             )
                         )
                     for future in concurrent.futures.as_completed(result_futures):
                         try:
                             if future.result().status_code != 200:
                                 self.logger.warning(
-                                    "Status code is %s.", future.result().status_code
+                                    "Status code is %s: %s from %s.",
+                                    future.result().status_code,
+                                    future.result().text,
+                                    future.result().url,
                                 )
                             progress.update(task, advance=1)
                         except Exception as ex:
                             self.logger.error("Error is %s, type: %s", ex, type(ex))
 
 
 def normalize_url(url: str) -> str:
```

## app/commercial/qualys.py

```diff
@@ -14,53 +14,45 @@
 import click
 import requests
 import xmltodict
 from requests import Session
 from rich.console import Console
 
 from app.api import Api
-from app.application import Application
 from app.logz import create_logger
 from app.utils.app_utils import (
+    check_license,
     create_progress_object,
     error_and_exit,
     get_current_datetime,
     save_data_to,
     check_file_path,
 )
 from app.utils.regscale_utils import lookup_reg_assets_by_parent
 from models.app_models.click import NotRequiredIf
 from models.app_models.click import save_output_to
 from models.regscale_models.asset import Asset
 from models.regscale_models.issue import Issue
 
-############################################################################################################
+####################################################################################################
 #
 # Qualys API Documentation:
 #   https://qualysguard.qg2.apps.qualys.com/qwebhelp/fo_portal/api_doc/index.htm
 #
-############################################################################################################
+####################################################################################################
 
-console = Console()
 
+# create global variables for the entire module
+console = Console()
 logger = create_logger()
-app = Application()
-config = app.config
-regscale_api = Api(app)
-qualys_api = Session()
-HEADERS = {"X-Requested-With": "RegScale CLI"}
 
-# create constants from app.config elements
-USER_NAME = app.config["qualysUserName"]
-PASSWORD = app.config["qualysPassword"]
-BASE_URL = app.config["qualysUrl"]
-
-qualys_api.auth = (USER_NAME, PASSWORD)
 # create progress object to add tasks to for real time updates
 job_progress = create_progress_object()
+HEADERS = {"X-Requested-With": "RegScale CLI"}
+QUALYS_API = Session()
 
 
 # Create group to handle Qualys commands
 @click.group()
 def qualys():
     """Performs actions from the Qualys API"""
 
@@ -73,14 +65,16 @@
     default=30,
     help="The number of days to go back for completed scans, default is 30.",
 )
 def export_past_scans(save_output_to: Path, days: int, export: bool = True):
     """Export scans from Qualys Host that were completed
     in the last x days, defaults to last 30 days
     and defaults to save it as a .json file"""
+    # see if user has enterprise license
+    check_license()
     date = get_current_datetime("%Y%m%d")
     results = get_detailed_scans(days)
     if export:
         check_file_path(save_output_to)
         save_data_to(
             file_name=f"{save_output_to.name}{os.sep}qualys_scans_{date}",
             file_type=".json",
@@ -94,14 +88,17 @@
     "--scan_id",
     type=click.STRING,
     help="Qualys scan reference ID to get results, defaults to all.",
     default="all",
 )
 def save_queries(save_output_to: Path, scan_id: str):
     """Get scan results from Qualys using a scan ID or all scans and save them to a .json file."""
+    # see if user has enterprise license
+    check_license()
+
     check_file_path(save_output_to)
     with job_progress:
         if scan_id.lower() == "all":
             # get all the scan results from Qualys
             scans = get_scans_summary("all")
 
             # add task to job progress to let user know # of scans to fetch
@@ -117,15 +114,15 @@
             )
             # get the scan result for the provided scan id
             scan_data = get_scan_results(scan_id, task1)
     # save the scan_data as the provided file_path
     save_data_to(file_name=save_output_to.name, file_type=".json", data=scan_data)
 
 
-@qualys.command(name="query_vuln")
+@qualys.command(name="sync_qualys")
 @click.option(
     "--regscale_ssp_id",
     type=click.INT,
     required=True,
     prompt="Enter RegScale System Security Plan ID",
     help="The ID number from RegScale of the System Security Plan",
 )
@@ -148,49 +145,55 @@
     "--asset_group_name",
     type=click.STRING,
     help="Filter assets from Qualys with an asset group name.",
     default=None,
     cls=NotRequiredIf,
     not_required_if=["asset_group_id"],
 )
-def query_vuln(
-    scan_id: str,
+def sync_qualys(
     regscale_ssp_id: int,
-    create_issue: bool,
+    create_issue: bool = False,
     asset_group_id: int = None,
     asset_group_name: str = None,
 ):
-    """Query Qualys and sync assets & their associated vulnerabilities to RegScale."""
+    """
+    Query Qualys and sync assets & their associated
+    vulnerabilities to a Security Plan in RegScale.
+    """
+    # see if user has enterprise license
+    check_license()
+
     # check if the user provided an asset group id or name
     if asset_group_id:
         # get the assets from Qualys using the group name
-        q_vuln(
-            scan_id=scan_id,
+        sync_qualys_assets_and_vulns(
             ssp_id=regscale_ssp_id,
             create_issue=create_issue,
-            asset_group_name=asset_group_name,
+            asset_group_filter=asset_group_name,
         )
     elif asset_group_name:
         # get the assets from Qualys using the group name
-        q_vuln(
-            scan_id=scan_id,
+        sync_qualys_assets_and_vulns(
             ssp_id=regscale_ssp_id,
             create_issue=create_issue,
-            asset_groupd_id=asset_group_id,
+            asset_group_filter=asset_group_id,
         )
     else:
-        q_vuln(scan_id=scan_id, ssp_id=regscale_ssp_id, create_issue=create_issue)
+        sync_qualys_assets_and_vulns(ssp_id=regscale_ssp_id, create_issue=create_issue)
 
 
 @qualys.command(name="get_asset_groups")
 @save_output_to()
 def get_asset_groups(save_output_to: Path):
     """
     Get all asset groups from Qualys via API and save them to a .json file.
     """
+    # see if user has enterprise license
+    check_license()
+
     date = get_current_datetime("%Y%m%d")
     check_file_path(save_output_to)
     asset_groups = get_asset_groups_from_qualys()
     save_data_to(
         file_name=f"{save_output_to}{os.sep}qualys_asset_groups_{date}",
         file_type=".json",
         data=asset_groups,
@@ -201,14 +204,20 @@
     """
     Function to retrieve scan results from Qualys using provided scan list and returns a dictionary
     :param any scans: list of scans to retrieve from Qualys
     :param task: task to update in the progress object
     :return: dictionary of detailed Qualys scans
     :rtype: dict
     """
+    app = check_license()
+    config = app.config
+
+    # set the auth for the QUALYS_API session
+    QUALYS_API.auth = (config["qualysUserName"], config["qualysPassword"])
+
     scan_data = {}
     # check number of scans requested
     if isinstance(scans, str):
         # only one scan was requested, set up variable for the for loop
         scans = {"SCAN": [{"REF": scans}]}
     for scan in scans["SCAN"]:
         # set up data and parameters for the scans query
@@ -219,16 +228,18 @@
             params = {
                 "action": "fetch",
                 "scan_ref": scan_id,
                 "mode": "extended",
                 "output_format": "json_extended",
             }
             # get the scan data via API
-            res = qualys_api.get(
-                url=BASE_URL + "/api/2.0/fo/scan/", headers=HEADERS, params=params
+            res = QUALYS_API.get(
+                url=f"{config['qualysUrl']}/api/2.0/fo/scan/",
+                headers=HEADERS,
+                params=params,
             )
             # convert response to json
             if res.status_code == 200:
                 try:
                     res_data = res.json()
                     scan_data[scan_id] = res_data
                 except JSONDecodeError:
@@ -242,38 +253,48 @@
             continue
         job_progress.update(task, advance=1)
     return scan_data
 
 
 def get_detailed_scans(days: int) -> list:
     """
-    function to get the list of all scans from Qualys using qualys_api
+    function to get the list of all scans from Qualys using QUALYS_API
     :param int days: # of days before today to filter scans
     :raises: JSONDecodeError if API response cannot be converted to a json object
     :return: list of results from Qualys API
     :rtype: list
     """
+    app = check_license()
+    config = app.config
+
+    # set the auth for the QUALYS_API session
+    QUALYS_API.auth = (config["qualysUserName"], config["qualysPassword"])
+
     today = datetime.now()
     scan_date = today - timedelta(days=days)
 
     # set up data and parameters for the scans query
     params = {
         "action": "list",
         "scan_date_since": scan_date.strftime("%Y-%m-%d"),
         "output_format": "json",
     }
     params2 = {
         "action": "list",
         "scan_datetime_since": scan_date.strftime("%Y-%m-%dT%H:%I:%S%ZZ"),
     }
-    res = qualys_api.get(
-        url=BASE_URL + "/api/2.0/fo/scan/summary/", headers=HEADERS, params=params
-    )
-    response = qualys_api.get(
-        url=BASE_URL + "/api/2.0/fo/scan/vm/summary/", headers=HEADERS, params=params2
+    res = QUALYS_API.get(
+        url=f"{config['qualysUrl']}/api/2.0/fo/scan/summary/",
+        headers=HEADERS,
+        params=params,
+    )
+    response = QUALYS_API.get(
+        url=f"{config['qualysUrl']}/api/2.0/fo/scan/vm/summary/",
+        headers=HEADERS,
+        params=params2,
     )
     # convert response to json
     res_data = res.json()
     try:
         response_data = xmltodict.parse(response.text)["SCAN_SUMMARY_OUTPUT"][
             "RESPONSE"
         ]["SCAN_SUMMARY_LIST"]["SCAN_SUMMARY"]
@@ -290,32 +311,38 @@
     """
     Get all scans from Qualys Host
     :param str scan_choice: The type of scan to retrieve from Qualys API
     :raises: KeyError if expected data isn't found in the Qualys API response
     :return: Detailed summary of scans from Qualys API as a dictionary
     :rtype: dict
     """
+    app = check_license()
+    config = app.config
+
+    # set the auth for the QUALYS_API session
+    QUALYS_API.auth = (config["qualysUserName"], config["qualysPassword"])
+
     # set up variables for function
     scan_data = {}
     responses = []
-    scan_url = BASE_URL + "/api/2.0/fo/scan/"
+    scan_url = f"{config['qualysUrl']}/api/2.0/fo/scan/"
 
     # set up parameters for the scans query
     params = {"action": "list"}
     # check what scan list was requested and set urls list accordingly
     if scan_choice.lower() == "all":
         urls = [scan_url, scan_url + "compliance", scan_url + "scap"]
     elif scan_choice.lower() == "vm":
         urls = [scan_url]
     elif scan_choice.lower() in ["compliance", "scap"]:
         urls = [scan_url + scan_choice.lower()]
     # get the list of vm scans
     for url in urls:
         # get the scan data
-        response = qualys_api.get(url=url, headers=HEADERS, params=params)
+        response = QUALYS_API.get(url=url, headers=HEADERS, params=params)
         # store response into a list
         responses.append(response)
     # check the responses received for data
     for response in responses:
         # see if response was successful
         if response.status_code == 200:
             # parse the data
@@ -335,14 +362,19 @@
     Retrieve completed scans from last x days from Qualys Host
     :param int days: # of days before today to filter scans
     :raises: JSONDecodeError if API response cannot be converted to a json object
     :raises: KeyError if expected data isn't found in the Qualys API response
     :return: Detailed summary of scans from Qualys API as a dictionary
     :rtype: list
     """
+    app = check_license()
+    config = app.config
+
+    # set the auth for the QUALYS_API session
+    QUALYS_API.auth = (config["qualysUserName"], config["qualysPassword"])
     # get since date for API call
     since_date = datetime.now() - timedelta(days=days)
     # set up data and parameters for the scans query
     headers = {
         "Content-Type": "application/json",
         "Accept": "application/json",
         "X-Requested-With": "RegScale CLI",
@@ -352,19 +384,23 @@
         "scan_date_since": since_date.strftime("%Y-%m-%d"),
         "output_format": "json",
     }
     params2 = {
         "action": "list",
         "scan_datetime_since": since_date.strftime("%Y-%m-%dT%H:%M:%SZ"),
     }
-    res = qualys_api.get(
-        url=BASE_URL + "/api/2.0/fo/scan/summary/", headers=headers, params=params
-    )
-    response = qualys_api.get(
-        url=BASE_URL + "/api/2.0/fo/scan/vm/summary/", headers=headers, params=params2
+    res = QUALYS_API.get(
+        url=f"{config['qualysUrl']}/api/2.0/fo/scan/summary/",
+        headers=headers,
+        params=params,
+    )
+    response = QUALYS_API.get(
+        url=f"{config['qualysUrl']}/api/2.0/fo/scan/vm/summary/",
+        headers=headers,
+        params=params2,
     )
     # convert response to json
     res_data = res.json()
     try:
         response_data = xmltodict.parse(response.text)["SCAN_SUMMARY_OUTPUT"][
             "RESPONSE"
         ]["SCAN_SUMMARY_LIST"]["SCAN_SUMMARY"]
@@ -375,74 +411,60 @@
     except JSONDecodeError as ex:
         error_and_exit(f"Unable to convert to JSON.\n{ex}")
     except KeyError:
         error_and_exit(f"No data found.\n{response.text}")
     return res_data
 
 
-def q_vuln(
+def sync_qualys_assets_and_vulns(
     ssp_id: int,
     create_issue: bool,
     asset_group_filter: Optional[Union[int, str]] = None,
 ) -> None:
     """
-    Function to query Qualys and sync assets & their associated vulnerabilities to RegScale.
+    Function to query Qualys and sync assets & associated vulnerabilities to RegScale
     :param int ssp_id: RegScale System Security Plan ID
     :param bool create_issue: Flag to create an issue in RegScale for each vulnerability from Qualys
-    :param str asset_group_filter: Filter the Qualys assets by an asset group ID or name, if provided
+    :param str asset_group_filter: Filter the Qualys assets by an asset group ID or name, if any
     :return: None
     """
+    app = check_license()
+    config = app.config
+    regscale_api = Api(app)
+
+    # set the auth for the QUALYS_API session
+    QUALYS_API.auth = (config["qualysUserName"], config["qualysPassword"])
+
     # Get the assets from RegScale with the provided SSP ID
     logger.info("Getting assets from RegScale for SSP #%s...", ssp_id)
     reg_assets = lookup_reg_assets_by_parent(
         api=regscale_api, parent_id=ssp_id, module="securityplans"
     )
-    logger.info("Located %s asset(s) associated with SSP#%s.", len(reg_assets), ssp_id)
+    logger.info(
+        "Located %s asset(s) associated with SSP #%s in RegScale.",
+        len(reg_assets),
+        ssp_id,
+    )
     logger.debug(reg_assets)
 
-    if asset_group_filter:
-        if isinstance(asset_group_filter, str):
-            # Get the asset group ID from Qualys
-            logger.info(
-                "Getting assets from Qualys by group name: %s...", asset_group_filter
-            )
-        logger.info(
-            "Getting assets from from Qualys by group ID: #%s...", asset_group_filter
-        )
-        qualys_assets = get_qualys_assets_and_scan_results(asset_group_filter)
+    if qualys_assets := get_qualys_assets_and_scan_results(asset_group_filter):
         logger.info("Received %s assets from Qualys.", len(qualys_assets))
         logger.debug(qualys_assets)
+        # Get vulnerabilities from Qualys for the Qualys assets
+        logger.info(
+            "Getting vulnerabilities for %s asset(s) from Qualys...", len(qualys_assets)
+        )
+        qualys_assets_and_issues, total_vuln_count = get_issue_data_for_assets(
+            qualys_assets
+        )
+        logger.info("Received %s vulnerabilities from Qualys.", total_vuln_count)
+        logger.debug(qualys_assets_and_issues)
     else:
-        # Get all assets from Qualys
-        logger.info("Getting all assets from Qualys...")
-        qualys_assets = get_qualys_assets_and_scan_results()
-        logger.info("Received %s assets from Qualys.", len(qualys_assets))
-        logger.debug(qualys_assets)
-
-    # Get vulnerabilities from Qualys for the Qualys assets
-    logger.info(
-        "Getting vulnerabilities for %s asset(s) from Qualys...", len(qualys_assets)
-    )
-    qualys_assets_and_issues, total_vuln_count = get_issue_data_for_assets(
-        qualys_assets
-    )
-    logger.info("Received %s vulnerabilities from Qualys.", total_vuln_count)
-    logger.debug(qualys_assets_and_issues)
+        error_and_exit("No assets found in Qualys.")
 
-    assets_to_be_inserted = list(
-        [
-            qualys_asset
-            for qualys_asset in qualys_assets_and_issues
-            if qualys_asset["ASSET_ID"]
-            not in set(
-                asset["ASSET_ID"]
-                for asset in inner_join(reg_assets, qualys_assets_and_issues)
-            )
-        ]
-    )
     update_assets = []
     insert_assets = []
     for (
         qualys_asset
     ) in qualys_assets:  # you can list as many input dicts as you want here
         lookup_assets = lookup_asset(reg_assets, qualys_asset["ASSET_ID"])
         # Update parent id to SSP on insert
@@ -452,60 +474,70 @@
                 asset.parentModule = "securityplans"
                 asset.otherTrackingNumber = qualys_asset["ID"]
                 asset.ipAddress = qualys_asset["IP"]
                 asset.qualysId = qualys_asset["ASSET_ID"]
                 try:
                     assert asset.id
                     # avoid duplication
-                    if asset.qualysId not in set(v["qualysId"] for v in update_assets):
+                    if asset.qualysId not in [v["qualysId"] for v in update_assets]:
                         update_assets.append(asdict(asset))
                 except AssertionError as aex:
                     logger.error(
                         "Asset does not have an id, unable to update!\n%s", aex
                     )
 
-    for qualys_asset in assets_to_be_inserted:
-        if len(assets_to_be_inserted) > 0:
+    if assets_to_be_inserted := [
+        qualys_asset
+        for qualys_asset in qualys_assets_and_issues
+        if qualys_asset["ASSET_ID"]
+        not in [
+            asset["ASSET_ID"]
+            for asset in inner_join(reg_assets, qualys_assets_and_issues)
+        ]
+    ]:
+        for qualys_asset in assets_to_be_inserted:
             # Do Insert
             r_asset = Asset(
                 name=f'Qualys Asset #{qualys_asset["ASSET_ID"]} IP: {qualys_asset["IP"]}',
                 otherTrackingNumber=qualys_asset["ID"],
                 parentId=ssp_id,
                 parentModule="securityplans",
                 ipAddress=qualys_asset["IP"],
-                assetOwnerId=app.config["userId"],
+                assetOwnerId=config["userId"],
                 assetType="Other",
                 assetCategory="Hardware",
                 status="Off-Network",
                 qualysId=qualys_asset["ASSET_ID"],
             )
             # avoid duplication
             if r_asset.qualysId not in set(v["qualysId"] for v in insert_assets):
                 insert_assets.append(asdict(r_asset))
-    try:
-        regscale_api.update_server(
-            method="post",
-            url=app.config["domain"] + "/api/assets",
-            json_list=insert_assets,
-            message=f"Inserting {len(insert_assets)} assets from Qualys to RegScale.",
-        )
+        try:
+            regscale_api.update_server(
+                method="post",
+                url=f"{config['domain']}/api/assets",
+                json_list=insert_assets,
+                message=f"Inserting {len(insert_assets)} assets from Qualys to RegScale.",
+            )
 
-        logger.info("Regscale Assets successfully inserted: %i", len(insert_assets))
-    except requests.exceptions.RequestException as rex:
-        logger.error("Unable to Insert Qualys Assets to RegScale\n%s", rex)
-    try:
-        regscale_api.update_server(
-            method="put",
-            url=app.config["domain"] + "/api/assets",
-            json_list=update_assets,
-            message=f"Updating {len(update_assets)} assets from Qualys to RegScale.",
-        )
-        logger.info("Regscale Assets successfully updated: %i", len(update_assets))
-    except requests.RequestException as rex:
-        logger.error("Unable to Update Qualys Assets to RegScale\n%s", rex)
+            logger.info("Regscale Assets successfully inserted: %i", len(insert_assets))
+        except requests.exceptions.RequestException as rex:
+            logger.error("Unable to Insert Qualys Assets to RegScale\n%s", rex)
+
+    if len(update_assets) > 0:
+        try:
+            regscale_api.update_server(
+                method="put",
+                url=f"{config['domain']}/api/assets",
+                json_list=update_assets,
+                message=f"Updating {len(update_assets)} assets from Qualys to RegScale.",
+            )
+            logger.info("Regscale Assets successfully updated: %i", len(update_assets))
+        except requests.RequestException as rex:
+            logger.error("Unable to Update Qualys Assets to RegScale\n%s", rex)
     if create_issue:
         for asset in qualys_assets_and_issues:
             # Create issues in RegScale from Qualys vulnerabilities
             create_regscale_issue_from_vuln(
                 regscale_ssp_id=ssp_id, qualys_asset=asset, vulns=asset["ISSUES"]
             )
 
@@ -515,26 +547,42 @@
 ) -> list:
     """
     function to gather all assets from Qualys API host along with their scan results
     :param int | str asset_group_filter: Qualys asset group ID or name to filter by, if provided
     :return: list of dictionaries containing asset data
     :rtype: list
     """
+    app = check_license()
+    config = app.config
+
+    # set the auth for the QUALYS_API session
+    QUALYS_API.auth = (config["qualysUserName"], config["qualysPassword"])
     # set url
     url = f'{config["qualysUrl"]}api/2.0/fo/asset/host/vm/detection?action=list&show_asset_id=1'
 
     # check if an asset group filter was provided and append it to the url
     if asset_group_filter:
-        if isinstance(asset_group_filter, int):
-            url += f"&ag_ids={asset_group_filter}"
-        elif isinstance(asset_group_filter, str):
+        if isinstance(asset_group_filter, str):
+            # Get the asset group ID from Qualys
             url += f"&ag_titles={asset_group_filter}"
+            logger.info(
+                "Getting assets from Qualys by group name: %s...", asset_group_filter
+            )
+        else:
+            url += f"&ag_ids={asset_group_filter}"
+            logger.info(
+                "Getting assets from from Qualys by group ID: #%s...",
+                asset_group_filter,
+            )
+    else:
+        # Get all assets from Qualys
+        logger.info("Getting all assets from Qualys...")
 
     # get the data via Qualys API host
-    response = qualys_api.get(url=url, headers=HEADERS)
+    response = QUALYS_API.get(url=url, headers=HEADERS)
 
     # parse the xml data from response.text and convert it to a dictionary
     response_data = xmltodict.parse(response.text)
     try:
         # try to extract the data from the parsed XML dictionary
         asset_data = response_data["HOST_LIST_VM_DETECTION_OUTPUT"]["RESPONSE"][
             "HOST_LIST"
@@ -549,14 +597,19 @@
 def get_issue_data_for_assets(asset_list: list) -> tuple[list, int]:
     """
     Function to get issue data from Qualys via API for assets in Qualys
     :param list asset_list: Assets and their scan results from Qualys
     :return:  Updated asset list of Qualys assets and their associated vulnerabilities, total number of vulnerabilities
     :rtype: tuple[list, int]
     """
+    app = check_license()
+    config = app.config
+
+    # set the auth for the QUALYS_API session
+    QUALYS_API.auth = (config["qualysUserName"], config["qualysPassword"])
     total_issues = 0
 
     with job_progress:
         fetching_vulns = job_progress.add_task(
             f"Getting vulnerability data from Qualys for {len(asset_list)} assets...",
             total=len(asset_list),
         )
@@ -576,17 +629,16 @@
 
                 maping_vulns = job_progress.add_task(
                     f"Mapping {len(issues)} vulnerabilities to Asset #{asset['ASSET_ID']} from Qualys...",
                     total=len(issues),
                 )
                 for issue in issues:
                     total_issues += 1
-                    response = qualys_api.get(
-                        config["qualysUrl"]
-                        + f"api/2.0/fo/knowledge_base/vuln?action=list&details=All&ids={issue}",
+                    response = QUALYS_API.get(
+                        url=f"{config['qualysUrl']}api/2.0/fo/knowledge_base/vuln?action=list&details=All&ids={issue}",
                         headers=HEADERS,
                     )
                     issues[issue]["ISSUE_DATA"] = xmltodict.parse(response.text)[
                         "KNOWLEDGE_BASE_VULN_LIST_OUTPUT"
                     ]["RESPONSE"]["VULN_LIST"]["VULN"]
                     job_progress.update(maping_vulns, advance=1)
                 # add the issues to the asset's dictionary
@@ -597,21 +649,21 @@
 
             # update the main task
             job_progress.update(fetching_vulns, advance=1)
 
     return asset_list, total_issues
 
 
-def lookup_asset(asset_list: list, asset_id: str = None) -> Asset:
+def lookup_asset(asset_list: list, asset_id: str = None) -> list[Asset]:
     """
     Function to look up an asset in the asset list and returns an Asset object
     :param list asset_list: List of assets from RegScale
     :param str asset_id: Qualys asset ID to search for, defaults to None
-    :return: Asset object
-    :rtype: Asset
+    :return: list of Asset objects
+    :rtype: list[Asset]
     """
     results = []
     if asset_id:
         results = [
             Asset.from_dict(asset)
             for asset in asset_list
             if asset.get("qualysId") == asset_id
@@ -627,38 +679,42 @@
     Map Qualys vulnerability severity to RegScale Issue severity
     :param int severity: Qualys vulnerability severity
     :return: RegScale Issue severity and key for init.yaml
     :rtype: tuple[str, str]
     """
     if severity <= 2:
         return "III - Low - Other Weakness", "low"
-    elif severity == 3:
+    if severity == 3:
         return "II - Moderate - Reportable Condition", "moderate"
-    elif severity > 3:
+    if severity > 3:
         return "I - High - Significant Deficiency", "high"
-    else:
-        return "IV - Not Assigned", "low"
+    return "IV - Not Assigned", "low"
 
 
 def create_regscale_issue_from_vuln(
-    regscale_ssp_id: int, qualys_asset: dict, vulns: list
+    regscale_ssp_id: int, qualys_asset: dict, vulns: dict
 ) -> None:
     """
     Sync Qualys vulnerabilities to RegScale issues.
     :param int regscale_ssp_id: RegScale SSP ID
     :param dict qualys_asset: Qualys asset as a dictionary
-    :param list vulns: List of Qualys vulnerabilities associated with the provided asset
+    :param dict vulns: dictionary of Qualys vulnerabilities associated with the provided asset
     :return: None
     """
+    app = check_license()
+    config = app.config
+    regscale_api = Api(app)
+
+    # set the auth for the QUALYS_API session
+    QUALYS_API.auth = (config["qualysUserName"], config["qualysPassword"])
     default_status = config["issues"]["qualys"]["status"]
     regscale_new_issues = []
     regscale_existing_issues = []
     existing_issues_req = regscale_api.get(
-        app.config["domain"]
-        + f"/api/issues/getAllByParent/{regscale_ssp_id}/securityplans"
+        url=f"{config['domain']}/api/issues/getAllByParent/{regscale_ssp_id}/securityplans"
     )
     if existing_issues_req.status_code == 200:
         regscale_existing_issues = existing_issues_req.json()
 
     for vuln in vulns.values():
         severity, key = map_qualys_severity_to_regscale(int(vuln["SEVERITY"]))
 
@@ -669,48 +725,50 @@
             days=default_due_delta
         )
         issue = Issue(
             title=vuln["ISSUE_DATA"]["TITLE"],
             description=vuln["ISSUE_DATA"]["CONSEQUENCE"]
             + "</br>"
             + vuln["ISSUE_DATA"]["DIAGNOSIS"],
-            issueOwnerId=app.config["userId"],
+            issueOwnerId=config["userId"],
             status=default_status,
             severityLevel=severity,
             qualysId=vuln["QID"],
             dueDate=due_date.strftime(fmt),
             identification="Vulnerability Assessment",
             parentId=regscale_ssp_id,
             parentModule="securityplans",
             recommendedActions=vuln["ISSUE_DATA"]["SOLUTION"],
             assetIdentifier=f'DNS: {qualys_asset["DNS"]} - IP: {qualys_asset["IP"]}',
         )
-        if issue.qualysId in set([iss["qualysId"] for iss in regscale_new_issues]):
+        if issue.qualysId in [iss["qualysId"] for iss in regscale_new_issues]:
             # Update
             update_issue = [
                 iss for iss in regscale_new_issues if iss["qualysId"] == issue.qualysId
             ]
             if update_issue["assetIdentifier"] != issue.assetIdentifier:
                 assets = set(update_issue["assetIdentifier"].split("<br>"))
                 if issue.assetIdentifier not in assets:
                     update_issue["assetIdentifier"] = (
                         update_issue["assetIdentifier"] + "<br>" + issue.assetIdentifier
                     )
         else:
-            if issue.qualysId not in set(
-                [iss["qualysId"] for iss in regscale_existing_issues]
-            ):
+            if issue.qualysId not in [
+                iss["qualysId"] for iss in regscale_existing_issues
+            ]:
                 # Add
                 regscale_new_issues.append(dataclasses.asdict(issue))
     logger.info(
-        f"Posting {len(regscale_new_issues)} new issues to RegScale condensed from {len(vulns)} Qualys vulnerabilities."
+        "Posting %i new issues to RegScale condensed from %i Qualys vulnerabilities.",
+        len(regscale_new_issues),
+        len(vulns),
     )
     if len(regscale_new_issues) > 0:
         regscale_api.update_server(
-            url=app.config["domain"] + "/api/issues",
+            url=f"{config['domain']}/api/issues",
             message=f"Posting {len(regscale_new_issues)} issues..",
             json_list=regscale_new_issues,
         )
 
 
 def inner_join(reg_list: list, qualys_list: list) -> list:
     """
@@ -735,16 +793,22 @@
 
 def get_asset_groups_from_qualys() -> list:
     """
     Get all asset groups from Qualys via API
     :return: list of assets from Qualys
     :rtype: list
     """
-    response = qualys_api.get(
-        config["qualysUrl"] + "api/2.0/fo/asset/group?action=list", headers=HEADERS
+    app = check_license()
+    config = app.config
+    asset_groups = []
+
+    # set the auth for the QUALYS_API session
+    QUALYS_API.auth = (config["qualysUserName"], config["qualysPassword"])
+    response = QUALYS_API.get(
+        url=f"{config['qualysUrl']}api/2.0/fo/asset/group?action=list", headers=HEADERS
     )
     if response.ok:
         logger.debug(response.text)
         try:
             asset_groups = xmltodict.parse(response.text)["ASSET_GROUP_LIST_OUTPUT"][
                 "RESPONSE"
             ]["ASSET_GROUP_LIST"]["ASSET_GROUP"]
```

## app/internal/evidence.py

```diff
@@ -307,22 +307,25 @@
 def set_directory_variables(task) -> Tuple[str, str, str]:
     """
     Set evidence folder directory variables
     :param task: The task to update on the job_progress
     :return: Tuple[evidence folder path, directory name, new working directory]
     :rtype: Tuple[str, str, str]
     """
-    # change working directory for evidence full path
+    # set evidence folder variable to init.yaml value
     evidence_folder = app.config["evidenceFolder"]
+    # if evidence folder does not exist then create it so tests will pass
     check_file_path(evidence_folder)
+    # if evidence folder does not exist or if it is empty then error out
     if evidence_folder is None or len(os.listdir(evidence_folder)) <= 1:
         error_and_exit(
             "The directory set to evidenceFolder cannot be found or is empty."
         )
     else:
+        # otherwise change directory to the evidence folder
         os.chdir(evidence_folder)
     progress.update(task, advance=1)
     # include RegScale projects folder
     dir_name = [
         filename
         for filename in os.listdir(os.getcwd())
         if os.path.isdir(os.path.join(os.getcwd(), filename))
```

## app/public/emass.py

```diff
@@ -12,14 +12,15 @@
 from openpyxl.comments import Comment
 from openpyxl.styles import PatternFill
 
 from app.api import Api
 from app.application import Application
 from app.logz import create_logger
 from app.utils.app_utils import (
+    check_file_path,
     create_progress_object,
     error_and_exit,
     get_current_datetime,
     get_file_type,
     reformat_str_date,
 )
 from models.app_models.click import regscale_id
@@ -31,14 +32,37 @@
 
 
 @click.group()
 def emass():
     """[BETA] Performs bulk processing of eMASS files (Upload trusted data only)."""
 
 
+@emass.command("get_template")
+def get_template():
+    """
+    Fetch a template for the eMASS controls document
+    """
+    app = Application()
+    api = Api(app)
+
+    # check if the artifacts folder exists
+    check_file_path("artifacts")
+
+    # get the template from the API
+    template = api.get(
+        url="https://regscaleblob.blob.core.windows.net/blob/eMASS_Control_Template.xlsx",
+        headers={},
+    )
+
+    # write the template to a file
+    with open(f".{os.sep}artifacts{os.sep}eMASS_Template.xlsx", "wb") as f:
+        f.write(template.content)
+    logger.info(f"Template saved to .{os.sep}artifacts{os.sep}eMASS_Template.xlsx")
+
+
 @emass.command("populate_controls")
 @click.option(
     "--file_name",
     type=click.Path(exists=True, dir_okay=False, file_okay=True),
     required=True,
     prompt="Enter the full file path of the eMASS controls document.",
     help="Enter the full file path of the eMASS controls document to populate with RegScale data.",
@@ -172,15 +196,16 @@
             len(controls),
             response["controls"]["totalCount"],
             ssp_id,
             total_controls.text,
         )
     else:
         error_and_exit(
-            "The RegScale SSP provided no data. Please verify the ID and try again."
+            "The RegScale SSP provided has no assessments associated with the controls. "
+            + "Please add assessments to the controls and try again."
         )
 
     # load the Excel file in pandas to find row # to update the data
     file_data = pd.read_excel(file_name, skiprows=SKIP_ROWS - 2)
 
     # load the workbook using openpyxl to retain worksheet styling
     wb = load_workbook(file_name)
@@ -192,16 +217,17 @@
     file_data_dict = file_data.to_dict()
 
     # format the controls
     raw_controls, formatted_controls = format_controls(
         file_data_dict=file_data_dict, file_name=file_name.name
     )
 
-    # create variable to count number of rows updated
+    # create variable to count number of rows updated and skipped
     update_counter: int = 0
+    skipped_counter: int = 0
 
     # create a list of all the control ids from the GraphQL query
     regscale_control_ids = [ctrl["control"]["controlId"] for ctrl in controls]
 
     # create comment & fill attribute for columns with missing data
     comment = Comment(
         text=f"SSP #{ssp_id} doesn't contain an assessment associated with this control.",
@@ -268,14 +294,17 @@
                         height=150,
                     )
                     sheet[f"O{row_number}"].fill = yellow_fill
 
                 # update the counter
                 update_counter += 1
             else:
+                # increment the skip counter
+                skipped_counter += 1
+
                 # highlight and add a comment
                 for column in COLUMNS:
                     sheet[f"{column}{row_number}"].comment = comment
                     sheet[f"{column}{row_number}"].fill = yellow_fill
             # update the progress bar
             job_progress.update(populating_controls, advance=1)
 
@@ -289,11 +318,15 @@
         )
     )
 
     # save the updated workbook
     wb.save(output_name)
 
     logger.info(
-        "%s has been created with %s updates.", output_name.name, update_counter
+        "%s has been created with %i update(s). %i row(s) were skipped because of missing controls in SSP #%i.",
+        output_name.name,
+        update_counter,
+        skipped_counter,
+        ssp_id,
     )
     # return the output path
     return output_name
```

## app/utils/app_utils.py

```diff
@@ -1,34 +1,38 @@
 #!/usr/bin/env python3
 # -*- coding: utf-8 -*-
 """ Functions used throughout the application """
 
 # standard python imports
 import csv
-from collections import abc
 import glob
 import json
 import ntpath
 import os
+import random
 import re
 import sys
+from collections import abc
 from datetime import datetime
 from pathlib import Path
+from shutil import copytree, rmtree
+from site import getusersitepackages
 from tempfile import gettempdir
-from dateutil import relativedelta
 
 import pandas as pd
+import requests
+import xmltodict
+from dateutil import relativedelta
 from rich.progress import (
     BarColumn,
     Progress,
     SpinnerColumn,
     TextColumn,
     TimeElapsedColumn,
 )
-import requests
 
 from app.application import Application
 from app.internal.login import is_licensed
 from app.logz import create_logger
 from exceptions.license_exception import LicenseException
 
 logger = create_logger()
@@ -44,14 +48,23 @@
     if not is_licensed(app):
         raise LicenseException(
             "This feature is limited to RegScale Enterprise, please check RegScale license."
         )
     return app
 
 
+def get_site_package_location() -> Path:
+    """
+    Return site package location as string
+    :return: site package location
+    :rtype: Path
+    """
+    return Path(getusersitepackages())
+
+
 def convert_datetime_to_regscale_string(
     reg_dt: datetime, dt_format="%Y-%m-%d %H:%M:%S"
 ):
     """
     Convert a datetime object to a RegScale API friendly string
     :param datatime reg_dt: Datetime object
     :param str format): Defaults to "%Y-%m-%d %H:%M:%S".
@@ -180,14 +193,26 @@
     :rtype: list
     """
     with open(file_path, "r", newline="", encoding="utf-8") as file:
         reader = csv.reader(file)
         return list(reader)
 
 
+def copy_and_overwrite(from_path: Path, to_path: Path) -> None:
+    """
+    Copy and overwrite files recursively in a given path
+    :param Path from_path: Path to copy from
+    :param Path to_path: Path to copy to
+    :return: None
+    """
+    if os.path.exists(to_path):
+        rmtree(to_path)
+    copytree(from_path, to_path)
+
+
 def create_progress_object() -> Progress:
     """
     Function to create and return a progress object
     :return: Progress object for live progress in console
     :rtype: Progress
     """
     return Progress(
@@ -206,14 +231,34 @@
     :return: Returns string of file type
     :rtype: str
     """
     file_type = Path(file_name).suffix
     return file_type.lower()
 
 
+def xml_file_to_dict(file_path: Path) -> dict:
+    """
+    Function to convert an XML file to a dictionary
+    :param Path file_path: Path to the XML file
+    :return: Dictionary of the XML file
+    :rtype: dict
+    """
+    # create variable to store the dictionary
+    xml_dict = {}
+
+    # check if the file exists
+    if os.path.exists(file_path):
+        # file exists so open the file
+        with open(file_path, "r", encoding="utf-8") as file:
+            # store the contents of the file in the xml_dict variable
+            xml_dict = xmltodict.parse(file.read())
+    # return the xml_dict variable
+    return xml_dict
+
+
 def get_file_name(file_path: str) -> str:
     """
     Function to parse the provided file path and returns the file's name as a string
     :param str file_path: path to the file
     :return: File name
     :rtype: str
     """
@@ -304,15 +349,15 @@
     """
     Function to check the provided file path, if it doesn't exist it will be created
     :param file_path: Path to the directory
     :return: None
     """
     # see if the provided directory exists, if not create it
     if not os.path.exists(file_path):
-        os.mkdir(file_path)
+        os.makedirs(file_path)
         # notify user directory has been created
         logger.info("%s didn't exist, but has been created.", file_path)
 
 
 def capitalize_words(word: str) -> str:
     """
     Function to convert string to title case.
@@ -329,34 +374,34 @@
     :param str error_desc: Description of the error encountered
     :return: None
     """
     logger.error(error_desc)
     sys.exit(1)
 
 
-def download_file(url: str, download_path: Path = gettempdir()) -> Path:
+def download_file(url: str, download_path: str = gettempdir()) -> Path:
     """
     Download file from the provided url and save it to the provided download_path
     :param str url: URL location of the file to download
     :param Path download_path: Path to download the file to
     :return: Path to the downloaded file
     :rtype: Path
     """
-    download_path = Path(download_path)
+    path = Path(download_path)
     local_filename = url.split("/")[-1]
     # NOTE the stream=True parameter below
     with requests.get(url, stream=True, timeout=10) as response:
         response.raise_for_status()
-        with open(download_path / local_filename, "wb+") as file:
+        with open(path / local_filename, "wb+") as file:
             for chunk in response.iter_content(chunk_size=8192):
                 # If you have chunk encoded response uncomment if
                 # and set chunk_size parameter to None.
                 # if chunk:
                 file.write(chunk)
-    return download_path / local_filename
+    return path / local_filename
 
 
 def save_data_to(file_name: str, file_type: str, data, output_log: bool = True) -> None:
     """
     Function to save the provided data to the provided file_name and file_type
     :param str file_name: Desired name to save the file as
     :param str file_type: Desired file type
@@ -539,14 +584,52 @@
     # get the last entry
     split_url = split_urls[-1]
 
     # remove the remaining text from the last entry and return it
     return split_url[: split_url.find(">")]
 
 
+def random_hex_color() -> str:
+    """Return a random hex color
+
+    :return: hex color
+    :rtype: str
+    """
+    return "#%02X%02X%02X" % (
+        random.randint(0, 255),
+        random.randint(0, 255),
+        random.randint(0, 255),
+    )
+
+
+def format_data_to_html(obj, indent=1) -> str:
+    """Format a list or a dict object to HTML
+
+    :param obj: list or dict of data
+    :param indent: Indentation. Defaults to 1.
+    :return: String representing HTML
+    """
+    htmls = []
+
+    if isinstance(obj, list):
+        for key in obj:
+            htmls.append(format_data_to_html(key, indent + 1))
+
+    if isinstance(obj, dict):
+        for key, val in obj.items():
+            htmls.append(
+                f"<span style='font-style: italic; color: #888'>{key}</span>: {format_data_to_html(val, indent + 1)}"
+            )
+
+    if htmls:
+        return f'<div style="margin-left: {indent}em">{",<br>".join(htmls)}</div>'
+
+    return str(obj)
+
+
 def find_keys(node, kv):
     """
     Python generator function to traverse deeply nested lists or dictionaries to
     extract values of every key found in a given node
     :param node: A string, dict or list to parse.
     :param kv: Key, Value pair
     """
```

## app/utils/regscale_utils.py

```diff
@@ -224,17 +224,19 @@
         f"{config['domain']}/api/assets/getAllByParent/{parent_id}/{module}"
     )
     results = []
 
     response = api.get(url=regscale_assets_url)
     if response.ok:
         try:
-            results = response.json() if response.ok else []
-        except JSONDecodeError as ex:
-            error_and_exit(f"Unable to fetch assets from RegScale:\n{ex}")
+            results = response.json()
+        except JSONDecodeError:
+            logger.warning(
+                f"No assets associated with the provided ID and module: {module} #{parent_id}."
+            )
     else:
         error_and_exit(
             f"Unable to get assets from RegScale. Received:{response.status_code}\n{response.text}"
         )
     return results
```

## models/regscale_models/asset.py

```diff
@@ -1,13 +1,17 @@
 #!/usr/bin/env python3
 # -*- coding: utf-8 -*-
 """ Dataclass for a RegScale Asset """
 
 # standard python imports
 from dataclasses import asdict, dataclass
+from app.application import Application
+from app.api import Api
+from requests import Response
+from typing import Any
 
 
 @dataclass()
 class Asset:
     """Asset Model"""
 
     name: str  # Required
@@ -39,49 +43,77 @@
     wizId: str = None
     wizInfo: str = None
     facilityId: int = None
     orgId: int = None
     id: int = None
     createdById: str = None
     lastUpdatedById: str = None
+    fqdn: str = None
 
     @staticmethod
     def from_dict(obj: dict) -> "Asset":
         """
         Create Asset object from dict
         :param obj: dictionary
         :return: Asset class
         :rtype: Asset
         """
-        _osVersion = str(obj.get("operatingSystemVersion"))
-        _isPublic = bool(obj.get("isPublic"))
-        _name = str(obj.get("name"))
-        _otherTrackingNumber = str(obj.get("otherTrackingNumber"))
-        _serialNumber = str(obj.get("serialNumber"))
-        _ipAddress = str(obj.get("ipAddress"))
-        _macAddress = str(obj.get("macAddress")).upper()
-        _manufacturer = str(obj.get("manufacturer"))
-        _model = str(obj.get("model"))
-        _assetCategory = str(obj.get("assetCategory"))
-        _assetOwnerId = str(obj.get("assetOwnerId"))
-        _operatingSystem = str(obj.get("operatingSystem"))
-        _osVersion = str(obj.get("osVersion"))
-        _assetType = str(obj.get("assetType"))
-        _cmmcAssetType = str(obj.get("cmmcAssetType"))
-        _cpu = int(obj.get("cpu"))
-        _ram = int(obj.get("ram"))
-        _diskStorage = int(obj.get("diskStorage"))
-        _description = str(obj.get("description"))
-        _endOfLifeDate = str(obj.get("endOfLifeDate"))
-        _purchaseDate = str(obj.get("purchaseDate"))
-        _status = str(obj.get("status"))
-        _tenableId = str(obj.get("tenableId"))
-        _qualysId = str(obj.get("qualysId"))
-        _wizId = str(obj.get("wizId"))
-        _wizInfo = str(obj.get("wizInfo"))
+        _osVersion = (
+            str(obj.get("operatingSystemVersion"))
+            if obj.get("operatingSystemVersion")
+            else None
+        )
+        _isPublic = bool(obj.get("isPublic")) if obj.get("isPublic") else True
+        _name = str(obj.get("name")) if obj.get("name") else None
+        _otherTrackingNumber = (
+            str(obj.get("otherTrackingNumber"))
+            if obj.get("otherTrackingNumber")
+            else None
+        )
+        _serialNumber = (
+            str(obj.get("serialNumber")) if obj.get("serialNumber") else None
+        )
+        _ipAddress = str(obj.get("ipAddress")) if obj.get("ipAddress") else None
+        _macAddress = (
+            str(obj.get("macAddress")).upper() if obj.get("macAddress") else None
+        )
+        _manufacturer = (
+            str(obj.get("manufacturer")) if obj.get("manufacturer") else None
+        )
+        _model = str(obj.get("model")) if obj.get("model") else None
+        _assetCategory = (
+            str(obj.get("assetCategory")) if obj.get("assetCategory") else None
+        )
+        _assetOwnerId = (
+            str(obj.get("assetOwnerId")) if obj.get("assetOwnerId") else None
+        )
+        _operatingSystem = (
+            str(obj.get("operatingSystem")) if obj.get("operatingSystem") else None
+        )
+        _osVersion = str(obj.get("osVersion")) if obj.get("osVersion") else None
+        _assetType = str(obj.get("assetType")) if obj.get("assetType") else None
+        _cmmcAssetType = (
+            str(obj.get("cmmcAssetType")) if obj.get("cmmcAssetType") else None
+        )
+        _cpu = int(obj.get("cpu")) if obj.get("cpu") else 0
+        _ram = int(obj.get("ram")) if obj.get("ram") else 0
+        _diskStorage = int(obj.get("diskStorage")) if obj.get("diskStorage") else None
+        _description = str(obj.get("description")) if obj.get("description") else None
+        _endOfLifeDate = (
+            str(obj.get("endOfLifeDate")) if obj.get("endOfLifeDate") else None
+        )
+        _purchaseDate = (
+            str(obj.get("purchaseDate")) if obj.get("purchaseDate") else None
+        )
+        _fqdn = str(obj.get("fqdn"))
+        _status = str(obj.get("status")) if obj.get("status") else None
+        _tenableId = str(obj.get("tenableId")) if obj.get("tenableId") else None
+        _qualysId = str(obj.get("qualysId")) if obj.get("qualysId") else None
+        _wizId = str(obj.get("wizId")) if obj.get("wizId") else None
+        _wizInfo = str(obj.get("wizInfo")) if obj.get("wizInfo") else None
         if obj.get("facilityId"):
             _facilityId = int(obj.get("facilityId"))
         else:
             _facilityId = None
         if obj.get("orgId"):
             _orgId = int(obj.get("orgId"))
         else:
@@ -94,15 +126,15 @@
             _id = None
         return Asset(
             isPublic=_isPublic,
             name=_name,
             otherTrackingNumber=_otherTrackingNumber,
             serialNumber=_serialNumber,
             ipAddress=_ipAddress,
-            macAddress=_macAddress.upper(),
+            macAddress=_macAddress.upper() if _macAddress else None,
             manufacturer=_manufacturer,
             model=_model,
             assetOwnerId=_assetOwnerId,
             operatingSystem=_operatingSystem,
             osVersion=_osVersion,
             assetCategory=_assetCategory,
             assetType=_assetType,
@@ -119,24 +151,36 @@
             wizId=_wizId,
             wizInfo=_wizInfo,
             facilityId=_facilityId,
             orgId=_orgId,
             parentId=_parentId,
             parentModule=_parentModule,
             id=_id,
+            fqdn=_fqdn,
         )
 
     # 'uniqueness': 'ip, macaddress'
     # Enable object to be hashable
     def __hash__(self):
         """
         Enable object to be hashable
         :return: Hashed TenableAsset
         """
-        return hash(str(self))
+        return hash(
+            (
+                self.name,
+                self.ipAddress,
+                self.macAddress.lower() if self.macAddress else None,
+                self.assetCategory,
+                self.assetType,
+                self.fqdn,
+                self.parentId,
+                self.parentModule,
+            )
+        )
 
     def __getitem__(self, key: any) -> any:
         """
         Get attribute from Pipeline
         :param any key:
         :return: value of provided key
         :rtype: any
@@ -169,7 +213,25 @@
     def dict(self) -> dict:
         """
         Create a dictionary from the Asset dataclass
         :return: Dictionary of Asset
         :rtype: dict
         """
         return {k: v for k, v in asdict(self).items()}
+
+    @staticmethod
+    def insert_asset(
+        app: Application,
+        obj: Any,
+    ) -> Response:
+        """
+        Create an asset in RegScale via API
+        :param app: Application Instance
+        :param obj: Asset Object
+        :return: Response from RegScale after inserting the provided asset object
+        :rtype: Response
+        """
+        if isinstance(obj, Asset):
+            obj = asdict(obj)
+        api = Api(app)
+        res = api.post(url=app.config["domain"] + "/api/assets", json=obj)
+        return res
```

## models/regscale_models/components.py

```diff
@@ -1,13 +1,15 @@
 #!/usr/bin/env python3
 # -*- coding: utf-8 -*-
 """ Dataclass for a RegScale Component """
 
 # standard python imports
 from dataclasses import dataclass
+from app.application import Application
+from app.api import Api
 
 
 @dataclass
 class Component:
     """Component Model"""
 
     title: str
@@ -33,17 +35,34 @@
     def __getitem__(self, key: any) -> any:
         """
         Get attribute from Pipeline
         :param any key:
         :return: value of provided key
         :rtype: any
         """
+        if getattr(self, key) == "None":
+            return None
         return getattr(self, key)
 
     def __setitem__(self, key: any, value: any) -> None:
         """
         Set attribute in Pipeline with provided key
         :param any key: Key to change to provided value
         :param any value: New value for provided Key
         :return: None
         """
         return setattr(self, key, value)
+
+    @staticmethod
+    def get_components_from_ssp(app: Application, ssp_id: int) -> list[dict]:
+        """Get all components for a given SSP
+
+        :param app: Application instance
+        :param ssp_id: RegScale SSP
+        :return: List of component dictionaries
+        """
+        api = Api(app)
+        existing_res = api.get(
+            app.config["domain"] + f"/api/components/getAllByParent/{ssp_id}"
+        )
+        if not existing_res.raise_for_status():
+            return existing_res.json()
```

## models/regscale_models/control_implementation.py

```diff
@@ -1,13 +1,13 @@
 #!/usr/bin/env python3
 # -*- coding: utf-8 -*-
 """ Dataclass for a RegScale Security Control Implementation """
 
 # standard python imports
-from dataclasses import dataclass, asdict
+from dataclasses import dataclass, field, asdict
 from typing import Any
 
 
 @dataclass
 class Control:
     """Control Model"""
 
@@ -35,28 +35,28 @@
     def from_dict(obj: Any) -> "Control":
         """
         Create RegScale Control from dictionary
         :param obj: dictionary
         :return: Control class
         :rtype: Control
         """
-        _id = int(obj.get("id"))
+        _id = int(obj.get("id", 0))
         _isPublic = bool(obj.get("isPublic"))
         _uuid = str(obj.get("uuid"))
         _controlId = str(obj.get("controlId"))
         _sortId = str(obj.get("sortId"))
         _controlType = str(obj.get("controlType"))
         _title = str(obj.get("title"))
         _description = str(obj.get("description"))
         _references = str(obj.get("references"))
         _relatedControls = str(obj.get("relatedControls"))
         _subControls = str(obj.get("subControls"))
         _enhancements = str(obj.get("enhancements"))
         _family = str(obj.get("family"))
-        _weight = int(obj.get("weight"))
+        _weight = int(obj.get("weight", 0))
         _catalogueID = int(obj.get("catalogueID"))
         _archived = bool(obj.get("archived"))
         _lastUpdatedById = str(obj.get("lastUpdatedById"))
         _dateLastUpdated = str(obj.get("dateLastUpdated"))
         _tenantsId = int(obj.get("tenantsId"))
         return Control(
             _id,
@@ -85,24 +85,23 @@
         Create a dictionary from the Control dataclass
         :return: Dictionary of Control
         :rtype: dict
         """
         return dict(asdict(self).items())
 
 
-@dataclass
+@dataclass(unsafe_hash=True)
 class ControlImplementation:
     """Security Control Implementation model"""
 
-    parentId: int  # Required
-    parentModule: str  # Required
+    parentId: int = field(hash=True)  # Required
+    parentModule: str = field(hash=True)  # Required
     controlOwnerId: str  # Required
-    status: str  # Required
-    controlID: int = None  # Required
-
+    status: str = field(hash=True)  # Required
+    controlID: int = field(hash=True)  # Required
     control: Control = None
     id: int = None
     createdById: str = None
     uuid: str = None
     policy: str = None
     implementation: str = None
     dateLastAssessed: str = None
@@ -140,55 +139,111 @@
     def from_dict(obj: Any) -> "ControlImplementation":
         """
         Create RegScale Security Control Implementation from dictionary
         :param obj: dictionary
         :return: ControlImplementation class
         :rtype: ControlImplementation
         """
-        _id = int(obj.get("id"))
-        _uuid = str(obj.get("uuid"))
+        _id = int(obj.get("id")) if obj.get("id") else None
+        _uuid = str(obj.get("uuid")) if obj.get("uuid") else None
         _control = Control.from_dict(obj.get("control"))
-        _isPublic = bool(obj.get("isPublic"))
-        _inheritable = bool(obj.get("inheritable"))
-        _controlOwnerId = str(obj.get("controlOwnerId"))
-        _policy = str(obj.get("policy"))
-        _implementation = str(obj.get("implementation"))
-        _status = str(obj.get("status"))
-        _dateLastAssessed = str(obj.get("dateLastAssessed"))
-        _lastAssessmentResult = str(obj.get("lastAssessmentResult"))
-        _controlID = int(obj.get("controlID"))
-        _practiceLevel = str(obj.get("practiceLevel"))
-        _processLevel = str(obj.get("processLevel"))
-        _cyberFunction = str(obj.get("cyberFunction"))
-        _implementationType = str(obj.get("implementationType"))
-        _implementationMethod = str(obj.get("implementationMethod"))
-        _qdWellDesigned = str(obj.get("qdWellDesigned"))
-        _qdProcedures = str(obj.get("qdProcedures"))
-        _qdSegregation = str(obj.get("qdSegregation"))
-        _qdFlowdown = str(obj.get("qdFlowdown"))
-        _qdAutomated = str(obj.get("qdAutomated"))
-        _qdOverall = str(obj.get("qdOverall"))
-        _qiResources = str(obj.get("qiResources"))
-        _qiMaturity = str(obj.get("qiMaturity"))
-        _qiReporting = str(obj.get("qiReporting"))
-        _qiVendorCompliance = str(obj.get("qiVendorCompliance"))
-        _qiIssues = str(obj.get("qiIssues"))
-        _qiOverall = str(obj.get("qiOverall"))
-        _responsibility = str(obj.get("responsibility"))
-        _inheritedControlId = int(obj.get("inheritedControlId"))
-        _inheritedRequirementId = int(obj.get("inheritedRequirementId"))
-        _inheritedSecurityPlanId = int(obj.get("inheritedSecurityPlanId"))
-        _inheritedPolicyId = int(obj.get("inheritedPolicyId"))
-        _parentId = int(obj.get("parentId"))
-        _parentModule = str(obj.get("parentModule"))
-        _createdById = str(obj.get("createdById"))
-        _dateCreated = str(obj.get("dateCreated"))
-        _lastUpdatedById = str(obj.get("lastUpdatedById"))
-        _dateLastUpdated = str(obj.get("dateLastUpdated"))
-        _weight = int(obj.get("weight"))
+        _isPublic = bool(obj.get("isPublic")) if obj.get("isPublic") else None
+        _inheritable = bool(obj.get("inheritable")) if obj.get("inheritable") else None
+        _controlOwnerId = (
+            str(obj.get("controlOwnerId")) if obj.get("controlOwnerId") else None
+        )
+        _policy = str(obj.get("policy")) if obj.get("policy") else None
+        _implementation = (
+            str(obj.get("implementation")) if obj.get("implementation") else None
+        )
+        _status = str(obj.get("status")) if obj.get("status") else None
+        _dateLastAssessed = (
+            str(obj.get("dateLastAssessed")) if obj.get("dateLastAssessed") else None
+        )
+        _lastAssessmentResult = (
+            str(obj.get("lastAssessmentResult"))
+            if obj.get("lastAssessmentResult")
+            else None
+        )
+        _controlID = int(obj.get("controlID")) if obj.get("controlID") else None
+        _practiceLevel = (
+            str(obj.get("practiceLevel")) if obj.get("practiceLevel") else None
+        )
+        _processLevel = (
+            str(obj.get("processLevel")) if obj.get("processLevel") else None
+        )
+        _cyberFunction = (
+            str(obj.get("cyberFunction")) if obj.get("cyberFunction") else None
+        )
+        _implementationType = (
+            str(obj.get("implementationType"))
+            if obj.get("implementationType")
+            else None
+        )
+        _implementationMethod = (
+            str(obj.get("implementationMethod"))
+            if obj.get("implementationMethod")
+            else None
+        )
+        _qdWellDesigned = (
+            str(obj.get("qdWellDesigned")) if obj.get("qdWellDesigned") else None
+        )
+        _qdProcedures = (
+            str(obj.get("qdProcedures")) if obj.get("qdProcedures") else None
+        )
+        _qdSegregation = (
+            str(obj.get("qdSegregation")) if obj.get("qdSegregation") else None
+        )
+        _qdFlowdown = str(obj.get("qdFlowdown")) if obj.get("qdFlowdown") else None
+        _qdAutomated = str(obj.get("qdAutomated")) if obj.get("qdAutomated") else None
+        _qdOverall = str(obj.get("qdOverall")) if obj.get("qdOverall") else None
+        _qiResources = str(obj.get("qiResources")) if obj.get("qiResources") else None
+        _qiMaturity = str(obj.get("qiMaturity")) if obj.get("qiMaturity") else None
+        _qiReporting = str(obj.get("qiReporting")) if obj.get("qiReporting") else None
+        _qiVendorCompliance = (
+            str(obj.get("qiVendorCompliance"))
+            if obj.get("qiVendorCompliance")
+            else None
+        )
+        _qiIssues = str(obj.get("qiIssues")) if obj.get("qiIssues") else None
+        _qiOverall = str(obj.get("qiOverall")) if obj.get("qiOverall") else None
+        _responsibility = (
+            str(obj.get("responsibility")) if obj.get("responsibility") else None
+        )
+        _inheritedControlId = (
+            int(obj.get("inheritedControlId"))
+            if obj.get("inheritedControlId")
+            else None
+        )
+        _inheritedRequirementId = (
+            int(obj.get("inheritedRequirementId"))
+            if obj.get("inheritedRequirementId")
+            else None
+        )
+        _inheritedSecurityPlanId = (
+            int(obj.get("inheritedSecurityPlanId"))
+            if obj.get("inheritedSecurityPlanId")
+            else None
+        )
+        _inheritedPolicyId = (
+            int(obj.get("inheritedPolicyId")) if obj.get("inheritedPolicyId") else None
+        )
+        _parentId = int(obj.get("parentId")) if obj.get("parentId") else None
+        _parentModule = (
+            str(obj.get("parentModule")) if obj.get("parentModule") else None
+        )
+        _createdById = str(obj.get("createdById")) if obj.get("createdById") else None
+        _dateCreated = str(obj.get("dateCreated")) if obj.get("dateCreated") else None
+        _lastUpdatedById = (
+            str(obj.get("lastUpdatedById")) if obj.get("lastUpdatedById") else None
+        )
+        _dateLastUpdated = (
+            str(obj.get("dateLastUpdated")) if obj.get("dateLastUpdated") else None
+        )
+        _weight = int(obj.get("weight")) if obj.get("weight") else None
         return ControlImplementation(
             _id,
             _uuid,
             _control,
             _isPublic,
             _inheritable,
             _controlOwnerId,
```

## models/regscale_models/threat.py

```diff
@@ -19,14 +19,15 @@
     vulnerabilityAnalysis: str
     mitigations: str
     dateCreated: str
     uuid: str = None
     id: int = None
     investigationResults: str = ""
     notes: str = ""
+    organization: str = ""
     status: str = "Under Investigation"
     source: str = "Open Source"
 
     def __getitem__(self, key: any) -> any:
         """
         Get attribute from Pipeline
         :param any key:
```

## tests/test_emass.py

```diff
@@ -12,14 +12,15 @@
 from app.internal.login import login
 from app.logz import create_logger
 from app.public.emass import populate_controls, SKIP_ROWS
 
 sys.path.append("..")  # Adds higher directory to python modules path.
 TEMPLATE_WORKBOOK = ""
 OUTPUT_WORKBOOK = Path()
+SSP_ID = 360
 
 
 class Test_Emass:
     """eMASS Test Class"""
 
     logger = create_logger()
 
@@ -54,15 +55,15 @@
         self.logger.debug(os.getenv("REGSCALE_USER"))
         self.logger.debug(os.getenv("REGSCALE_PASSWORD"))
         # Get fresh token
         login(os.getenv("REGSCALE_USER"), os.getenv("REGSCALE_PASSWORD"), app=app)
 
         # populate the controls in the Excel workbook
         output_name = populate_controls(
-            file_name=Path(TEMPLATE_WORKBOOK), ssp_id=331, api=api
+            file_name=Path(TEMPLATE_WORKBOOK), ssp_id=SSP_ID, api=api
         )
         self.logger.debug(output_name.name)
         global OUTPUT_WORKBOOK
         OUTPUT_WORKBOOK = output_name
 
     def test_values(self):
         """Check output for populated data"""
```

## tests/test_evidence.py

```diff
@@ -1,40 +1,56 @@
 #!/usr/bin/env python3
 # -*- coding: utf-8 -*-
 
 """standard imports"""
-import os
 import json
+import os
 import random
-import fitz
 from datetime import datetime, timedelta
+from pathlib import Path
+
+import fitz
+
 from app.api import Api
 from app.application import Application
 from app.logz import create_logger
-
+from app.utils.app_utils import check_file_path
 
 # create logger function to log errors
 logger = create_logger()
 
 # set environment and application configuration
 app = Application()
 api = Api(app)
 config = {}
 try:
     # load the config from YAML
     config = app.load_config()
 except FileNotFoundError:
     logger.error("ERROR: No init.yaml file or permission error when opening file.")
+EVIDENCE_FOLDER = ""
 
 
 class TestEvidence:
     """
     Tests for evidence.py
     """
 
+    def test_init(self):
+        """
+        Figure out current working directory and set EVIDENCE_FOLDER accordingly
+        """
+        global EVIDENCE_FOLDER
+        cur_dir = Path(os.getcwd())
+        if cur_dir.stem.lower() == "tests":
+            EVIDENCE_FOLDER = f'.{app.config["evidenceFolder"]}'
+        else:
+            EVIDENCE_FOLDER = app.config["evidenceFolder"]
+        check_file_path(EVIDENCE_FOLDER)
+
     def test_remove(self):
         """
         Test item removal
         """
         # create test list
         test_list = [".test1.csv", ".test2.docx", ".test3.pdf"]
         # copy list for removal
@@ -108,43 +124,39 @@
         # assert number one of the values below
         assert number in [-1, 0, 1, 3]
 
     def test_set_directory_variables(self):
         """
         Test setting evidence folder directory variables
         """
-
-        # change working directory for evidence full path
-        evidence_folder = app.config["evidenceFolder"]
         dir_name = [
             filename
-            for filename in os.listdir(evidence_folder)
-            if os.path.isdir(os.path.join(evidence_folder, filename))
+            for filename in os.listdir(EVIDENCE_FOLDER)
+            if os.path.isdir(os.path.join(EVIDENCE_FOLDER, filename))
         ][0]
         # pick up subdirectory under the evidence folder
-        new_cwd = evidence_folder + os.sep + dir_name
-        assert isinstance(evidence_folder, str)
-        assert len(evidence_folder) > 0
+        new_cwd = EVIDENCE_FOLDER + os.sep + dir_name
+        assert isinstance(EVIDENCE_FOLDER, str)
+        assert len(EVIDENCE_FOLDER) > 0
         assert isinstance(dir_name, str)
         assert len(dir_name) > 0
         assert isinstance(new_cwd, str)
         assert len(new_cwd) > 0
 
     def test_parse_required_docs(self):
         """
         Test building a list of the required documents from config.json
         """
         # create an empty list to hold a list of all document requirements for the assessment
         required_docs = []
         # create an empty list to hold a list of all required documents
         document_list = set()
         # open app//evidence//config.json file and read contents
-        evidence_folder = app.config["evidenceFolder"]
         with open(
-            evidence_folder + os.sep + "config.json", "r", encoding="utf-8"
+            f"{EVIDENCE_FOLDER}{os.sep}config.json", "r", encoding="utf-8"
         ) as json_file:
             # load json object into a readable dictionary
             rules = json.load(json_file)
             # loop through required document dicts
             for i in range(len(rules["required-documents"])):
                 # add to a list of dictionaries for parsing
                 required_docs.append(
@@ -179,23 +191,23 @@
     def test_get_doc_timestamps(self):
         """
         Test geting document timestamps
         """
         # extract directory name from evidence folder
         dir_name = [
             filename
-            for filename in os.listdir(app.config["evidenceFolder"])
-            if os.path.isdir(os.path.join(app.config["evidenceFolder"], filename))
+            for filename in os.listdir(EVIDENCE_FOLDER)
+            if os.path.isdir(os.path.join(EVIDENCE_FOLDER, filename))
         ][0]
         # set evidence folder directory location
-        evidence_folder = app.config["evidenceFolder"] + os.sep + dir_name
+        local_evidence_folder = f"{EVIDENCE_FOLDER}{os.sep}{dir_name}"
         # create empty list to hold file modified times
         modified_times = []
         # get list of folders in parent folder
-        folders_list = os.listdir(evidence_folder)
+        folders_list = os.listdir(local_evidence_folder)
 
         # remove any child folders that start with '.'
         def remove(list_to_review):
             """Remove items that start with "." """
             copy_list = list_to_review.copy()
             # loop through folder/file list
             for item in list_to_review:
@@ -206,28 +218,26 @@
             return copy_list
 
         # remove folders that start with "."
         new_folders = remove(list_to_review=folders_list)
         # loop through directory listing
         for folder in new_folders:
             # get list of files in each folder
-            filelist = os.listdir(os.path.join(evidence_folder, folder))
+            filelist = os.listdir(os.path.join(local_evidence_folder, folder))
             # remove any files that start with '.'
             newlist = remove(list_to_review=filelist)
             # loop through list of files in each folder
             for filename in newlist:
                 # append the modified time for each file to the list
                 modified_times.append(
                     {
                         "program": folder,
                         "file": filename,
                         "last-modified": os.path.getmtime(
-                            os.path.join(
-                                app.config["evidenceFolder"], dir_name, folder, filename
-                            )
+                            os.path.join(EVIDENCE_FOLDER, dir_name, folder, filename)
                         ),
                     }
                 )
 
         # loop through the list of timestamps
         def delta(time):
             """
@@ -260,24 +270,23 @@
         # assert the length of modified_times is equal to count of files
         assert len(modified_times) == counter
 
     def test_set_required_texts(self):
         """
         Parse config.json file and build a list of the required texts for the assessment
         """
-        evidence_folder = app.config["evidenceFolder"]
         # create an empty set to hold all unique required texts for the assessment
         required_text = set()
         # create an empty list to hold all texts in the file
         all_texts = []
         # create an empty list to hold the unique texts in the file
         unique_texts = []
         # open app//evidence//config.json file and read contents
         with open(
-            evidence_folder + os.sep + "config.json", "r", encoding="utf-8"
+            f"{EVIDENCE_FOLDER}{os.sep}config.json", "r", encoding="utf-8"
         ) as json_file:
             # load json object into a readable dictionary
             rules = json.load(json_file)
             # create iterator to traverse dictionary
             for i in range(len(rules["rules-engine"])):
                 # pull out required text to look for from config
                 for items in rules["rules-engine"][i]["text-to-find"]:
@@ -295,30 +304,30 @@
         # assert required_text is a set
         assert isinstance(required_text, set)
         # assert length of set of unique values matches length list of unique values
         assert len(required_text) == len(unique_texts)
         # assert contents of required text are equal to contents of unique texts
         assert required_text == set(unique_texts)
 
-    def test_find_required_files_in_folder(evidence_folder: str):
+    def test_find_required_files_in_folder(self):
         """
         Pull out required files from each directory for parsing
         """
         # create directory name
         dir_name = [
             filename
-            for filename in os.listdir(app.config["evidenceFolder"])
-            if os.path.isdir(os.path.join(app.config["evidenceFolder"], filename))
+            for filename in os.listdir(EVIDENCE_FOLDER)
+            if os.path.isdir(os.path.join(EVIDENCE_FOLDER, filename))
         ][0]
         # create evidence folder
-        evidence_folder = app.config["evidenceFolder"] + os.sep + dir_name
+        local_evidence_folder = f"{EVIDENCE_FOLDER}{os.sep}{dir_name}"
         # create empty list to hold list of files in directory
         dir_list = []
         # build a list of all folders to iterate through
-        folder_list = os.listdir(evidence_folder)
+        folder_list = os.listdir(local_evidence_folder)
 
         # remove any folders starting with '.' from list
         def remove(list_to_review):
             """Remove items that start with "." """
             copy_list = list_to_review.copy()
             # loop through folder/file list
             for item in list_to_review:
@@ -326,16 +335,16 @@
                 if item.startswith("."):
                     # remove the item from the list
                     copy_list.remove(item)
             return copy_list
 
         new_folders = remove(folder_list)
         for folder in new_folders:
-            # build a list of all files contained in sub-directories
-            filelist = os.listdir(evidence_folder + os.sep + folder)
+            # build a list of all files contained in subdirectories
+            filelist = os.listdir(local_evidence_folder + os.sep + folder)
             # remove folders and file names that start with a .
             newlist = remove(filelist)
             for filename in newlist:
                 dir_list.append({"program": folder, "file": filename})
                 # set counter to 0 for matching entry counts
         counter = 0
         # loop through each folder
@@ -344,11 +353,7 @@
             for files in newlist:
                 # increment counter by 1
                 counter += 1
         # assert dir_list is a list
         assert isinstance(dir_list, list)
         # assert the length of dir_list is equal to count of all files in each folder
         assert len(dir_list) == counter
-
-
-T = TestEvidence()
-T.test_find_required_files_in_folder()
```

## Comparing `RegScale_CLI-4.25.0.dist-info/LICENSE` & `RegScale_CLI-4.25.1.dist-info/LICENSE`

 * *Files identical despite different names*

## Comparing `RegScale_CLI-4.25.0.dist-info/METADATA` & `RegScale_CLI-4.25.1.dist-info/METADATA`

 * *Files 0% similar despite different names*

```diff
@@ -1,10 +1,10 @@
 Metadata-Version: 2.1
 Name: RegScale-CLI
-Version: 4.25.0
+Version: 4.25.1
 Summary: Command Line Interface (CLI) for bulk processing/loading data into RegScale
 Home-page: https://github.com/RegScale/regscale-cli
 Author: Travis Howerton
 Author-email: thowerton@regscale.com
 License: MIT
 Platform: UNKNOWN
 Classifier: Operating System :: OS Independent
```

## Comparing `RegScale_CLI-4.25.0.dist-info/RECORD` & `RegScale_CLI-4.25.1.dist-info/RECORD`

 * *Files 5% similar despite different names*

```diff
@@ -1,42 +1,43 @@
-regscale.py,sha256=gWnFlYcCWnoIHk0p5pX5Yf7ECiux2qeFoES1G_3LhWg,14547
+regscale.py,sha256=-QqDONm-p2MqbrqH6HMYbMt6FS9d7-KZOnZAjiDJHVY,14485
 app/__init__.py,sha256=gbUXYeGrcrqcOc70BjFtxHtBnwSqor-SlWYgZjypEOA,47
-app/_version.py,sha256=uEkWyTCTIko4OLjvojEvKqYA_3SQyM6CoLwk6dNKrtk,73
-app/api.py,sha256=RMqoyJNX3HhwkXBCHhjVLbW159Z8svhX2OvUolMrR5o,14197
+app/_version.py,sha256=7rL0JrwSTgN8NJAeI_9_-UTloDwa79yBvaJPuK8a1sM,73
+app/api.py,sha256=yezBIkGP5y-CKO-7b0f00T_q5l8-Kyaw1kXHVQ8Ee_U,14497
 app/application.py,sha256=Qj9VzhImSvAoBCJQI5SMT-vVn_4Rxfsk4POQNDsh_j0,13397
 app/logz.py,sha256=p7ADwGAkz75cey8CS6XdsS--jp9WnFRZANm02ZhtFAk,1287
 app/commercial/__init__.py,sha256=47DEQpj8HBSa-_TImW-5JCeuQeRkm5NMpJWZG3hSuFU,0
 app/commercial/ad.py,sha256=CTt7F5mNznZGHJkgEK5zSCozmP858gqJyVti1ogkh98,16359
 app/commercial/defender.py,sha256=Crt8VKp3BRZvqMz_irfZ9cOAPEMs5kXkKYmchG-q1zs,45796
 app/commercial/jira.py,sha256=bqdbbp79JN6GBL5mfAg-sHEfwWyzTlobLYPw7bCUhko,8007
 app/commercial/okta.py,sha256=P0iJ59akglkEU0EhvSILnVT799VTMkDtlQi1Tl_u3TE,27240
-app/commercial/qualys.py,sha256=J0JzKhgH073kXNdHThRxIugzFTXS0A8_CMA5OenBpGU,27892
+app/commercial/qualys.py,sha256=IPhxBjOp8FvI4ebM4Xwdpl5ef7UJ8y2eefgzQ-zE_kY,29595
 app/commercial/servicenow.py,sha256=nzQVHzdw02UpJDtxI850pCwipPUCGA19ijg8bi_WJUE,11689
+app/commercial/stig.py,sha256=I9RjHqgpNiiXtkSwTqAcz7Cxw4nMiIzJ3FxgSLVJDaM,62786
 app/commercial/tenable.py,sha256=NeoG2BCagPD5s8A78xf8kED6Wmu076AmmrPW8bVB-Xc,22634
 app/commercial/wiz.py,sha256=P5wInsQ7HvyltQW_KccT113IkmGCRK9e_TujJi5FALk,56457
 app/internal/__init__.py,sha256=47DEQpj8HBSa-_TImW-5JCeuQeRkm5NMpJWZG3hSuFU,0
 app/internal/admin_actions.py,sha256=Ry1x_dmM2odXmVZpBB3R3Wgs8bj3qCC4acsTA-Pel8A,26998
 app/internal/assessments_editor.py,sha256=boaP7PTNFO831WLuDP3o5cRXT6P7H6g9Wt3WJWYDE_I,31042
 app/internal/comparison.py,sha256=F4VcAUpxzBctouUVHq_9cC_VC46qkNxtDZs93Lc45tw,16114
 app/internal/control_editor.py,sha256=eTb8p_JJS7g64zj9wqMXnHZh6OynfAHYzzox7P4N6nY,15277
 app/internal/encrypt.py,sha256=UTs3mwTxackgYhr357npx6rqXz7X2gMJ9mTaQ5hBsKw,5912
-app/internal/evidence.py,sha256=YcHmS7wktfZbOXlQIYsW_blYdW5UGqSiRcPBZLyEqO0,39915
+app/internal/evidence.py,sha256=94ew7Vg-FeYm4q7RUha8S4vk3Ky-Hnpmc-qVIsrLwLQ,40122
 app/internal/healthcheck.py,sha256=K6NNvgKucBl1Kg5GO-XiENfISQXk331t-KzhIHSPlPE,2325
 app/internal/login.py,sha256=vk5VwrCQU18Al-nayPQaNin5lbXEx4jiQFmyizecQ08,6397
 app/internal/migrations.py,sha256=4s_QoBJPDrHI9jMvYMZVady4GbEbGMlEK41hrhsA-iw,9419
 app/public/__init__.py,sha256=47DEQpj8HBSa-_TImW-5JCeuQeRkm5NMpJWZG3hSuFU,0
 app/public/cisa.py,sha256=ON5phwcGZYqOFk-JlkVvca_K5E9H0C6EXyN1rwjaC74,18601
-app/public/emass.py,sha256=69jEKyQGJc8f8ZZAcLRta7o1FR2sqUyQksRoa6k46XA,10193
+app/public/emass.py,sha256=Jm5B_1Sw3g7vEAVGnioWK4UclCALjVLWR5TTP2F3Ovw,11186
 app/public/fedramp.py,sha256=n_B4AqYk4vXHt3TIf8zgVJShEYb4gINxFwUSRFeOpSk,63918
 app/public/nist_catalog.py,sha256=MnGyJ1hNvqnfrBjtUkTIBYlV0oeQsQYpp1hZ7Y7IPZE,7946
 app/public/oscal.py,sha256=1fn5USWnq3LN-E5w0WpIlbOvFEyVY73PuYpTs5GBF9k,71111
 app/public/otx.py,sha256=Q_4BnAKpij6lGC_I71uT5ruarP4laWF20Z4zGBXo8-U,6081
 app/utils/__init__.py,sha256=47DEQpj8HBSa-_TImW-5JCeuQeRkm5NMpJWZG3hSuFU,0
-app/utils/app_utils.py,sha256=qboD1GMvX2ma5tFggVrDxKPqNf0osOJVj-7J5mfnxhk,19408
-app/utils/regscale_utils.py,sha256=wJZ97v3Qf39SGx2LsdHgbiiwYE4LueoeH2q8ycgiZS4,10375
+app/utils/app_utils.py,sha256=ZfsEN9GoJhlQbIzlpFw9x9333CO0lX7uI5BG25t6k10,21592
+app/utils/regscale_utils.py,sha256=zGj9J7oxfgbONkktSNh2QO0ZFcS90AeqdN6xe4qCW0Q,10409
 app/utils/threadhandler.py,sha256=XcKXSYSQeJla1Vd5RPryt4f5yW_-P4kXIEmw_JuF3Z8,1591
 exceptions/__init__.py,sha256=47DEQpj8HBSa-_TImW-5JCeuQeRkm5NMpJWZG3hSuFU,0
 exceptions/license_exception.py,sha256=5lDYW1uGf7dHFKBkhzYD3FlNnI6W4BICXi24OJyOs_w,195
 models/__init__.py,sha256=GLPPGTA5Lczf4OWUnudaFTG4OV2Hqt6IjZymYO6HL04,79
 models/app_models/__init__.py,sha256=47DEQpj8HBSa-_TImW-5JCeuQeRkm5NMpJWZG3hSuFU,0
 models/app_models/click.py,sha256=o2eu7-AZFBQtdCb1USHYmq7DKYMyh01Tx3q-oYpDhBA,3997
 models/app_models/control_editor.py,sha256=F0Ky7As96UvUBu-W_WfDoObJBfs94t-w3zcFdTslT-Q,13863
@@ -44,40 +45,48 @@
 models/integration_models/__init__.py,sha256=47DEQpj8HBSa-_TImW-5JCeuQeRkm5NMpJWZG3hSuFU,0
 models/integration_models/azure_alerts.py,sha256=I_jcjaLMsQpgabkdtVbalGZ23GeAH8aQCmH9iXlKFhw,7858
 models/integration_models/recommendations.py,sha256=T_zyM1G4xFsZgApVvz8CGUMYuZLzfXLgoAcXsz1xUKE,872
 models/integration_models/tenable.py,sha256=ssbs0p5VNqWBvQSwDqNchVHQOxhzblnd1F_Zjf9NAJ8,8319
 models/integration_models/wiz.py,sha256=BqHeFvHtft7Ona8Gz1p9_JctxHjdJi0KlrDJ83Ub5g4,1833
 models/regscale_models/__init__.py,sha256=47DEQpj8HBSa-_TImW-5JCeuQeRkm5NMpJWZG3hSuFU,0
 models/regscale_models/assessment.py,sha256=bH9Wa08CfCv1Kwq_rDgJg6xvn9IPXxlmGGuvXq9R2qo,6688
-models/regscale_models/asset.py,sha256=yQm9Wm3q6J0fZ-XsSsrNjfcnDQYkznwom2sBtl2BKEw,5433
-models/regscale_models/components.py,sha256=AcUOAey-FTUFx6DJ1-1oMHgE2H7rhKE2z8QQqjPjR5w,1237
-models/regscale_models/control_implementation.py,sha256=cjKdRzMNVGQFRE94REzucDtjCmubP3nw_-Jhzha97_8,7805
+models/regscale_models/asset.py,sha256=VKz5ryCiIKdzorREB_0AoQVPYD4uBjzybWv-JVyPco0,7726
+models/regscale_models/checklist.py,sha256=6O6IoUoA0FUVPXubiS7WrF8bX64wnNooFxyjj_DIuYI,4327
+models/regscale_models/components.py,sha256=CeaZPkQaF4wwh029feCEXyRRW_JBszwrg5FyqyYn1Qs,1877
+models/regscale_models/control_implementation.py,sha256=3F6W9GP3iOGWIc4oSDj90_VPmqX_7TTmEeg7All_EPo,10070
+models/regscale_models/control_objective.py,sha256=s29H5qHQQf3yx3XpCOjB0g_ST-WybpKpRFWzUlMRPDw,1441
+models/regscale_models/implementation_objective.py,sha256=4kH8LNhusvwQBuuCVHqnOTiebgWOgVhuAYzQ67pLRVA,6294
+models/regscale_models/implementation_option.py,sha256=msHRYWn2hwQ1VNVx4v06tHhWwc57cx-9lYfRgaJl8Tk,2981
 models/regscale_models/interconnects.py,sha256=Amv3CSrurRwDOaLBiqioLNWlmhAqcq6Pbsm8ekv1Yk8,2850
 models/regscale_models/issue.py,sha256=veNXQW_hkx4_3_opiSaIE6_kuUoVR92WbB6SBCCjc9U,4175
 models/regscale_models/modules.py,sha256=Gdjv4CAOrUNeOHI7NKJ84MlpVX8hwOd-bhujJQ1pgEI,4878
+models/regscale_models/objective.py,sha256=-qwNIEyAN2st1MzANxgQDysSiqspRGRwjdW6wlhtL9I,232
 models/regscale_models/ports_protocols.py,sha256=qupVuXfeNXxMBW8EviLDgtBJc3id9YvxfcJibHpjojo,2353
 models/regscale_models/requirements.py,sha256=msCh2iZD9YujpJO5yakfRRKebd1KE_wmbQIFe-iJbHQ,2415
 models/regscale_models/securityplans.py,sha256=93qb92V2W_hOf2hOhLLw7J087LngCgzo91Zzg9gQ1S8,5886
-models/regscale_models/threat.py,sha256=Qt4mhCEgcWbAQ70DUXZ0MoVVCbbKXN8MSGWChxoua7U,1398
+models/regscale_models/stig.py,sha256=DUS5SUpaI-0bPuP2b_mXsYWordxHCnAqYGrdcrANdVY,25813
+models/regscale_models/threat.py,sha256=eRO_tPT4pOTJvMGYAQ9bU7QHs2HnFBLiIWY8Jyu1pQk,1425
 models/regscale_models/user.py,sha256=mm-1ajFmCFzDeHDAydcANdQMIBehfCRhjWCCoMKZXFY,2242
 tests/__init__.py,sha256=47DEQpj8HBSa-_TImW-5JCeuQeRkm5NMpJWZG3hSuFU,0
 tests/conftest.py,sha256=7Ba9a9CreEyUJJbxXolUQnHuOt3lrI-lnsOch8N390I,1818
+tests/mock_api_service.py,sha256=52ih6mY0II1e7z-e3JxK0sQF6WTwa2MnObgL3WcoTxs,368
 tests/test_app_utils.py,sha256=CP8ZQVCVdTRKy97QICKc4_4cHWQYQPd9KZw4vivAAWY,1334
 tests/test_assessments_editor.py,sha256=JK-ap6JVnF3SABLLkKvy-OPRi8sPkcjwhbz0yjxns3Y,1930
 tests/test_cisa.py,sha256=2tpRm-hB-bYl01lif8UNwhJETFuRm_R0UQBC3SCfcwk,1687
 tests/test_control_editor.py,sha256=kad6vmaeeNmkUWp1uETRsGPDsF1TeMFjxfln2lZJPlY,1747
 tests/test_dependabot.py,sha256=tTQZnikbzxW7v5LAMucZbDHQuwnM3UttZ8KLXl3KMts,1425
-tests/test_emass.py,sha256=1N-XgKBP3IjrW76XkiulqSsEO1EOeGKsIYmmWtiE4aw,2811
-tests/test_evidence.py,sha256=B8yap4uMxhjPLm1cmIUNDGfU3GJd-VGziKpfnWCny0o,14035
+tests/test_emass.py,sha256=2-w7c77ZDzkLKiGBjmUejdjrddLounVTbr7iPqlKhVc,2827
+tests/test_evidence.py,sha256=q4KwOyiJ3NLsoedifYa3Tcg4_cggKkozftwVdz3IbxU,14137
 tests/test_login.py,sha256=u_LPs_H_g8ubARUKHdvPZl3flt2SHEjwFjmWuPnZYLU,1186
 tests/test_npm_audit.py,sha256=XdF0FM8telb2nzhVUc0gT4Zu7Srq3GiJheJFKSWICnk,1416
 tests/test_oscal.py,sha256=Lcm1f0hTr6Iwu5LGU-sKSC55bBsQVm2WX_zeiPBAdbA,9248
 tests/test_snow.py,sha256=tPdi-gWE_kmiv_dZV50T3vV6OB9vgbHr_jBGUi4hCaw,866
 tests/test_sonarcloud.py,sha256=Um1WqpIHRMWyPN7GF-pj263vt2YWcS2Sk7px9f1Ej-o,1245
+tests/test_stig.py,sha256=BNIPmY3ydqeV6nIkCZDCPV7kKYivS1gl4LNqAQ2CnNw,1258
 tests/test_tenable.py,sha256=Ik7GTnKzzXwykQH-VFsBeJPCtjqKx8LA91RCmiHNFpo,1666
 tests/test_update_regscale_config.py,sha256=GoU2ZKh7_2RYFj742_oFz8WuQx4NWL6nx2rzs4TSr40,1254
-RegScale_CLI-4.25.0.dist-info/LICENSE,sha256=ytNhYQ9Rmhj_m-EX2pPq9Ld6tH5wrqqDYg-fCf46WDU,1076
-RegScale_CLI-4.25.0.dist-info/METADATA,sha256=UK9ujVnVmWdvLJhsfklFP9C-VJj2BGJTMMt1pzdul-w,6330
-RegScale_CLI-4.25.0.dist-info/WHEEL,sha256=G16H4A3IeoQmnOrYV4ueZGKSjhipXx8zc8nu9FGlvMA,92
-RegScale_CLI-4.25.0.dist-info/entry_points.txt,sha256=7K_c4hLFOPUjCZbuY5gat-C4fVj0-4aqxbwBon21Nnc,43
-RegScale_CLI-4.25.0.dist-info/top_level.txt,sha256=6YXQTQW1Iq23W68s8qehQk2zgUCqyCCr6miOwR-RiPM,37
-RegScale_CLI-4.25.0.dist-info/RECORD,,
+RegScale_CLI-4.25.1.dist-info/LICENSE,sha256=ytNhYQ9Rmhj_m-EX2pPq9Ld6tH5wrqqDYg-fCf46WDU,1076
+RegScale_CLI-4.25.1.dist-info/METADATA,sha256=n_ZoZpGBZnDqaLPafGr79mixLVqQ0KoFwFju0QCh-pY,6330
+RegScale_CLI-4.25.1.dist-info/WHEEL,sha256=G16H4A3IeoQmnOrYV4ueZGKSjhipXx8zc8nu9FGlvMA,92
+RegScale_CLI-4.25.1.dist-info/entry_points.txt,sha256=7K_c4hLFOPUjCZbuY5gat-C4fVj0-4aqxbwBon21Nnc,43
+RegScale_CLI-4.25.1.dist-info/top_level.txt,sha256=6YXQTQW1Iq23W68s8qehQk2zgUCqyCCr6miOwR-RiPM,37
+RegScale_CLI-4.25.1.dist-info/RECORD,,
```

