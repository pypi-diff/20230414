# Comparing `tmp/feathub_nightly-0.1.dev20230412-py3-none-any.whl.zip` & `tmp/feathub_nightly-0.1.dev20230413-py3-none-any.whl.zip`

## zipinfo {}

```diff
@@ -1,162 +1,164 @@
-Zip file size: 10016659 bytes, number of entries: 160
--rw-r--r--  2.0 unx      584 b- defN 23-Apr-12 16:18 feathub/__init__.py
--rw-r--r--  2.0 unx     7406 b- defN 23-Apr-12 16:18 feathub/feathub_client.py
--rw-r--r--  2.0 unx      700 b- defN 23-Apr-12 16:18 feathub/version.py
--rw-r--r--  2.0 unx      584 b- defN 23-Apr-12 16:18 feathub/common/__init__.py
--rw-r--r--  2.0 unx     5943 b- defN 23-Apr-12 16:18 feathub/common/config.py
--rw-r--r--  2.0 unx     1176 b- defN 23-Apr-12 16:18 feathub/common/exceptions.py
--rw-r--r--  2.0 unx     1168 b- defN 23-Apr-12 16:18 feathub/common/test_utils.py
--rw-r--r--  2.0 unx     4724 b- defN 23-Apr-12 16:18 feathub/common/types.py
--rw-r--r--  2.0 unx     6950 b- defN 23-Apr-12 16:18 feathub/common/utils.py
--rw-r--r--  2.0 unx     2431 b- defN 23-Apr-12 16:18 feathub/common/validators.py
--rw-r--r--  2.0 unx      584 b- defN 23-Apr-12 16:18 feathub/common/protobuf/__init__.py
--rw-r--r--  2.0 unx    12527 b- defN 23-Apr-12 16:18 feathub/common/protobuf/value_pb2.py
--rw-r--r--  2.0 unx      584 b- defN 23-Apr-12 16:18 feathub/dsl/__init__.py
--rw-r--r--  2.0 unx     4257 b- defN 23-Apr-12 16:18 feathub/dsl/abstract_ast_evaluator.py
--rw-r--r--  2.0 unx    11411 b- defN 23-Apr-12 16:18 feathub/dsl/ast.py
--rw-r--r--  2.0 unx     3653 b- defN 23-Apr-12 16:18 feathub/dsl/expr_lexer_rules.py
--rw-r--r--  2.0 unx     6283 b- defN 23-Apr-12 16:18 feathub/dsl/expr_parser.py
--rw-r--r--  2.0 unx      584 b- defN 23-Apr-12 16:18 feathub/examples/__init__.py
--rw-r--r--  2.0 unx     8975 b- defN 23-Apr-12 16:18 feathub/examples/nyc_taxi.py
--rw-r--r--  2.0 unx     1550 b- defN 23-Apr-12 16:18 feathub/examples/nyc_taxi_flink_session.py
--rw-r--r--  2.0 unx     1262 b- defN 23-Apr-12 16:18 feathub/examples/nyc_taxi_spark_client.py
--rw-r--r--  2.0 unx      885 b- defN 23-Apr-12 16:18 feathub/examples/sample_data.csv
--rw-r--r--  2.0 unx     2825 b- defN 23-Apr-12 16:18 feathub/examples/streaming_average_flink_cli.py
--rw-r--r--  2.0 unx      584 b- defN 23-Apr-12 16:18 feathub/feature_service/__init__.py
--rw-r--r--  2.0 unx     3264 b- defN 23-Apr-12 16:18 feathub/feature_service/feature_service.py
--rw-r--r--  2.0 unx     1440 b- defN 23-Apr-12 16:18 feathub/feature_service/feature_service_config.py
--rw-r--r--  2.0 unx     6396 b- defN 23-Apr-12 16:18 feathub/feature_service/local_feature_service.py
--rw-r--r--  2.0 unx      594 b- defN 23-Apr-12 16:18 feathub/feature_tables/__init__.py
--rw-r--r--  2.0 unx     5465 b- defN 23-Apr-12 16:18 feathub/feature_tables/feature_table.py
--rw-r--r--  2.0 unx      584 b- defN 23-Apr-12 16:18 feathub/feature_tables/sinks/__init__.py
--rw-r--r--  2.0 unx     1013 b- defN 23-Apr-12 16:18 feathub/feature_tables/sinks/black_hole_sink.py
--rw-r--r--  2.0 unx     1346 b- defN 23-Apr-12 16:18 feathub/feature_tables/sinks/file_system_sink.py
--rw-r--r--  2.0 unx     2644 b- defN 23-Apr-12 16:18 feathub/feature_tables/sinks/kafka_sink.py
--rw-r--r--  2.0 unx     1226 b- defN 23-Apr-12 16:18 feathub/feature_tables/sinks/memory_store_sink.py
--rw-r--r--  2.0 unx     2436 b- defN 23-Apr-12 16:18 feathub/feature_tables/sinks/mysql_sink.py
--rw-r--r--  2.0 unx      936 b- defN 23-Apr-12 16:18 feathub/feature_tables/sinks/print_sink.py
--rw-r--r--  2.0 unx     2393 b- defN 23-Apr-12 16:18 feathub/feature_tables/sinks/redis_sink.py
--rw-r--r--  2.0 unx     2288 b- defN 23-Apr-12 16:18 feathub/feature_tables/sinks/sink.py
--rw-r--r--  2.0 unx      584 b- defN 23-Apr-12 16:18 feathub/feature_tables/sources/__init__.py
--rw-r--r--  2.0 unx     7977 b- defN 23-Apr-12 16:18 feathub/feature_tables/sources/datagen_source.py
--rw-r--r--  2.0 unx     3525 b- defN 23-Apr-12 16:18 feathub/feature_tables/sources/file_system_source.py
--rw-r--r--  2.0 unx     7819 b- defN 23-Apr-12 16:18 feathub/feature_tables/sources/kafka_source.py
--rw-r--r--  2.0 unx     2219 b- defN 23-Apr-12 16:18 feathub/feature_tables/sources/memory_store_source.py
--rw-r--r--  2.0 unx     4018 b- defN 23-Apr-12 16:18 feathub/feature_tables/sources/mysql_source.py
--rw-r--r--  2.0 unx     3466 b- defN 23-Apr-12 16:18 feathub/feature_tables/sources/redis_source.py
--rw-r--r--  2.0 unx      584 b- defN 23-Apr-12 16:18 feathub/feature_views/__init__.py
--rw-r--r--  2.0 unx     6900 b- defN 23-Apr-12 16:18 feathub/feature_views/derived_feature_view.py
--rw-r--r--  2.0 unx     4263 b- defN 23-Apr-12 16:18 feathub/feature_views/feature.py
--rw-r--r--  2.0 unx    11082 b- defN 23-Apr-12 16:18 feathub/feature_views/feature_view.py
--rw-r--r--  2.0 unx     6549 b- defN 23-Apr-12 16:18 feathub/feature_views/on_demand_feature_view.py
--rw-r--r--  2.0 unx    15520 b- defN 23-Apr-12 16:18 feathub/feature_views/sliding_feature_view.py
--rw-r--r--  2.0 unx     5572 b- defN 23-Apr-12 16:18 feathub/feature_views/sql_feature_view.py
--rw-r--r--  2.0 unx      584 b- defN 23-Apr-12 16:18 feathub/feature_views/transforms/__init__.py
--rw-r--r--  2.0 unx     1649 b- defN 23-Apr-12 16:18 feathub/feature_views/transforms/agg_func.py
--rw-r--r--  2.0 unx     1214 b- defN 23-Apr-12 16:18 feathub/feature_views/transforms/expression_transform.py
--rw-r--r--  2.0 unx     1349 b- defN 23-Apr-12 16:18 feathub/feature_views/transforms/join_transform.py
--rw-r--r--  2.0 unx     3633 b- defN 23-Apr-12 16:18 feathub/feature_views/transforms/over_window_transform.py
--rw-r--r--  2.0 unx     1279 b- defN 23-Apr-12 16:18 feathub/feature_views/transforms/python_udf_transform.py
--rw-r--r--  2.0 unx     2973 b- defN 23-Apr-12 16:18 feathub/feature_views/transforms/sliding_window_transform.py
--rw-r--r--  2.0 unx     1099 b- defN 23-Apr-12 16:18 feathub/feature_views/transforms/transformation.py
--rw-r--r--  2.0 unx      545 b- defN 23-Apr-12 16:18 feathub/online_stores/__init__.py
--rw-r--r--  2.0 unx     7568 b- defN 23-Apr-12 16:18 feathub/online_stores/memory_online_store.py
--rw-r--r--  2.0 unx     3631 b- defN 23-Apr-12 16:18 feathub/online_stores/mysql_client.py
--rw-r--r--  2.0 unx     3291 b- defN 23-Apr-12 16:18 feathub/online_stores/online_store_client.py
--rw-r--r--  2.0 unx     3564 b- defN 23-Apr-12 16:18 feathub/online_stores/redis_client.py
--rw-r--r--  2.0 unx      584 b- defN 23-Apr-12 16:18 feathub/processors/__init__.py
--rw-r--r--  2.0 unx      641 b- defN 23-Apr-12 16:18 feathub/processors/constants.py
--rw-r--r--  2.0 unx     6027 b- defN 23-Apr-12 16:18 feathub/processors/processor.py
--rw-r--r--  2.0 unx     1404 b- defN 23-Apr-12 16:18 feathub/processors/processor_config.py
--rw-r--r--  2.0 unx     1678 b- defN 23-Apr-12 16:18 feathub/processors/processor_job.py
--rw-r--r--  2.0 unx     1808 b- defN 23-Apr-12 16:18 feathub/processors/type_utils.py
--rw-r--r--  2.0 unx      594 b- defN 23-Apr-12 16:18 feathub/processors/flink/__init__.py
--rw-r--r--  2.0 unx      775 b- defN 23-Apr-12 16:18 feathub/processors/flink/flink_deployment_mode.py
--rw-r--r--  2.0 unx     2513 b- defN 23-Apr-12 16:18 feathub/processors/flink/flink_jar_utils.py
--rw-r--r--  2.0 unx    11040 b- defN 23-Apr-12 16:18 feathub/processors/flink/flink_processor.py
--rw-r--r--  2.0 unx     3491 b- defN 23-Apr-12 16:18 feathub/processors/flink/flink_processor_config.py
--rw-r--r--  2.0 unx     7579 b- defN 23-Apr-12 16:18 feathub/processors/flink/flink_table.py
--rw-r--r--  2.0 unx     5313 b- defN 23-Apr-12 16:18 feathub/processors/flink/flink_types_utils.py
--rw-r--r--  2.0 unx      594 b- defN 23-Apr-12 16:18 feathub/processors/flink/ast_evaluator/__init__.py
--rw-r--r--  2.0 unx     4179 b- defN 23-Apr-12 16:18 feathub/processors/flink/ast_evaluator/flink_ast_evaluator.py
--rw-r--r--  2.0 unx     1240 b- defN 23-Apr-12 16:18 feathub/processors/flink/ast_evaluator/functions.py
--rw-r--r--  2.0 unx      863 b- defN 23-Apr-12 16:18 feathub/processors/flink/job_submitter/__init__.py
--rw-r--r--  2.0 unx     3905 b- defN 23-Apr-12 16:18 feathub/processors/flink/job_submitter/feathub_job_descriptor.py
--rw-r--r--  2.0 unx     2951 b- defN 23-Apr-12 16:18 feathub/processors/flink/job_submitter/flink_application_cluster_job_entry.py
--rw-r--r--  2.0 unx     3277 b- defN 23-Apr-12 16:18 feathub/processors/flink/job_submitter/flink_job_submitter.py
--rw-r--r--  2.0 unx    10326 b- defN 23-Apr-12 16:18 feathub/processors/flink/job_submitter/flink_kubernetes_application_cluster_job_submitter.py
--rw-r--r--  2.0 unx     5428 b- defN 23-Apr-12 16:18 feathub/processors/flink/job_submitter/flink_session_cluster_job_submitter.py
--rw-r--r--  2.0 unx   250072 b- defN 23-Apr-12 16:18 feathub/processors/flink/lib/flink-connector-jdbc-1.15.2.jar
--rw-r--r--  2.0 unx    13536 b- defN 23-Apr-12 16:18 feathub/processors/flink/lib/flink-connector-kafka-0.1-SNAPSHOT.jar
--rw-r--r--  2.0 unx    13223 b- defN 23-Apr-12 16:18 feathub/processors/flink/lib/flink-connector-redis-0.1-SNAPSHOT.jar
--rw-r--r--  2.0 unx     6776 b- defN 23-Apr-12 16:18 feathub/processors/flink/lib/flink-shaded-force-shading-15.0.jar
--rw-r--r--  2.0 unx  5179853 b- defN 23-Apr-12 16:18 feathub/processors/flink/lib/flink-sql-connector-kafka-1.15.2.jar
--rw-r--r--  2.0 unx    83532 b- defN 23-Apr-12 16:18 feathub/processors/flink/lib/flink-udf-0.1-SNAPSHOT.jar
--rw-r--r--  2.0 unx   258075 b- defN 23-Apr-12 16:18 feathub/processors/flink/lib/gson-2.8.9.jar
--rw-r--r--  2.0 unx   792882 b- defN 23-Apr-12 16:18 feathub/processors/flink/lib/jedis-4.3.0.jar
--rw-r--r--  2.0 unx  2480823 b- defN 23-Apr-12 16:18 feathub/processors/flink/lib/mysql-connector-j-8.0.32.jar
--rw-r--r--  2.0 unx  1671409 b- defN 23-Apr-12 16:18 feathub/processors/flink/lib/protobuf-java-3.21.9.jar
--rw-r--r--  2.0 unx      594 b- defN 23-Apr-12 16:18 feathub/processors/flink/table_builder/__init__.py
--rw-r--r--  2.0 unx     3399 b- defN 23-Apr-12 16:18 feathub/processors/flink/table_builder/aggregation_utils.py
--rw-r--r--  2.0 unx      907 b- defN 23-Apr-12 16:18 feathub/processors/flink/table_builder/black_hole_utils.py
--rw-r--r--  2.0 unx     3892 b- defN 23-Apr-12 16:18 feathub/processors/flink/table_builder/datagen_utils.py
--rw-r--r--  2.0 unx     2932 b- defN 23-Apr-12 16:18 feathub/processors/flink/table_builder/file_system_utils.py
--rw-r--r--  2.0 unx     1129 b- defN 23-Apr-12 16:18 feathub/processors/flink/table_builder/flink_sql_expr_utils.py
--rw-r--r--  2.0 unx    29158 b- defN 23-Apr-12 16:18 feathub/processors/flink/table_builder/flink_table_builder.py
--rw-r--r--  2.0 unx    11454 b- defN 23-Apr-12 16:18 feathub/processors/flink/table_builder/join_utils.py
--rw-r--r--  2.0 unx     8725 b- defN 23-Apr-12 16:18 feathub/processors/flink/table_builder/kafka_utils.py
--rw-r--r--  2.0 unx     2900 b- defN 23-Apr-12 16:18 feathub/processors/flink/table_builder/mysql_utils.py
--rw-r--r--  2.0 unx     8585 b- defN 23-Apr-12 16:18 feathub/processors/flink/table_builder/over_window_utils.py
--rw-r--r--  2.0 unx     1061 b- defN 23-Apr-12 16:18 feathub/processors/flink/table_builder/print_utils.py
--rw-r--r--  2.0 unx     2928 b- defN 23-Apr-12 16:18 feathub/processors/flink/table_builder/python_udf_utils.py
--rw-r--r--  2.0 unx     6258 b- defN 23-Apr-12 16:18 feathub/processors/flink/table_builder/redis_utils.py
--rw-r--r--  2.0 unx     6987 b- defN 23-Apr-12 16:18 feathub/processors/flink/table_builder/sliding_window_utils.py
--rw-r--r--  2.0 unx     3954 b- defN 23-Apr-12 16:18 feathub/processors/flink/table_builder/source_sink_utils.py
--rw-r--r--  2.0 unx     4051 b- defN 23-Apr-12 16:18 feathub/processors/flink/table_builder/source_sink_utils_common.py
--rw-r--r--  2.0 unx     1605 b- defN 23-Apr-12 16:18 feathub/processors/flink/table_builder/time_utils.py
--rw-r--r--  2.0 unx     3979 b- defN 23-Apr-12 16:18 feathub/processors/flink/table_builder/udf.py
--rw-r--r--  2.0 unx      594 b- defN 23-Apr-12 16:18 feathub/processors/local/__init__.py
--rw-r--r--  2.0 unx     1327 b- defN 23-Apr-12 16:18 feathub/processors/local/aggregation_utils.py
--rw-r--r--  2.0 unx     2565 b- defN 23-Apr-12 16:18 feathub/processors/local/file_system_utils.py
--rw-r--r--  2.0 unx     1011 b- defN 23-Apr-12 16:18 feathub/processors/local/local_job.py
--rw-r--r--  2.0 unx    25001 b- defN 23-Apr-12 16:18 feathub/processors/local/local_processor.py
--rw-r--r--  2.0 unx      715 b- defN 23-Apr-12 16:18 feathub/processors/local/local_processor_config.py
--rw-r--r--  2.0 unx     2337 b- defN 23-Apr-12 16:18 feathub/processors/local/local_table.py
--rw-r--r--  2.0 unx    11599 b- defN 23-Apr-12 16:18 feathub/processors/local/sliding_window_utils.py
--rw-r--r--  2.0 unx     1531 b- defN 23-Apr-12 16:18 feathub/processors/local/time_utils.py
--rw-r--r--  2.0 unx      594 b- defN 23-Apr-12 16:18 feathub/processors/local/ast_evaluator/__init__.py
--rw-r--r--  2.0 unx     7203 b- defN 23-Apr-12 16:18 feathub/processors/local/ast_evaluator/local_ast_evaluator.py
--rw-r--r--  2.0 unx     1293 b- defN 23-Apr-12 16:18 feathub/processors/local/ast_evaluator/local_func_evaluator.py
--rw-r--r--  2.0 unx      594 b- defN 23-Apr-12 16:18 feathub/processors/spark/__init__.py
--rw-r--r--  2.0 unx     1872 b- defN 23-Apr-12 16:18 feathub/processors/spark/spark_job.py
--rw-r--r--  2.0 unx     5602 b- defN 23-Apr-12 16:18 feathub/processors/spark/spark_processor.py
--rw-r--r--  2.0 unx     1467 b- defN 23-Apr-12 16:18 feathub/processors/spark/spark_processor_config.py
--rw-r--r--  2.0 unx     5315 b- defN 23-Apr-12 16:18 feathub/processors/spark/spark_table.py
--rw-r--r--  2.0 unx     5787 b- defN 23-Apr-12 16:18 feathub/processors/spark/spark_types_utils.py
--rw-r--r--  2.0 unx      584 b- defN 23-Apr-12 16:18 feathub/processors/spark/ast_evaluator/__init__.py
--rw-r--r--  2.0 unx     1246 b- defN 23-Apr-12 16:18 feathub/processors/spark/ast_evaluator/functions.py
--rw-r--r--  2.0 unx     4179 b- defN 23-Apr-12 16:18 feathub/processors/spark/ast_evaluator/spark_ast_evaluator.py
--rw-r--r--  2.0 unx      594 b- defN 23-Apr-12 16:18 feathub/processors/spark/dataframe_builder/__init__.py
--rw-r--r--  2.0 unx     2296 b- defN 23-Apr-12 16:18 feathub/processors/spark/dataframe_builder/aggregation_utils.py
--rw-r--r--  2.0 unx     6347 b- defN 23-Apr-12 16:18 feathub/processors/spark/dataframe_builder/datagen_utils.py
--rw-r--r--  2.0 unx     3883 b- defN 23-Apr-12 16:18 feathub/processors/spark/dataframe_builder/join_utils.py
--rw-r--r--  2.0 unx     6829 b- defN 23-Apr-12 16:18 feathub/processors/spark/dataframe_builder/over_window_utils.py
--rw-r--r--  2.0 unx     5187 b- defN 23-Apr-12 16:18 feathub/processors/spark/dataframe_builder/source_sink_utils.py
--rw-r--r--  2.0 unx    17143 b- defN 23-Apr-12 16:18 feathub/processors/spark/dataframe_builder/spark_dataframe_builder.py
--rw-r--r--  2.0 unx     1129 b- defN 23-Apr-12 16:18 feathub/processors/spark/dataframe_builder/spark_sql_expr_utils.py
--rw-r--r--  2.0 unx     2030 b- defN 23-Apr-12 16:18 feathub/processors/spark/dataframe_builder/time_utils.py
--rw-r--r--  2.0 unx      584 b- defN 23-Apr-12 16:18 feathub/registries/__init__.py
--rw-r--r--  2.0 unx     1474 b- defN 23-Apr-12 16:18 feathub/registries/entity.py
--rw-r--r--  2.0 unx     3583 b- defN 23-Apr-12 16:18 feathub/registries/local_registry.py
--rw-r--r--  2.0 unx     4636 b- defN 23-Apr-12 16:18 feathub/registries/registry.py
--rw-r--r--  2.0 unx     1351 b- defN 23-Apr-12 16:18 feathub/registries/registry_config.py
--rw-r--r--  2.0 unx      584 b- defN 23-Apr-12 16:18 feathub/table/__init__.py
--rw-r--r--  2.0 unx     3508 b- defN 23-Apr-12 16:18 feathub/table/schema.py
--rw-r--r--  2.0 unx     2800 b- defN 23-Apr-12 16:18 feathub/table/table.py
--rw-r--r--  2.0 unx     5237 b- defN 23-Apr-12 16:18 feathub/table/table_descriptor.py
--rw-r--r--  2.0 unx      792 b- defN 23-Apr-12 16:18 feathub_nightly-0.1.dev20230412.dist-info/METADATA
--rw-r--r--  2.0 unx       92 b- defN 23-Apr-12 16:18 feathub_nightly-0.1.dev20230412.dist-info/WHEEL
--rw-r--r--  2.0 unx        8 b- defN 23-Apr-12 16:18 feathub_nightly-0.1.dev20230412.dist-info/top_level.txt
--rw-r--r--  2.0 unx        1 b- defN 23-Apr-12 16:18 feathub_nightly-0.1.dev20230412.dist-info/zip-safe
--rw-rw-r--  2.0 unx    16339 b- defN 23-Apr-12 16:18 feathub_nightly-0.1.dev20230412.dist-info/RECORD
-160 files, 11331844 bytes uncompressed, 9989909 bytes compressed:  11.8%
+Zip file size: 10020243 bytes, number of entries: 162
+-rw-r--r--  2.0 unx      584 b- defN 23-Apr-13 16:19 feathub/__init__.py
+-rw-r--r--  2.0 unx     7406 b- defN 23-Apr-13 16:19 feathub/feathub_client.py
+-rw-r--r--  2.0 unx      700 b- defN 23-Apr-13 16:19 feathub/version.py
+-rw-r--r--  2.0 unx      584 b- defN 23-Apr-13 16:19 feathub/common/__init__.py
+-rw-r--r--  2.0 unx     5931 b- defN 23-Apr-13 16:19 feathub/common/config.py
+-rw-r--r--  2.0 unx     1176 b- defN 23-Apr-13 16:19 feathub/common/exceptions.py
+-rw-r--r--  2.0 unx     1168 b- defN 23-Apr-13 16:19 feathub/common/test_utils.py
+-rw-r--r--  2.0 unx     4789 b- defN 23-Apr-13 16:19 feathub/common/types.py
+-rw-r--r--  2.0 unx     6950 b- defN 23-Apr-13 16:19 feathub/common/utils.py
+-rw-r--r--  2.0 unx     2702 b- defN 23-Apr-13 16:19 feathub/common/validators.py
+-rw-r--r--  2.0 unx      584 b- defN 23-Apr-13 16:19 feathub/common/protobuf/__init__.py
+-rw-r--r--  2.0 unx    12527 b- defN 23-Apr-13 16:20 feathub/common/protobuf/value_pb2.py
+-rw-r--r--  2.0 unx      584 b- defN 23-Apr-13 16:19 feathub/dsl/__init__.py
+-rw-r--r--  2.0 unx     4257 b- defN 23-Apr-13 16:19 feathub/dsl/abstract_ast_evaluator.py
+-rw-r--r--  2.0 unx    10819 b- defN 23-Apr-13 16:19 feathub/dsl/ast.py
+-rw-r--r--  2.0 unx     1587 b- defN 23-Apr-13 16:19 feathub/dsl/built_in_func.py
+-rw-r--r--  2.0 unx     3653 b- defN 23-Apr-13 16:19 feathub/dsl/expr_lexer_rules.py
+-rw-r--r--  2.0 unx     6283 b- defN 23-Apr-13 16:19 feathub/dsl/expr_parser.py
+-rw-r--r--  2.0 unx     1182 b- defN 23-Apr-13 16:19 feathub/dsl/expr_utils.py
+-rw-r--r--  2.0 unx      584 b- defN 23-Apr-13 16:19 feathub/examples/__init__.py
+-rw-r--r--  2.0 unx     8975 b- defN 23-Apr-13 16:19 feathub/examples/nyc_taxi.py
+-rw-r--r--  2.0 unx     1510 b- defN 23-Apr-13 16:19 feathub/examples/nyc_taxi_flink_session.py
+-rw-r--r--  2.0 unx     1262 b- defN 23-Apr-13 16:19 feathub/examples/nyc_taxi_spark_client.py
+-rw-r--r--  2.0 unx      885 b- defN 23-Apr-13 16:19 feathub/examples/sample_data.csv
+-rw-r--r--  2.0 unx     2825 b- defN 23-Apr-13 16:19 feathub/examples/streaming_average_flink_cli.py
+-rw-r--r--  2.0 unx      584 b- defN 23-Apr-13 16:19 feathub/feature_service/__init__.py
+-rw-r--r--  2.0 unx     3264 b- defN 23-Apr-13 16:19 feathub/feature_service/feature_service.py
+-rw-r--r--  2.0 unx     1440 b- defN 23-Apr-13 16:19 feathub/feature_service/feature_service_config.py
+-rw-r--r--  2.0 unx     6396 b- defN 23-Apr-13 16:19 feathub/feature_service/local_feature_service.py
+-rw-r--r--  2.0 unx      594 b- defN 23-Apr-13 16:19 feathub/feature_tables/__init__.py
+-rw-r--r--  2.0 unx     5465 b- defN 23-Apr-13 16:19 feathub/feature_tables/feature_table.py
+-rw-r--r--  2.0 unx      584 b- defN 23-Apr-13 16:19 feathub/feature_tables/sinks/__init__.py
+-rw-r--r--  2.0 unx     1013 b- defN 23-Apr-13 16:19 feathub/feature_tables/sinks/black_hole_sink.py
+-rw-r--r--  2.0 unx     1346 b- defN 23-Apr-13 16:19 feathub/feature_tables/sinks/file_system_sink.py
+-rw-r--r--  2.0 unx     2644 b- defN 23-Apr-13 16:19 feathub/feature_tables/sinks/kafka_sink.py
+-rw-r--r--  2.0 unx     1226 b- defN 23-Apr-13 16:19 feathub/feature_tables/sinks/memory_store_sink.py
+-rw-r--r--  2.0 unx     2436 b- defN 23-Apr-13 16:19 feathub/feature_tables/sinks/mysql_sink.py
+-rw-r--r--  2.0 unx      936 b- defN 23-Apr-13 16:19 feathub/feature_tables/sinks/print_sink.py
+-rw-r--r--  2.0 unx     2393 b- defN 23-Apr-13 16:19 feathub/feature_tables/sinks/redis_sink.py
+-rw-r--r--  2.0 unx     2288 b- defN 23-Apr-13 16:19 feathub/feature_tables/sinks/sink.py
+-rw-r--r--  2.0 unx      584 b- defN 23-Apr-13 16:19 feathub/feature_tables/sources/__init__.py
+-rw-r--r--  2.0 unx     7977 b- defN 23-Apr-13 16:19 feathub/feature_tables/sources/datagen_source.py
+-rw-r--r--  2.0 unx     3525 b- defN 23-Apr-13 16:19 feathub/feature_tables/sources/file_system_source.py
+-rw-r--r--  2.0 unx     7819 b- defN 23-Apr-13 16:19 feathub/feature_tables/sources/kafka_source.py
+-rw-r--r--  2.0 unx     2219 b- defN 23-Apr-13 16:19 feathub/feature_tables/sources/memory_store_source.py
+-rw-r--r--  2.0 unx     4018 b- defN 23-Apr-13 16:19 feathub/feature_tables/sources/mysql_source.py
+-rw-r--r--  2.0 unx     3466 b- defN 23-Apr-13 16:19 feathub/feature_tables/sources/redis_source.py
+-rw-r--r--  2.0 unx      584 b- defN 23-Apr-13 16:19 feathub/feature_views/__init__.py
+-rw-r--r--  2.0 unx     8600 b- defN 23-Apr-13 16:19 feathub/feature_views/derived_feature_view.py
+-rw-r--r--  2.0 unx     4422 b- defN 23-Apr-13 16:19 feathub/feature_views/feature.py
+-rw-r--r--  2.0 unx    10955 b- defN 23-Apr-13 16:19 feathub/feature_views/feature_view.py
+-rw-r--r--  2.0 unx     6531 b- defN 23-Apr-13 16:19 feathub/feature_views/on_demand_feature_view.py
+-rw-r--r--  2.0 unx    19810 b- defN 23-Apr-13 16:19 feathub/feature_views/sliding_feature_view.py
+-rw-r--r--  2.0 unx     5667 b- defN 23-Apr-13 16:19 feathub/feature_views/sql_feature_view.py
+-rw-r--r--  2.0 unx      584 b- defN 23-Apr-13 16:19 feathub/feature_views/transforms/__init__.py
+-rw-r--r--  2.0 unx     1649 b- defN 23-Apr-13 16:19 feathub/feature_views/transforms/agg_func.py
+-rw-r--r--  2.0 unx     1214 b- defN 23-Apr-13 16:19 feathub/feature_views/transforms/expression_transform.py
+-rw-r--r--  2.0 unx     1349 b- defN 23-Apr-13 16:19 feathub/feature_views/transforms/join_transform.py
+-rw-r--r--  2.0 unx     3665 b- defN 23-Apr-13 16:19 feathub/feature_views/transforms/over_window_transform.py
+-rw-r--r--  2.0 unx     1279 b- defN 23-Apr-13 16:19 feathub/feature_views/transforms/python_udf_transform.py
+-rw-r--r--  2.0 unx     2973 b- defN 23-Apr-13 16:19 feathub/feature_views/transforms/sliding_window_transform.py
+-rw-r--r--  2.0 unx     1099 b- defN 23-Apr-13 16:19 feathub/feature_views/transforms/transformation.py
+-rw-r--r--  2.0 unx      545 b- defN 23-Apr-13 16:19 feathub/online_stores/__init__.py
+-rw-r--r--  2.0 unx     7568 b- defN 23-Apr-13 16:19 feathub/online_stores/memory_online_store.py
+-rw-r--r--  2.0 unx     3631 b- defN 23-Apr-13 16:19 feathub/online_stores/mysql_client.py
+-rw-r--r--  2.0 unx     3291 b- defN 23-Apr-13 16:19 feathub/online_stores/online_store_client.py
+-rw-r--r--  2.0 unx     3564 b- defN 23-Apr-13 16:19 feathub/online_stores/redis_client.py
+-rw-r--r--  2.0 unx      584 b- defN 23-Apr-13 16:19 feathub/processors/__init__.py
+-rw-r--r--  2.0 unx      641 b- defN 23-Apr-13 16:19 feathub/processors/constants.py
+-rw-r--r--  2.0 unx     6027 b- defN 23-Apr-13 16:19 feathub/processors/processor.py
+-rw-r--r--  2.0 unx     1404 b- defN 23-Apr-13 16:19 feathub/processors/processor_config.py
+-rw-r--r--  2.0 unx     1678 b- defN 23-Apr-13 16:19 feathub/processors/processor_job.py
+-rw-r--r--  2.0 unx     1808 b- defN 23-Apr-13 16:19 feathub/processors/type_utils.py
+-rw-r--r--  2.0 unx      594 b- defN 23-Apr-13 16:19 feathub/processors/flink/__init__.py
+-rw-r--r--  2.0 unx      775 b- defN 23-Apr-13 16:19 feathub/processors/flink/flink_deployment_mode.py
+-rw-r--r--  2.0 unx     2513 b- defN 23-Apr-13 16:19 feathub/processors/flink/flink_jar_utils.py
+-rw-r--r--  2.0 unx    12308 b- defN 23-Apr-13 16:19 feathub/processors/flink/flink_processor.py
+-rw-r--r--  2.0 unx     3770 b- defN 23-Apr-13 16:19 feathub/processors/flink/flink_processor_config.py
+-rw-r--r--  2.0 unx     7579 b- defN 23-Apr-13 16:19 feathub/processors/flink/flink_table.py
+-rw-r--r--  2.0 unx     5313 b- defN 23-Apr-13 16:19 feathub/processors/flink/flink_types_utils.py
+-rw-r--r--  2.0 unx      594 b- defN 23-Apr-13 16:19 feathub/processors/flink/ast_evaluator/__init__.py
+-rw-r--r--  2.0 unx     4179 b- defN 23-Apr-13 16:19 feathub/processors/flink/ast_evaluator/flink_ast_evaluator.py
+-rw-r--r--  2.0 unx     1240 b- defN 23-Apr-13 16:19 feathub/processors/flink/ast_evaluator/functions.py
+-rw-r--r--  2.0 unx      863 b- defN 23-Apr-13 16:19 feathub/processors/flink/job_submitter/__init__.py
+-rw-r--r--  2.0 unx     3905 b- defN 23-Apr-13 16:19 feathub/processors/flink/job_submitter/feathub_job_descriptor.py
+-rw-r--r--  2.0 unx     2951 b- defN 23-Apr-13 16:19 feathub/processors/flink/job_submitter/flink_application_cluster_job_entry.py
+-rw-r--r--  2.0 unx     3277 b- defN 23-Apr-13 16:19 feathub/processors/flink/job_submitter/flink_job_submitter.py
+-rw-r--r--  2.0 unx    10326 b- defN 23-Apr-13 16:19 feathub/processors/flink/job_submitter/flink_kubernetes_application_cluster_job_submitter.py
+-rw-r--r--  2.0 unx     5428 b- defN 23-Apr-13 16:19 feathub/processors/flink/job_submitter/flink_session_cluster_job_submitter.py
+-rw-r--r--  2.0 unx   250072 b- defN 23-Apr-13 16:19 feathub/processors/flink/lib/flink-connector-jdbc-1.15.2.jar
+-rw-r--r--  2.0 unx    13537 b- defN 23-Apr-13 16:19 feathub/processors/flink/lib/flink-connector-kafka-0.1-SNAPSHOT.jar
+-rw-r--r--  2.0 unx    13224 b- defN 23-Apr-13 16:19 feathub/processors/flink/lib/flink-connector-redis-0.1-SNAPSHOT.jar
+-rw-r--r--  2.0 unx     6776 b- defN 23-Apr-13 16:19 feathub/processors/flink/lib/flink-shaded-force-shading-15.0.jar
+-rw-r--r--  2.0 unx  5179853 b- defN 23-Apr-13 16:19 feathub/processors/flink/lib/flink-sql-connector-kafka-1.15.2.jar
+-rw-r--r--  2.0 unx    84318 b- defN 23-Apr-13 16:19 feathub/processors/flink/lib/flink-udf-0.1-SNAPSHOT.jar
+-rw-r--r--  2.0 unx   258075 b- defN 23-Apr-13 16:19 feathub/processors/flink/lib/gson-2.8.9.jar
+-rw-r--r--  2.0 unx   792882 b- defN 23-Apr-13 16:19 feathub/processors/flink/lib/jedis-4.3.0.jar
+-rw-r--r--  2.0 unx  2480823 b- defN 23-Apr-13 16:19 feathub/processors/flink/lib/mysql-connector-j-8.0.32.jar
+-rw-r--r--  2.0 unx  1671409 b- defN 23-Apr-13 16:19 feathub/processors/flink/lib/protobuf-java-3.21.9.jar
+-rw-r--r--  2.0 unx      594 b- defN 23-Apr-13 16:19 feathub/processors/flink/table_builder/__init__.py
+-rw-r--r--  2.0 unx     3399 b- defN 23-Apr-13 16:19 feathub/processors/flink/table_builder/aggregation_utils.py
+-rw-r--r--  2.0 unx      907 b- defN 23-Apr-13 16:19 feathub/processors/flink/table_builder/black_hole_utils.py
+-rw-r--r--  2.0 unx     3892 b- defN 23-Apr-13 16:19 feathub/processors/flink/table_builder/datagen_utils.py
+-rw-r--r--  2.0 unx     2932 b- defN 23-Apr-13 16:19 feathub/processors/flink/table_builder/file_system_utils.py
+-rw-r--r--  2.0 unx     1129 b- defN 23-Apr-13 16:19 feathub/processors/flink/table_builder/flink_sql_expr_utils.py
+-rw-r--r--  2.0 unx    29239 b- defN 23-Apr-13 16:19 feathub/processors/flink/table_builder/flink_table_builder.py
+-rw-r--r--  2.0 unx    11454 b- defN 23-Apr-13 16:19 feathub/processors/flink/table_builder/join_utils.py
+-rw-r--r--  2.0 unx     8725 b- defN 23-Apr-13 16:19 feathub/processors/flink/table_builder/kafka_utils.py
+-rw-r--r--  2.0 unx     2900 b- defN 23-Apr-13 16:19 feathub/processors/flink/table_builder/mysql_utils.py
+-rw-r--r--  2.0 unx     8649 b- defN 23-Apr-13 16:19 feathub/processors/flink/table_builder/over_window_utils.py
+-rw-r--r--  2.0 unx     1061 b- defN 23-Apr-13 16:19 feathub/processors/flink/table_builder/print_utils.py
+-rw-r--r--  2.0 unx     2928 b- defN 23-Apr-13 16:19 feathub/processors/flink/table_builder/python_udf_utils.py
+-rw-r--r--  2.0 unx     6258 b- defN 23-Apr-13 16:19 feathub/processors/flink/table_builder/redis_utils.py
+-rw-r--r--  2.0 unx     6987 b- defN 23-Apr-13 16:19 feathub/processors/flink/table_builder/sliding_window_utils.py
+-rw-r--r--  2.0 unx     3954 b- defN 23-Apr-13 16:19 feathub/processors/flink/table_builder/source_sink_utils.py
+-rw-r--r--  2.0 unx     4051 b- defN 23-Apr-13 16:19 feathub/processors/flink/table_builder/source_sink_utils_common.py
+-rw-r--r--  2.0 unx     1605 b- defN 23-Apr-13 16:19 feathub/processors/flink/table_builder/time_utils.py
+-rw-r--r--  2.0 unx     4112 b- defN 23-Apr-13 16:19 feathub/processors/flink/table_builder/udf.py
+-rw-r--r--  2.0 unx      594 b- defN 23-Apr-13 16:19 feathub/processors/local/__init__.py
+-rw-r--r--  2.0 unx     1327 b- defN 23-Apr-13 16:19 feathub/processors/local/aggregation_utils.py
+-rw-r--r--  2.0 unx     2565 b- defN 23-Apr-13 16:19 feathub/processors/local/file_system_utils.py
+-rw-r--r--  2.0 unx     1011 b- defN 23-Apr-13 16:19 feathub/processors/local/local_job.py
+-rw-r--r--  2.0 unx    25001 b- defN 23-Apr-13 16:19 feathub/processors/local/local_processor.py
+-rw-r--r--  2.0 unx      715 b- defN 23-Apr-13 16:19 feathub/processors/local/local_processor_config.py
+-rw-r--r--  2.0 unx     2337 b- defN 23-Apr-13 16:19 feathub/processors/local/local_table.py
+-rw-r--r--  2.0 unx    11599 b- defN 23-Apr-13 16:19 feathub/processors/local/sliding_window_utils.py
+-rw-r--r--  2.0 unx     1531 b- defN 23-Apr-13 16:19 feathub/processors/local/time_utils.py
+-rw-r--r--  2.0 unx      594 b- defN 23-Apr-13 16:19 feathub/processors/local/ast_evaluator/__init__.py
+-rw-r--r--  2.0 unx     7203 b- defN 23-Apr-13 16:19 feathub/processors/local/ast_evaluator/local_ast_evaluator.py
+-rw-r--r--  2.0 unx     1293 b- defN 23-Apr-13 16:19 feathub/processors/local/ast_evaluator/local_func_evaluator.py
+-rw-r--r--  2.0 unx      594 b- defN 23-Apr-13 16:19 feathub/processors/spark/__init__.py
+-rw-r--r--  2.0 unx     1872 b- defN 23-Apr-13 16:19 feathub/processors/spark/spark_job.py
+-rw-r--r--  2.0 unx     6203 b- defN 23-Apr-13 16:19 feathub/processors/spark/spark_processor.py
+-rw-r--r--  2.0 unx     1673 b- defN 23-Apr-13 16:19 feathub/processors/spark/spark_processor_config.py
+-rw-r--r--  2.0 unx     5315 b- defN 23-Apr-13 16:19 feathub/processors/spark/spark_table.py
+-rw-r--r--  2.0 unx     5787 b- defN 23-Apr-13 16:19 feathub/processors/spark/spark_types_utils.py
+-rw-r--r--  2.0 unx      584 b- defN 23-Apr-13 16:19 feathub/processors/spark/ast_evaluator/__init__.py
+-rw-r--r--  2.0 unx     1246 b- defN 23-Apr-13 16:19 feathub/processors/spark/ast_evaluator/functions.py
+-rw-r--r--  2.0 unx     4179 b- defN 23-Apr-13 16:19 feathub/processors/spark/ast_evaluator/spark_ast_evaluator.py
+-rw-r--r--  2.0 unx      594 b- defN 23-Apr-13 16:19 feathub/processors/spark/dataframe_builder/__init__.py
+-rw-r--r--  2.0 unx     2296 b- defN 23-Apr-13 16:19 feathub/processors/spark/dataframe_builder/aggregation_utils.py
+-rw-r--r--  2.0 unx     6347 b- defN 23-Apr-13 16:19 feathub/processors/spark/dataframe_builder/datagen_utils.py
+-rw-r--r--  2.0 unx     3883 b- defN 23-Apr-13 16:19 feathub/processors/spark/dataframe_builder/join_utils.py
+-rw-r--r--  2.0 unx     6829 b- defN 23-Apr-13 16:19 feathub/processors/spark/dataframe_builder/over_window_utils.py
+-rw-r--r--  2.0 unx     5187 b- defN 23-Apr-13 16:19 feathub/processors/spark/dataframe_builder/source_sink_utils.py
+-rw-r--r--  2.0 unx    17143 b- defN 23-Apr-13 16:19 feathub/processors/spark/dataframe_builder/spark_dataframe_builder.py
+-rw-r--r--  2.0 unx     1129 b- defN 23-Apr-13 16:19 feathub/processors/spark/dataframe_builder/spark_sql_expr_utils.py
+-rw-r--r--  2.0 unx     2030 b- defN 23-Apr-13 16:19 feathub/processors/spark/dataframe_builder/time_utils.py
+-rw-r--r--  2.0 unx      584 b- defN 23-Apr-13 16:19 feathub/registries/__init__.py
+-rw-r--r--  2.0 unx     1474 b- defN 23-Apr-13 16:19 feathub/registries/entity.py
+-rw-r--r--  2.0 unx     3583 b- defN 23-Apr-13 16:19 feathub/registries/local_registry.py
+-rw-r--r--  2.0 unx     4636 b- defN 23-Apr-13 16:19 feathub/registries/registry.py
+-rw-r--r--  2.0 unx     1351 b- defN 23-Apr-13 16:19 feathub/registries/registry_config.py
+-rw-r--r--  2.0 unx      584 b- defN 23-Apr-13 16:19 feathub/table/__init__.py
+-rw-r--r--  2.0 unx     3508 b- defN 23-Apr-13 16:19 feathub/table/schema.py
+-rw-r--r--  2.0 unx     2800 b- defN 23-Apr-13 16:19 feathub/table/table.py
+-rw-r--r--  2.0 unx     5237 b- defN 23-Apr-13 16:19 feathub/table/table_descriptor.py
+-rw-r--r--  2.0 unx      792 b- defN 23-Apr-13 16:20 feathub_nightly-0.1.dev20230413.dist-info/METADATA
+-rw-r--r--  2.0 unx       92 b- defN 23-Apr-13 16:20 feathub_nightly-0.1.dev20230413.dist-info/WHEEL
+-rw-r--r--  2.0 unx        8 b- defN 23-Apr-13 16:20 feathub_nightly-0.1.dev20230413.dist-info/top_level.txt
+-rw-r--r--  2.0 unx        1 b- defN 23-Apr-13 16:20 feathub_nightly-0.1.dev20230413.dist-info/zip-safe
+-rw-rw-r--  2.0 unx    16506 b- defN 23-Apr-13 16:20 feathub_nightly-0.1.dev20230413.dist-info/RECORD
+162 files, 11344023 bytes uncompressed, 9993235 bytes compressed:  11.9%
```

## zipnote {}

```diff
@@ -39,20 +39,26 @@
 
 Filename: feathub/dsl/abstract_ast_evaluator.py
 Comment: 
 
 Filename: feathub/dsl/ast.py
 Comment: 
 
+Filename: feathub/dsl/built_in_func.py
+Comment: 
+
 Filename: feathub/dsl/expr_lexer_rules.py
 Comment: 
 
 Filename: feathub/dsl/expr_parser.py
 Comment: 
 
+Filename: feathub/dsl/expr_utils.py
+Comment: 
+
 Filename: feathub/examples/__init__.py
 Comment: 
 
 Filename: feathub/examples/nyc_taxi.py
 Comment: 
 
 Filename: feathub/examples/nyc_taxi_flink_session.py
@@ -459,23 +465,23 @@
 
 Filename: feathub/table/table.py
 Comment: 
 
 Filename: feathub/table/table_descriptor.py
 Comment: 
 
-Filename: feathub_nightly-0.1.dev20230412.dist-info/METADATA
+Filename: feathub_nightly-0.1.dev20230413.dist-info/METADATA
 Comment: 
 
-Filename: feathub_nightly-0.1.dev20230412.dist-info/WHEEL
+Filename: feathub_nightly-0.1.dev20230413.dist-info/WHEEL
 Comment: 
 
-Filename: feathub_nightly-0.1.dev20230412.dist-info/top_level.txt
+Filename: feathub_nightly-0.1.dev20230413.dist-info/top_level.txt
 Comment: 
 
-Filename: feathub_nightly-0.1.dev20230412.dist-info/zip-safe
+Filename: feathub_nightly-0.1.dev20230413.dist-info/zip-safe
 Comment: 
 
-Filename: feathub_nightly-0.1.dev20230412.dist-info/RECORD
+Filename: feathub_nightly-0.1.dev20230413.dist-info/RECORD
 Comment: 
 
 Zip file comment:
```

## feathub/common/config.py

```diff
@@ -26,28 +26,28 @@
 
     E.g
 
     {
         "processor": {
             "type": "flink",
             "flink": {
-                "rest.address": "localhost",
+                "master": "localhost",
             },
         },
         "online_store": {
             "types": ["memory"],
             "memory": {},
         },
     }
 
     becomes
 
     {
         "processor.type": "flink",
-        "processor.flink.rest.address": "localhost",
+        "processor.flink.master": "localhost",
         "online_store.types": ["memory"],
     }
     """
     json_normalized = pd.json_normalize(dict_to_flatten).to_dict(orient="records")
     if len(json_normalized) >= 1:
         return json_normalized[0]
     else:
```

## feathub/common/types.py

```diff
@@ -117,14 +117,16 @@
         return np.int32
     elif dtype == Int64:
         return np.int64
     elif dtype == Float32:
         return np.float32
     elif dtype == Float64:
         return np.float64
+    elif isinstance(dtype, VectorType):
+        return np.object
     elif isinstance(dtype, MapType):
         return np.object
     elif dtype == Unknown:
         return np.object
 
     raise FeathubTypeException(f"Converting {dtype} to numpy type is not supported.")
```

## feathub/common/validators.py

```diff
@@ -33,14 +33,24 @@
         :param value: The value of the configuration
 
         :raise FeathubConfigurationException if the value is invalid.
         """
         pass
 
 
+class NotNoneValidator(Validator[T]):
+    def ensure_valid(self, name: str, value: T) -> None:
+        if value is None:
+            raise FeathubConfigurationException(f"Value of {name} cannot be None.")
+
+
+def not_none() -> Validator[T]:
+    return NotNoneValidator()
+
+
 class InListValidator(Validator[T]):
     def __init__(self, *allowed: T):
         self.allowed = allowed
 
     def ensure_valid(self, name: str, value: T) -> None:
         if value not in self.allowed:
             raise FeathubConfigurationException(
```

## feathub/dsl/ast.py

```diff
@@ -9,40 +9,31 @@
 #  Unless required by applicable law or agreed to in writing, software
 #  distributed under the License is distributed on an "AS IS" BASIS,
 #  WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
 #  See the License for the specific language governing permissions and
 #  limitations under the License.
 import json
 from abc import ABC, abstractmethod
-from typing import List, Dict, Any, Optional, Callable
+from typing import List, Dict, Any, Optional
 
 from feathub.common.exceptions import FeathubException, FeathubExpressionException
 from feathub.common.types import (
     DType,
     Int32,
     Int64,
     Float32,
     Float64,
     Bool,
-    String,
     get_type_by_name,
     from_python_type,
 )
+from feathub.dsl.built_in_func import get_builtin_func_def
 
 TYPE_PRECISION_RANK: List[DType] = [Float64, Float32, Int64, Int32]
 
-# A map from the FeatHub built-in function name to a callable that is used to
-# evaluate the result data type of the function. The callable takes a list of
-# data types of arguments and returns the data type of the result.
-# TODO: Add a dedicated class to keep track of all the FeatHub function.
-FUNCTION_RESULT_TYPE_EVALUATOR: Dict[str, Callable[[List[DType]], DType]] = {
-    "LOWER": lambda _: String,
-    "UNIX_TIMESTAMP": lambda _: Int64,
-}
-
 
 def _get_higher_precision_type(*dtype: DType) -> Optional[DType]:
     res_type = dtype[0]
 
     for t in dtype[1:]:
         if res_type not in TYPE_PRECISION_RANK or t not in TYPE_PRECISION_RANK:
             raise FeathubExpressionException(f"Illegal mixing of types: {dtype}")
@@ -230,20 +221,16 @@
     def __init__(self, func_name: str, args: ArgListNode) -> None:
         super().__init__(node_type="FuncCallOp")
         self.func_name = func_name.upper()
         self.args = args
 
     def eval_dtype(self, variable_types: Dict[str, DType]) -> DType:
         arg_types = [arg.eval_dtype(variable_types) for arg in self.args.values]
-        function_type_evaluator = FUNCTION_RESULT_TYPE_EVALUATOR.get(self.func_name)
-        if function_type_evaluator is None:
-            raise RuntimeError(
-                f"Unknown result type evaluator for function {self.func_name}."
-            )
-        return function_type_evaluator(arg_types)
+        builtin_func_def = get_builtin_func_def(self.func_name)
+        return builtin_func_def.get_result_type(arg_types)
 
     def to_json(self) -> Dict:
         return {
             "node_type": "FuncCallOp",
             "func_name": self.func_name,
             "args": self.args.to_json(),
         }
```

## feathub/examples/nyc_taxi_flink_session.py

```diff
@@ -23,16 +23,15 @@
 
 def main() -> None:
     client = FeathubClient(
         props={
             "processor": {
                 "type": "flink",
                 "flink": {
-                    "rest.address": "localhost",
-                    "rest.port": 8081,
+                    "master": "localhost:8081",
                 },
             },
             "online_store": {
                 "types": ["memory"],
                 "memory": {},
             },
             "registry": {
```

## feathub/feature_views/derived_feature_view.py

```diff
@@ -10,21 +10,24 @@
 # distributed under the License is distributed on an "AS IS" BASIS,
 # WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
 # See the License for the specific language governing permissions and
 # limitations under the License.
 
 from __future__ import annotations
 
-from typing import Union, Dict, Sequence, Optional
+from typing import Union, Dict, Sequence, Optional, List
 
 from feathub.common.exceptions import FeathubException
+from feathub.dsl.expr_utils import get_variables
 from feathub.feature_views.feature import Feature
 from feathub.feature_views.feature_view import FeatureView
 from feathub.feature_views.transforms.expression_transform import ExpressionTransform
 from feathub.feature_views.transforms.join_transform import JoinTransform
+from feathub.feature_views.transforms.over_window_transform import OverWindowTransform
+from feathub.feature_views.transforms.python_udf_transform import PythonUdfTransform
 from feathub.registries.registry import Registry
 from feathub.table.table_descriptor import TableDescriptor
 
 
 class DerivedFeatureView(FeatureView):
     """
     Derives features by applying the given transformations on an existing table.
@@ -91,37 +94,71 @@
 
         features = []
         for feature in self.features:
             if isinstance(feature, str):
                 feature = self._get_feature_from_feature_str(feature, registry, source)
             features.append(feature)
 
-        # TODO: Validate ExpressionTransform features that depends on
-        #  OverWindowTransform or JoinTransform features are listed after the first
-        #  OverWindowTransform or JoinTransform feature.
+        self._validate(features, source)
 
         return DerivedFeatureView(
             name=self.name,
             source=source,
             features=features,
             keep_source_fields=self.keep_source_fields,
             filter_expr=self.filter_expr,
         )
 
     @staticmethod
+    def _validate(features: List[Feature], source: TableDescriptor) -> None:
+        # Check if the feature only depends on the features specified earlier or the
+        # features in the source table.
+        valid_variables = set([f.name for f in source.get_output_features()])
+        for feature in features:
+            transform = feature.transform
+            if isinstance(transform, JoinTransform):
+                variables = set()
+            elif isinstance(transform, PythonUdfTransform):
+                variables = {f.name for f in feature.input_features}
+            elif isinstance(transform, OverWindowTransform):
+                variables = {
+                    *(
+                        get_variables(transform.filter_expr)
+                        if transform.filter_expr is not None
+                        else set()
+                    ),
+                    *get_variables(transform.expr),
+                    *transform.group_by_keys,
+                }
+            elif isinstance(transform, ExpressionTransform):
+                variables = get_variables(transform.expr)
+            else:
+                raise FeathubException(
+                    f"Unexpected transform {transform} of feature {feature.name} in "
+                    f"DerivedFeatureView."
+                )
+
+            if not variables.issubset(valid_variables):
+                raise FeathubException(
+                    f"Feature {feature} should only depend on features specified "
+                    f"earlier or the features in the source table."
+                )
+            valid_variables.add(feature.name)
+
+    @staticmethod
     def _get_feature_from_feature_str(
         feature_str: str, registry: Registry, source: TableDescriptor
     ) -> Feature:
         parts = feature_str.split(".")
         if len(parts) == 1:
             source_feature = source.get_feature(parts[0])
             feature = Feature(
                 name=source_feature.name,
                 dtype=source_feature.dtype,
-                transform=ExpressionTransform(source_feature.name),
+                transform=ExpressionTransform(f"`{source_feature.name}`"),
                 keys=source_feature.keys,
             )
             return feature
         elif len(parts) == 2:
             join_table_name = parts[0]
             join_feature_name = parts[1]
             table_desc = registry.get_features(name=join_table_name)
```

## feathub/feature_views/feature.py

```diff
@@ -92,9 +92,15 @@
         }
 
     # TODO: add from_json()
 
     def __str__(self) -> str:
         return json.dumps(self.to_json(), indent=2, sort_keys=True)
 
+    def __repr__(self) -> str:
+        return self.__str__()
+
+    def __hash__(self) -> int:
+        return hash(((k, v) for k, v in self.to_json().items()))
+
     def __eq__(self, other: object) -> bool:
         return isinstance(other, Feature) and self.to_json() == other.to_json()
```

## feathub/feature_views/feature_view.py

```diff
@@ -178,34 +178,35 @@
 
     def get_resolved_source(self) -> TableDescriptor:
         if self.is_unresolved():
             raise RuntimeError("This feature view is unresolved.")
         return cast(TableDescriptor, self.source)
 
     def _get_keys(self) -> Optional[List[str]]:
-        if self.keep_source_fields and cast(TableDescriptor, self.source).keys is None:
-            return None
-
-        feature_with_keys = [
-            f for f in self.get_resolved_features() if f.keys is not None
-        ]
-        # Table's keys are unknown if no feature has keys specified.
-        if not self.keep_source_fields and not feature_with_keys:
-            return None
-
         key_fields: List[str] = []
-        if self.keep_source_fields:
+
+        if (
+            self.keep_source_fields
+            and cast(TableDescriptor, self.source).keys is not None
+        ):
             keys: Sequence[str] = cast(TableDescriptor, self.source).keys
             if keys is not None:
                 key_fields.extend(keys)
+
+        feature_with_keys = [
+            f for f in self.get_resolved_features() if f.keys is not None
+        ]
         for feature in feature_with_keys:
             keys = feature.keys
             if keys is not None:
                 key_fields.extend(keys)
 
+        if not key_fields:
+            return None
+
         return list(OrderedDict.fromkeys(key_fields))
 
     def is_bounded(self) -> bool:
         return self.get_resolved_source().is_bounded()
 
     def get_bounded_view(self) -> TableDescriptor:
         if self.is_bounded():
```

## feathub/feature_views/on_demand_feature_view.py

```diff
@@ -82,15 +82,15 @@
             keep_source_fields=keep_source_fields,
         )
         self.request_schema = request_schema
         for feature in features:
             if isinstance(feature, str) and len(feature.split(".")) != 2:
                 raise RuntimeError(
                     f"Feature '{feature}' is not in the format "
-                    "{table_name}.{feature_name} or {feature_name}."
+                    "{table_name}.{feature_name}."
                 )
             if not (
                 isinstance(feature, str)
                 or isinstance(feature.transform, JoinTransform)
                 or isinstance(feature.transform, ExpressionTransform)
             ):
                 raise RuntimeError(
```

## feathub/feature_views/sliding_feature_view.py

```diff
@@ -7,19 +7,20 @@
 #      https://www.apache.org/licenses/LICENSE-2.0
 #
 #  Unless required by applicable law or agreed to in writing, software
 #  distributed under the License is distributed on an "AS IS" BASIS,
 #  WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
 #  See the License for the specific language governing permissions and
 #  limitations under the License.
-from typing import Dict, Union, Sequence, Set, Any, Optional, List, OrderedDict
+from typing import Dict, Union, Sequence, Set, Any, Optional, List, OrderedDict, cast
 
 from feathub.common import types
 from feathub.common.config import BaseConfig, ConfigDef
 from feathub.common.exceptions import FeathubException, FeathubConfigurationException
+from feathub.dsl.expr_utils import get_variables
 from feathub.feature_views.feature import Feature
 from feathub.feature_views.feature_view import FeatureView
 from feathub.feature_views.transforms.expression_transform import ExpressionTransform
 from feathub.feature_views.transforms.python_udf_transform import PythonUdfTransform
 from feathub.feature_views.transforms.sliding_window_transform import (
     SlidingWindowTransform,
 )
@@ -71,19 +72,23 @@
 
 # TODO: Add general and formal description for concepts like bounded/unbounded stream,
 #  max out of orderness, (watermark,) and late data in Feathub documents.
 class SlidingFeatureView(FeatureView):
     """
     Derives features by applying sliding window transformations on an existing table.
 
-    Supports per-row expression transformation and sliding window transformation. Does
-    not support table join or over window transformation. Those features defined with
-    expression transformation must be part of the groups keys of sliding window
-    transformations used in this feature view. And sliding window transformations used
-    in this feature view must have the same step size and group-by keys.
+    SlidingFeatureView supports ExpressionTransform, PythonUdfTransform, and
+    SlidingWindowTransform, but it does not support JoinTransform or
+    OverWindowTransform. SlidingWindowTransform used in this feature view must have the
+    same step size and group-by keys. Those features defined with ExpressionTransform or
+    PythonUdfTransform before the first SlidingWindowTransform feature must be part of
+    the group-by keys of sliding window transformations used in this feature view. If
+    they are defined after the first SlidingWindowTransform feature, they must only
+    depend on the timestamp_field, SlidingWindowTransform features, or the group-by
+    keys.
 
     Unlike DerivedFeatureView, the number of rows emitted by SlidingFeatureView might
     not equal the number of rows in its source table. This is because the features
     defined by a sliding window transformation can change over time even if there is no
     change in the source table.
 
     The output fields of this feature view consist of the features explicitly listed in
@@ -120,23 +125,25 @@
     ):
         """
         :param name: The unique identifier of this feature view in the registry.
         :param source: The source dataset used to derive this feature view. If it is a
                        string, it should refer to the name of a table descriptor in the
                        registry.
         :param features: A list of features to be computed from the source table. The
-                         feature should be computed by either ExpressionTransform or
-                         SlidingWindowTransform. It must have at least one feature with
-                         SlidingWindowTransform. Features computed by
-                         SlidingWindowTransform must have the same step_size and
-                         group-by keys. For any feature computed by ExpressionTransform,
-                         it should either be included as one of the group-by keys of
-                         SlidingWindowTransform features in this list, or its expression
-                         must only depend on the SlidingWindowTransform features
-                         specified earlier in this list and their group-by keys.
+                         feature should be computed by either ExpressionTransform,
+                         PythonUdfTransform, or SlidingWindowTransform. It must have at
+                         least one feature computed by SlidingWindowTransform.
+                         Features computed by SlidingWindowTransform must have the same
+                         step_size and group-by keys. Features computed by
+                         ExpressionTransform or PythonUdfTransform before the first
+                         SlidingWindowTransform feature should be included in the
+                         group-by keys of SlidingWindowTransform features. If they are
+                         listed after the first SlidingWindowTransform feature, they
+                         must only depend on the timestamp_field, SlidingWindowTransform
+                         features, or the group-by keys.
         :param timestamp_field: The name of the field generated by the
                                 SlidingFeatureView that represents the closed window end
                                 time for each row. The window end time is the last
                                 millisecond included in the window. For example, a
                                 one-hour sliding window started at 00:00:00.000 has
                                 window end time of 00:59:59.999.
         :param timestamp_format: The format of the timestamp field. See TableDescriptor
@@ -160,16 +167,14 @@
             keep_source_fields=False,
             timestamp_field=timestamp_field,
             timestamp_format=timestamp_format,
         )
 
         self.filter_expr = filter_expr
 
-        self._validate(features)
-
         self.config = (
             SlidingFeatureViewConfig({})
             if props is None
             else SlidingFeatureViewConfig(props)
         )
         if not self.config.get(ENABLE_EMPTY_WINDOW_OUTPUT_CONFIG) and self.config.get(
             SKIP_SAME_WINDOW_OUTPUT_CONFIG
@@ -242,14 +247,15 @@
                     transform=ExpressionTransform(source_feature.name),
                     keys=source_feature.keys,
                 )
             if feature.name == self.timestamp_field:
                 continue
             features.append(feature)
 
+        self._validate(source, features)
         props = {} if props is None else props
         feature_view = SlidingFeatureView(
             name=self.name,
             source=source,
             features=features,
             timestamp_field=self.timestamp_field,
             timestamp_format=self.timestamp_format,
@@ -270,77 +276,170 @@
                 for feature in self.features
             ],
             "timestamp_field": self.timestamp_field,
             "timestamp_format": self.timestamp_format,
             "filter_expr": self.filter_expr,
         }
 
-    @staticmethod
-    def _validate(features: Sequence[Union[str, Feature]]) -> None:
-        sliding_window_transforms = [
-            feature.transform
-            for feature in features
-            if isinstance(feature, Feature)
-            and isinstance(feature.transform, SlidingWindowTransform)
-        ]
-        if len(sliding_window_transforms) < 1:
-            raise FeathubException(
-                "SlidingWindowFeatureView must have at least one feature with "
-                "SlidingWindowTransform."
-            )
-
-        # Per-row transform features listed before the first SlidingWindowTransform
-        # feature.
-        per_row_transform_feature_names: Set[str] = set()
-        sliding_window_transforms_group_by_keys: Set[str] = set()
+    def _validate(self, source: TableDescriptor, features: Sequence[Feature]) -> None:
+        pre_sliding_features: Set[Feature] = set()
+        sliding_features: Set[Feature] = set()
+        post_sliding_features: Set[Feature] = set()
 
         for feature in features:
-            if isinstance(feature, str):
-                if len(sliding_window_transforms_group_by_keys) == 0:
-                    per_row_transform_feature_names.add(feature)
-                continue
-
             transform = feature.transform
             if isinstance(transform, ExpressionTransform):
-                if len(sliding_window_transforms_group_by_keys) == 0:
-                    per_row_transform_feature_names.add(feature.name)
+                if len(sliding_features) == 0:
+                    pre_sliding_features.add(feature)
+                else:
+                    post_sliding_features.add(feature)
             elif isinstance(transform, SlidingWindowTransform):
-                sliding_window_transforms_group_by_keys.update(transform.group_by_keys)
+                sliding_features.add(feature)
             elif isinstance(transform, PythonUdfTransform):
-                if len(sliding_window_transforms_group_by_keys) == 0:
-                    per_row_transform_feature_names.add(feature.name)
+                if len(sliding_features) == 0:
+                    pre_sliding_features.add(feature)
+                else:
+                    post_sliding_features.add(feature)
             else:
                 raise FeathubException(
                     f"Feature '{feature.name}' uses unsupported transform type "
                     f"'{type(transform)}'."
                 )
 
-        # TODO: validate that ExpressionTransform feature after the first
-        #  SlidingWindowTransform feature depends only on SlidingWindowTransform
-        #  features and their group-by keys.
-        invalid_expression_feature_names = set()
-        for per_row_transform_feature_name in per_row_transform_feature_names:
-            if (
-                per_row_transform_feature_name
-                not in sliding_window_transforms_group_by_keys
-            ):
-                invalid_expression_feature_names.add(per_row_transform_feature_name)
-        if len(invalid_expression_feature_names) != 0:
+        self._validate_pre_sliding_features(source, pre_sliding_features)
+        self._validate_sliding_features(source, pre_sliding_features, sliding_features)
+        self._validate_post_sliding_features(
+            sliding_features, post_sliding_features, self.timestamp_field
+        )
+
+    @staticmethod
+    def _validate_pre_sliding_features(
+        source: TableDescriptor, pre_sliding_features: Set[Feature]
+    ) -> None:
+        valid_variables = set([f.name for f in source.get_output_features()])
+
+        # Check if the pre sliding feature only depends on the features specified
+        # earlier or the features in the source table.
+        for feature in pre_sliding_features:
+            transform = feature.transform
+            if isinstance(transform, ExpressionTransform):
+                variables = get_variables(transform.expr)
+            elif isinstance(transform, PythonUdfTransform):
+                variables = {f.name for f in feature.input_features}
+            else:
+                raise FeathubException(
+                    f"Pre sliding feature '{feature.name}' uses unsupported transform "
+                    f"type '{type(transform)}'."
+                )
+
+            if not variables.issubset(valid_variables):
+                raise FeathubException(
+                    f"Feature {feature} should only depend on features specified "
+                    f"earlier or the features in the source table."
+                )
+            valid_variables.add(feature.name)
+
+    @staticmethod
+    def _validate_sliding_features(
+        source: TableDescriptor,
+        pre_sliding_features: Set[Feature],
+        sliding_features: Set[Feature],
+    ) -> None:
+        if len(sliding_features) < 1:
             raise FeathubException(
-                f"{invalid_expression_feature_names} are not used as grouping key of "
-                f"the sliding windows."
+                "SlidingWindowFeatureView must have at least one feature with "
+                "SlidingWindowTransform."
             )
 
-        group_by_keys = set(
+        valid_variables = {
+            *[f.name for f in source.get_output_features()],
+            *[f.name for f in pre_sliding_features],
+        }
+
+        # Check if the sliding feature only depends on the pre sliding features and
+        # the features in the source table.
+        sliding_window_transforms = []
+        for feature in sliding_features:
+            transform = feature.transform
+            if isinstance(transform, SlidingWindowTransform):
+                variables = set.union(
+                    get_variables(transform.filter_expr)
+                    if transform.filter_expr is not None
+                    else set(),
+                    get_variables(transform.expr),
+                    transform.group_by_keys,
+                )
+                sliding_window_transforms.append(transform)
+            else:
+                raise FeathubException(
+                    f"Sliding feature '{feature.name}' uses unsupported transform "
+                    f"type '{type(transform)}'."
+                )
+
+            if not variables.issubset(valid_variables):
+                raise FeathubException(
+                    f"Feature {feature} should only depend on features specified "
+                    f"earlier or the features in the source table."
+                )
+
+        group_by_keys_set = set(
             [tuple(transform.group_by_keys) for transform in sliding_window_transforms]
         )
-        if len(group_by_keys) > 1:
+        if len(group_by_keys_set) > 1:
             raise FeathubException(
                 f"SlidingWindowTransforms have different group-by keys "
-                f"{group_by_keys}."
+                f"{group_by_keys_set}."
             )
 
         steps = set([transform.step_size for transform in sliding_window_transforms])
         if len(steps) > 1:
             raise FeathubException(
                 f"SlidingWindowTransforms have different step size " f"{steps}."
             )
+
+        # Validate that the per-row transform features are used group-by-keys of
+        # SlidingWindowTransform.
+        invalid_expression_feature_names = set()
+        group_by_keys = group_by_keys_set.pop()
+        for feature in pre_sliding_features:
+            if feature.name not in group_by_keys:
+                invalid_expression_feature_names.add(feature.name)
+        if len(invalid_expression_feature_names) != 0:
+            raise FeathubException(
+                f"{invalid_expression_feature_names} are not used as grouping key of "
+                f"the sliding windows."
+            )
+
+    @staticmethod
+    def _validate_post_sliding_features(
+        sliding_features: Set[Feature],
+        post_sliding_features: Set[Feature],
+        timestamp_field: str,
+    ) -> None:
+        sliding_window_group_by_keys = cast(
+            SlidingWindowTransform, next(iter(sliding_features)).transform
+        ).group_by_keys
+        valid_variables = {
+            *[f.name for f in sliding_features],
+            timestamp_field,
+            *sliding_window_group_by_keys,
+        }
+        # Check if the post sliding feature only depends on the timestamp field,
+        # sliding window features and group-by keys.
+        for feature in post_sliding_features:
+            transform = feature.transform
+            if isinstance(transform, ExpressionTransform):
+                variables = get_variables(transform.expr)
+            elif isinstance(transform, PythonUdfTransform):
+                variables = {f.name for f in feature.input_features}
+            else:
+                raise FeathubException(
+                    f"Unexpected transformation: {transform} after sliding window."
+                )
+
+            if not variables.issubset(valid_variables):
+                raise FeathubException(
+                    f"Feature {feature} after sliding window should "
+                    f"only depend on timestamp field, sliding window features, or "
+                    f"group-by keys."
+                )
+            valid_variables.add(feature.name)
```

## feathub/feature_views/sql_feature_view.py

```diff
@@ -99,24 +99,27 @@
 
     def is_unresolved(self) -> bool:
         return False
 
     def get_output_fields(self, source_fields: List[str]) -> List[str]:
         return self.schema.field_names.copy()
 
+    def get_output_features(self) -> List[Feature]:
+        return [self.get_feature(field_name) for field_name in self.schema.field_names]
+
     def get_feature(self, feature_name: str) -> Feature:
         return Feature(
             name=feature_name,
             dtype=self.schema.get_field_type(feature_name),
             transform=feature_name,
             keys=self.keys,
         )
 
     def get_resolved_features(self) -> Sequence[Feature]:
-        return [self.get_feature(field_name) for field_name in self.schema.field_names]
+        return self.get_output_features()
 
     def get_resolved_source(self) -> TableDescriptor:
         raise FeathubException("Unsupported Operation.")
 
     def is_bounded(self) -> bool:
         return self._is_bounded
```

## feathub/feature_views/transforms/over_window_transform.py

```diff
@@ -53,15 +53,17 @@
                             with the same `group_by_keys` and filter expression result.
         :param limit: Optional. If it is not None, up to `limit` number of most recent
                       rows that match the `filter_expr` prior to this row can be
                       included in the aggregation.
         """
         super().__init__()
         self.expr = expr
-        self.agg_func = agg_func if isinstance(agg_func, AggFunc) else AggFunc(agg_func)
+        self.agg_func = (
+            agg_func if isinstance(agg_func, AggFunc) else AggFunc(agg_func.upper())
+        )
         self.group_by_keys = group_by_keys
         self.window_size = window_size
         self.filter_expr = filter_expr
         self.limit = limit
 
     def to_json(self) -> Dict:
         return {
```

## feathub/processors/flink/flink_processor.py

```diff
@@ -11,36 +11,40 @@
 #  WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
 #  See the License for the specific language governing permissions and
 #  limitations under the License.
 import logging
 import os
 from datetime import timedelta, datetime
 from typing import Optional, Union, Dict
+from urllib.parse import urlparse
 
 import pandas as pd
+from pyflink.common import Configuration
 from pyflink.datastream import StreamExecutionEnvironment
 from pyflink.table import (
     StreamTableEnvironment,
+    EnvironmentSettings,
 )
 
 from feathub.common.config import TIMEZONE_CONFIG
 from feathub.common.exceptions import (
     FeathubException,
+    FeathubConfigurationException,
 )
 from feathub.feature_tables.feature_table import FeatureTable
 from feathub.feature_views.feature_view import FeatureView
 from feathub.feature_views.sql_feature_view import SqlFeatureView
 from feathub.feature_views.transforms.join_transform import JoinTransform
 from feathub.processors.flink.flink_deployment_mode import DeploymentMode
 from feathub.processors.flink.flink_processor_config import (
     FlinkProcessorConfig,
     DEPLOYMENT_MODE_CONFIG,
-    REST_ADDRESS_CONFIG,
-    REST_PORT_CONFIG,
+    MASTER_CONFIG,
     NATIVE_CONFIG_PREFIX,
+    NATIVE_CONFIG_PROCESSOR_CONFIG_MAP,
 )
 from feathub.processors.flink.flink_table import FlinkTable
 from feathub.processors.flink.job_submitter.flink_job_submitter import FlinkJobSubmitter
 from feathub.processors.flink.job_submitter.flink_session_cluster_job_submitter import (
     FlinkSessionClusterJobSubmitter,
 )
 from feathub.processors.flink.table_builder.flink_table_builder import (
@@ -68,16 +72,15 @@
                          "kubernetes-application". Default to "session".
         native.*: Any key with the "native" prefix will be forwarded to the Flink job
                   config after the "native" prefix is removed. For example, if the
                   processor config has an entry "native.parallelism.default: 2",
                   then the Flink job config will have an entry "parallelism.default: 2".
 
     Extra config keys accepted when deployment_mode = "session":
-        rest.address: The ip or hostname where the JobManager runs. Required.
-        rest.port: The port where the JobManager runs. Required.
+        master: The Flink JobManager URL to connect to. Required.
 
     Extra config keys accepted when deployment_mode = "kubernetes-application":
         flink_home: The path to the Flink distribution. If not specified, it uses the
                     Flink's distribution in PyFlink.
         kubernetes.image: The docker image to start the JobManager and TaskManager pod.
                           Default to "feathub:latest".
         kubernetes.namespace: The namespace of the Kubernetes cluster to run the Flink
@@ -100,30 +103,44 @@
         try:
             self.deployment_mode = DeploymentMode(
                 self.config.get(DEPLOYMENT_MODE_CONFIG)
             )
         except ValueError:
             raise FeathubException("Unsupported deployment mode.")
 
-        if self.deployment_mode == DeploymentMode.CLI:
+        if self.deployment_mode == DeploymentMode.CLI or (
+            self.deployment_mode == DeploymentMode.SESSION
+            and self.config.get(MASTER_CONFIG) == "local"
+        ):
             self.flink_table_builder = FlinkTableBuilder(
                 self._get_table_env(), self.registry
             )
 
             # The type of flink_job_submitter is set explicitly to the base class
             # FlinkJobSubmitter so that the type checking won't complain.
             self.flink_job_submitter: FlinkJobSubmitter = (
                 FlinkSessionClusterJobSubmitter(self)
             )
         elif self.deployment_mode == DeploymentMode.SESSION:
-            jobmanager_rpc_address = self.config.get(REST_ADDRESS_CONFIG)
-            jobmanager_rpc_port = self.config.get(REST_PORT_CONFIG)
+            master = self.config.get(MASTER_CONFIG)
+            if master is None:
+                raise FeathubException(
+                    "master url containing host and port has to be set with session "
+                    "deployment mode."
+                )
+
+            parse_result = urlparse(master)
+            if not parse_result.scheme:
+                parse_result = urlparse("http://" + master)
+
+            jobmanager_rpc_address = parse_result.hostname
+            jobmanager_rpc_port = str(parse_result.port)
             if jobmanager_rpc_address is None or jobmanager_rpc_port is None:
                 raise FeathubException(
-                    "rest.address or rest.port has to be set with session "
+                    "master url containing host and port has to be set with session "
                     "deployment mode."
                 )
             self.flink_table_builder = FlinkTableBuilder(
                 self._get_table_env(jobmanager_rpc_address, jobmanager_rpc_port),
                 self.registry,
             )
             self.flink_job_submitter = FlinkSessionClusterJobSubmitter(self)
@@ -207,26 +224,42 @@
             # config. Currently, we work around by setting the environment. We should
             # initialize the StreamExecutionEnvironment with config after PyFlink 1.16.
             os.environ.setdefault(
                 "SUBMIT_ARGS",
                 f"remote -m {jobmanager_rpc_address}:{jobmanager_rpc_port}",
             )
 
-        env = StreamExecutionEnvironment.get_execution_environment()
-        table_env = StreamTableEnvironment.create(env)
-
-        table_env.get_config().set(
+        native_flink_config = Configuration()
+        native_flink_config.set_string(
             "table.local-time-zone", self.config.get(TIMEZONE_CONFIG)
         )
 
-        # TODO: report error when processor configs conflict with native.* configs.
+        prefix_len = len(NATIVE_CONFIG_PREFIX)
         for k, v in self.config.original_props_with_prefix(
-            NATIVE_CONFIG_PREFIX, True
+            NATIVE_CONFIG_PREFIX, False
         ).items():
-            table_env.get_config().set(k, v)
+            if (
+                k in NATIVE_CONFIG_PROCESSOR_CONFIG_MAP
+                and NATIVE_CONFIG_PROCESSOR_CONFIG_MAP[k] in self.config.config_values
+                and v
+                != self.config.config_values[NATIVE_CONFIG_PROCESSOR_CONFIG_MAP[k]]
+            ):
+                raise FeathubConfigurationException(
+                    f"Native config: {k} is conflict with processor config: "
+                    f"{NATIVE_CONFIG_PROCESSOR_CONFIG_MAP[k]}."
+                )
+            native_flink_config.set_string(k[prefix_len:], v)
+
+        env = StreamExecutionEnvironment.get_execution_environment()
+        table_env = StreamTableEnvironment.create(
+            env,
+            EnvironmentSettings.new_instance()
+            .with_configuration(native_flink_config)
+            .build(),
+        )
 
         if jobmanager_rpc_address is not None and jobmanager_rpc_port is not None:
             os.environ.pop("SUBMIT_ARGS")
 
         return table_env
 
     def _resolve_table_descriptor(
```

## feathub/processors/flink/flink_processor_config.py

```diff
@@ -10,29 +10,26 @@
 #  distributed under the License is distributed on an "AS IS" BASIS,
 #  WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
 #  See the License for the specific language governing permissions and
 #  limitations under the License.
 
 from typing import Dict, Any, List
 
-from feathub.common.config import ConfigDef
+from feathub.common.config import ConfigDef, TIMEZONE_CONFIG
 from feathub.common.validators import in_list
 from feathub.processors.flink.flink_deployment_mode import DeploymentMode
 from feathub.processors.processor_config import ProcessorConfig, PROCESSOR_PREFIX
 
 FLINK_PROCESSOR_PREFIX = PROCESSOR_PREFIX + "flink."
 
 DEPLOYMENT_MODE_CONFIG = FLINK_PROCESSOR_PREFIX + "deployment_mode"
 DEPLOYMENT_MODE_DOC = "The flink job deployment mode."
 
-REST_ADDRESS_CONFIG = FLINK_PROCESSOR_PREFIX + "rest.address"
-REST_ADDRESS_DOC = "The ip or hostname where the JobManager runs."
-
-REST_PORT_CONFIG = FLINK_PROCESSOR_PREFIX + "rest.port"
-REST_PORT_DOC = "The port where the JobManager runs."
+MASTER_CONFIG = FLINK_PROCESSOR_PREFIX + "master"
+MASTER_DOC = "The Flink JobManager URL to connect to."
 
 FLINK_HOME_CONFIG = FLINK_PROCESSOR_PREFIX + "flink_home"
 FLINK_HOME_DOC = (
     "The path to the Flink distribution. If not specified, it uses the "
     "Flink's distribution in PyFlink."
 )
 
@@ -56,23 +53,17 @@
         name=DEPLOYMENT_MODE_CONFIG,
         value_type=str,
         description=DEPLOYMENT_MODE_DOC,
         default_value="session",
         validator=in_list(*[t.value for t in DeploymentMode]),
     ),
     ConfigDef(
-        name=REST_ADDRESS_CONFIG,
+        name=MASTER_CONFIG,
         value_type=str,
-        description=REST_ADDRESS_DOC,
-        default_value=None,
-    ),
-    ConfigDef(
-        name=REST_PORT_CONFIG,
-        value_type=int,
-        description=REST_PORT_DOC,
+        description=MASTER_DOC,
         default_value=None,
     ),
     ConfigDef(
         name=FLINK_HOME_CONFIG,
         value_type=str,
         description=FLINK_HOME_DOC,
         default_value=None,
@@ -93,12 +84,22 @@
         name=KUBERNETES_CONFIG_FILE_CONFIG,
         value_type=str,
         description=KUBERNETES_CONFIG_FILE_DOC,
         default_value="~/.kube/config",
     ),
 ]
 
+# Map from native Flink configs to the corresponding FeatHub processor configs
+NATIVE_CONFIG_PROCESSOR_CONFIG_MAP = {
+    NATIVE_CONFIG_PREFIX + "rest.address": MASTER_CONFIG,
+    NATIVE_CONFIG_PREFIX + "rest.port": MASTER_CONFIG,
+    NATIVE_CONFIG_PREFIX + "kubernetes.container.image": KUBERNETES_IMAGE_CONFIG,
+    NATIVE_CONFIG_PREFIX + "kubernetes.namespace": KUBERNETES_NAMESPACE_CONFIG,
+    NATIVE_CONFIG_PREFIX + "kubernetes.config.file": KUBERNETES_CONFIG_FILE_CONFIG,
+    NATIVE_CONFIG_PREFIX + "table.local-time-zone": TIMEZONE_CONFIG,
+}
+
 
 class FlinkProcessorConfig(ProcessorConfig):
     def __init__(self, props: Dict[str, Any]) -> None:
         super().__init__(props)
         self.update_config_values(flink_processor_config_defs)
```

## feathub/processors/flink/lib/flink-connector-kafka-0.1-SNAPSHOT.jar

### zipinfo {}

```diff
@@ -1,22 +1,22 @@
-Zip file size: 13536 bytes, number of entries: 20
-drwxr-xr-x  2.0 unx        0 b- stor 23-Apr-12 16:18 META-INF/
--rw-r--r--  2.0 unx      132 b- defN 23-Apr-12 16:18 META-INF/MANIFEST.MF
-drwxr-xr-x  2.0 unx        0 b- stor 23-Apr-12 16:18 META-INF/services/
-drwxr-xr-x  2.0 unx        0 b- stor 23-Apr-12 16:18 org/
-drwxr-xr-x  2.0 unx        0 b- stor 23-Apr-12 16:18 org/apache/
-drwxr-xr-x  2.0 unx        0 b- stor 23-Apr-12 16:18 org/apache/flink/
-drwxr-xr-x  2.0 unx        0 b- stor 23-Apr-12 16:18 org/apache/flink/streaming/
-drwxr-xr-x  2.0 unx        0 b- stor 23-Apr-12 16:18 org/apache/flink/streaming/connectors/
-drwxr-xr-x  2.0 unx        0 b- stor 23-Apr-12 16:18 org/apache/flink/streaming/connectors/kafka/
-drwxr-xr-x  2.0 unx        0 b- stor 23-Apr-12 16:18 org/apache/flink/streaming/connectors/kafka/table/
--rw-r--r--  2.0 unx      671 b- defN 23-Apr-12 16:18 META-INF/services/org.apache.flink.table.factories.Factory
--rw-r--r--  2.0 unx    19353 b- defN 23-Apr-12 16:18 org/apache/flink/streaming/connectors/kafka/table/BoundedKafkaDynamicSource.class
--rw-r--r--  2.0 unx     1107 b- defN 23-Apr-12 16:18 org/apache/flink/streaming/connectors/kafka/table/BoundedKafkaDynamicSource$2.class
--rw-r--r--  2.0 unx     4590 b- defN 23-Apr-12 16:18 org/apache/flink/streaming/connectors/kafka/table/BoundedKafkaDynamicSource$1.class
--rw-r--r--  2.0 unx     4064 b- defN 23-Apr-12 16:18 org/apache/flink/streaming/connectors/kafka/table/BoundedKafkaDynamicTableFactory.class
-?rwsrwsrwt  2.0 unx        0 b- stor 23-Apr-12 16:18 META-INF/maven/
-?rwsrwsrwt  2.0 unx        0 b- stor 23-Apr-12 16:18 META-INF/maven/com.alibaba.feathub/
-?rwsrwsrwt  2.0 unx        0 b- stor 23-Apr-12 16:18 META-INF/maven/com.alibaba.feathub/flink-connector-kafka/
--rw-r--r--  2.0 unx     4197 b- defN 23-Apr-12 16:18 META-INF/maven/com.alibaba.feathub/flink-connector-kafka/pom.xml
--rw-r--r--  2.0 unx      132 b- defN 23-Apr-12 16:18 META-INF/maven/com.alibaba.feathub/flink-connector-kafka/pom.properties
-20 files, 34246 bytes uncompressed, 10250 bytes compressed:  70.1%
+Zip file size: 13537 bytes, number of entries: 20
+drwxr-xr-x  2.0 unx        0 b- stor 23-Apr-13 16:19 META-INF/
+-rw-r--r--  2.0 unx      132 b- defN 23-Apr-13 16:19 META-INF/MANIFEST.MF
+drwxr-xr-x  2.0 unx        0 b- stor 23-Apr-13 16:19 META-INF/services/
+drwxr-xr-x  2.0 unx        0 b- stor 23-Apr-13 16:19 org/
+drwxr-xr-x  2.0 unx        0 b- stor 23-Apr-13 16:19 org/apache/
+drwxr-xr-x  2.0 unx        0 b- stor 23-Apr-13 16:19 org/apache/flink/
+drwxr-xr-x  2.0 unx        0 b- stor 23-Apr-13 16:19 org/apache/flink/streaming/
+drwxr-xr-x  2.0 unx        0 b- stor 23-Apr-13 16:19 org/apache/flink/streaming/connectors/
+drwxr-xr-x  2.0 unx        0 b- stor 23-Apr-13 16:19 org/apache/flink/streaming/connectors/kafka/
+drwxr-xr-x  2.0 unx        0 b- stor 23-Apr-13 16:19 org/apache/flink/streaming/connectors/kafka/table/
+-rw-r--r--  2.0 unx      671 b- defN 23-Apr-13 16:19 META-INF/services/org.apache.flink.table.factories.Factory
+-rw-r--r--  2.0 unx    19353 b- defN 23-Apr-13 16:19 org/apache/flink/streaming/connectors/kafka/table/BoundedKafkaDynamicSource.class
+-rw-r--r--  2.0 unx     1107 b- defN 23-Apr-13 16:19 org/apache/flink/streaming/connectors/kafka/table/BoundedKafkaDynamicSource$2.class
+-rw-r--r--  2.0 unx     4590 b- defN 23-Apr-13 16:19 org/apache/flink/streaming/connectors/kafka/table/BoundedKafkaDynamicSource$1.class
+-rw-r--r--  2.0 unx     4064 b- defN 23-Apr-13 16:19 org/apache/flink/streaming/connectors/kafka/table/BoundedKafkaDynamicTableFactory.class
+?rwsrwsrwt  2.0 unx        0 b- stor 23-Apr-13 16:19 META-INF/maven/
+?rwsrwsrwt  2.0 unx        0 b- stor 23-Apr-13 16:19 META-INF/maven/com.alibaba.feathub/
+?rwsrwsrwt  2.0 unx        0 b- stor 23-Apr-13 16:19 META-INF/maven/com.alibaba.feathub/flink-connector-kafka/
+-rw-r--r--  2.0 unx     4197 b- defN 23-Apr-13 16:19 META-INF/maven/com.alibaba.feathub/flink-connector-kafka/pom.xml
+-rw-r--r--  2.0 unx      132 b- defN 23-Apr-13 16:19 META-INF/maven/com.alibaba.feathub/flink-connector-kafka/pom.properties
+20 files, 34246 bytes uncompressed, 10251 bytes compressed:  70.1%
```

### META-INF/maven/com.alibaba.feathub/flink-connector-kafka/pom.properties

```diff
@@ -1,5 +1,5 @@
 #Generated by Maven
-#Wed Apr 12 16:18:21 UTC 2023
+#Thu Apr 13 16:19:50 UTC 2023
 version=0.1-SNAPSHOT
 groupId=com.alibaba.feathub
 artifactId=flink-connector-kafka
```

## feathub/processors/flink/lib/flink-connector-redis-0.1-SNAPSHOT.jar

### zipinfo {}

```diff
@@ -1,23 +1,23 @@
-Zip file size: 13223 bytes, number of entries: 21
-drwxr-xr-x  2.0 unx        0 b- stor 23-Apr-12 16:18 META-INF/
--rw-r--r--  2.0 unx      132 b- defN 23-Apr-12 16:18 META-INF/MANIFEST.MF
-drwxr-xr-x  2.0 unx        0 b- stor 23-Apr-12 16:18 META-INF/services/
-drwxr-xr-x  2.0 unx        0 b- stor 23-Apr-12 16:18 com/
-drwxr-xr-x  2.0 unx        0 b- stor 23-Apr-12 16:18 com/alibaba/
-drwxr-xr-x  2.0 unx        0 b- stor 23-Apr-12 16:18 com/alibaba/feathub/
-drwxr-xr-x  2.0 unx        0 b- stor 23-Apr-12 16:18 com/alibaba/feathub/flink/
-drwxr-xr-x  2.0 unx        0 b- stor 23-Apr-12 16:18 com/alibaba/feathub/flink/connectors/
-drwxr-xr-x  2.0 unx        0 b- stor 23-Apr-12 16:18 com/alibaba/feathub/flink/connectors/redis/
-drwxr-xr-x  2.0 unx        0 b- stor 23-Apr-12 16:18 com/alibaba/feathub/flink/connectors/redis/sink/
--rw-r--r--  2.0 unx      666 b- defN 23-Apr-12 16:18 META-INF/services/org.apache.flink.table.factories.Factory
--rw-r--r--  2.0 unx     2950 b- defN 23-Apr-12 16:18 com/alibaba/feathub/flink/connectors/redis/sink/RedisSinkConfigs.class
--rw-r--r--  2.0 unx     3002 b- defN 23-Apr-12 16:18 com/alibaba/feathub/flink/connectors/redis/sink/RedisDynamicTableSinkFactory.class
--rw-r--r--  2.0 unx     2219 b- defN 23-Apr-12 16:18 com/alibaba/feathub/flink/connectors/redis/sink/RedisDynamicTableSink.class
--rw-r--r--  2.0 unx     9237 b- defN 23-Apr-12 16:18 com/alibaba/feathub/flink/connectors/redis/sink/RedisSinkFunction.class
--rw-r--r--  2.0 unx     1987 b- defN 23-Apr-12 16:18 com/alibaba/feathub/flink/connectors/redis/sink/script.lua
-?rwsrwsrwt  2.0 unx        0 b- stor 23-Apr-12 16:18 META-INF/maven/
-?rwsrwsrwt  2.0 unx        0 b- stor 23-Apr-12 16:18 META-INF/maven/com.alibaba.feathub/
-?rwsrwsrwt  2.0 unx        0 b- stor 23-Apr-12 16:18 META-INF/maven/com.alibaba.feathub/flink-connector-redis/
--rw-r--r--  2.0 unx     2595 b- defN 23-Apr-12 16:18 META-INF/maven/com.alibaba.feathub/flink-connector-redis/pom.xml
--rw-r--r--  2.0 unx      132 b- defN 23-Apr-12 16:18 META-INF/maven/com.alibaba.feathub/flink-connector-redis/pom.properties
-21 files, 22920 bytes uncompressed, 9819 bytes compressed:  57.2%
+Zip file size: 13224 bytes, number of entries: 21
+drwxr-xr-x  2.0 unx        0 b- stor 23-Apr-13 16:19 META-INF/
+-rw-r--r--  2.0 unx      132 b- defN 23-Apr-13 16:19 META-INF/MANIFEST.MF
+drwxr-xr-x  2.0 unx        0 b- stor 23-Apr-13 16:19 META-INF/services/
+drwxr-xr-x  2.0 unx        0 b- stor 23-Apr-13 16:19 com/
+drwxr-xr-x  2.0 unx        0 b- stor 23-Apr-13 16:19 com/alibaba/
+drwxr-xr-x  2.0 unx        0 b- stor 23-Apr-13 16:19 com/alibaba/feathub/
+drwxr-xr-x  2.0 unx        0 b- stor 23-Apr-13 16:19 com/alibaba/feathub/flink/
+drwxr-xr-x  2.0 unx        0 b- stor 23-Apr-13 16:19 com/alibaba/feathub/flink/connectors/
+drwxr-xr-x  2.0 unx        0 b- stor 23-Apr-13 16:19 com/alibaba/feathub/flink/connectors/redis/
+drwxr-xr-x  2.0 unx        0 b- stor 23-Apr-13 16:19 com/alibaba/feathub/flink/connectors/redis/sink/
+-rw-r--r--  2.0 unx      666 b- defN 23-Apr-13 16:19 META-INF/services/org.apache.flink.table.factories.Factory
+-rw-r--r--  2.0 unx     2950 b- defN 23-Apr-13 16:19 com/alibaba/feathub/flink/connectors/redis/sink/RedisSinkConfigs.class
+-rw-r--r--  2.0 unx     3002 b- defN 23-Apr-13 16:19 com/alibaba/feathub/flink/connectors/redis/sink/RedisDynamicTableSinkFactory.class
+-rw-r--r--  2.0 unx     2219 b- defN 23-Apr-13 16:19 com/alibaba/feathub/flink/connectors/redis/sink/RedisDynamicTableSink.class
+-rw-r--r--  2.0 unx     9237 b- defN 23-Apr-13 16:19 com/alibaba/feathub/flink/connectors/redis/sink/RedisSinkFunction.class
+-rw-r--r--  2.0 unx     1987 b- defN 23-Apr-13 16:19 com/alibaba/feathub/flink/connectors/redis/sink/script.lua
+?rwsrwsrwt  2.0 unx        0 b- stor 23-Apr-13 16:19 META-INF/maven/
+?rwsrwsrwt  2.0 unx        0 b- stor 23-Apr-13 16:19 META-INF/maven/com.alibaba.feathub/
+?rwsrwsrwt  2.0 unx        0 b- stor 23-Apr-13 16:19 META-INF/maven/com.alibaba.feathub/flink-connector-redis/
+-rw-r--r--  2.0 unx     2595 b- defN 23-Apr-13 16:19 META-INF/maven/com.alibaba.feathub/flink-connector-redis/pom.xml
+-rw-r--r--  2.0 unx      132 b- defN 23-Apr-13 16:19 META-INF/maven/com.alibaba.feathub/flink-connector-redis/pom.properties
+21 files, 22920 bytes uncompressed, 9820 bytes compressed:  57.2%
```

### META-INF/maven/com.alibaba.feathub/flink-connector-redis/pom.properties

```diff
@@ -1,5 +1,5 @@
 #Generated by Maven
-#Wed Apr 12 16:18:22 UTC 2023
+#Thu Apr 13 16:19:51 UTC 2023
 version=0.1-SNAPSHOT
 groupId=com.alibaba.feathub
 artifactId=flink-connector-redis
```

## feathub/processors/flink/lib/flink-udf-0.1-SNAPSHOT.jar

### zipinfo {}

```diff
@@ -1,62 +1,63 @@
-Zip file size: 83532 bytes, number of entries: 60
-drwxr-xr-x  2.0 unx        0 b- stor 23-Apr-12 16:18 META-INF/
--rw-r--r--  2.0 unx      132 b- defN 23-Apr-12 16:18 META-INF/MANIFEST.MF
-drwxr-xr-x  2.0 unx        0 b- stor 23-Apr-12 16:18 com/
-drwxr-xr-x  2.0 unx        0 b- stor 23-Apr-12 16:18 com/alibaba/
-drwxr-xr-x  2.0 unx        0 b- stor 23-Apr-12 16:18 com/alibaba/feathub/
-drwxr-xr-x  2.0 unx        0 b- stor 23-Apr-12 16:18 com/alibaba/feathub/flink/
-drwxr-xr-x  2.0 unx        0 b- stor 23-Apr-12 16:18 com/alibaba/feathub/flink/udf/
-drwxr-xr-x  2.0 unx        0 b- stor 23-Apr-12 16:18 com/alibaba/feathub/flink/udf/processfunction/
-drwxr-xr-x  2.0 unx        0 b- stor 23-Apr-12 16:18 com/alibaba/feathub/flink/udf/aggregation/
--rw-r--r--  2.0 unx     1994 b- defN 23-Apr-12 16:18 com/alibaba/feathub/flink/udf/UnixTimestampMillis.class
--rw-r--r--  2.0 unx     2535 b- defN 23-Apr-12 16:18 com/alibaba/feathub/flink/udf/TimeWindowedLastValueAggFunc.class
--rw-r--r--  2.0 unx     3789 b- defN 23-Apr-12 16:18 com/alibaba/feathub/flink/udf/SlidingWindowUtils$SingleDataToPreAggResultMapFunction.class
--rw-r--r--  2.0 unx     4674 b- defN 23-Apr-12 16:18 com/alibaba/feathub/flink/udf/TimeWindowedSumAggFunc.class
--rw-r--r--  2.0 unx     2051 b- defN 23-Apr-12 16:18 com/alibaba/feathub/flink/udf/TimeWindowedValueCountsAggFunc.class
--rw-r--r--  2.0 unx     2850 b- defN 23-Apr-12 16:18 com/alibaba/feathub/flink/udf/AbstractTimeWindowedAggFunc$TimeWindowedAccumulator.class
--rw-r--r--  2.0 unx     2015 b- defN 23-Apr-12 16:18 com/alibaba/feathub/flink/udf/AggregationFieldsDescriptor$Builder.class
--rw-r--r--  2.0 unx     7656 b- defN 23-Apr-12 16:18 com/alibaba/feathub/flink/udf/AbstractTimeWindowedAggFunc.class
--rw-r--r--  2.0 unx     4926 b- defN 23-Apr-12 16:18 com/alibaba/feathub/flink/udf/TimeWindowedMinAggFunc.class
--rw-r--r--  2.0 unx    14242 b- defN 23-Apr-12 16:18 com/alibaba/feathub/flink/udf/processfunction/SlidingWindowKeyedProcessFunction$SlidingWindowState.class
--rw-r--r--  2.0 unx    11860 b- defN 23-Apr-12 16:18 com/alibaba/feathub/flink/udf/processfunction/SlidingWindowKeyedProcessFunction.class
--rw-r--r--  2.0 unx     1915 b- defN 23-Apr-12 16:18 com/alibaba/feathub/flink/udf/processfunction/SlidingWindowZeroValuedRowExpiredRowHandler.class
--rw-r--r--  2.0 unx      428 b- defN 23-Apr-12 16:18 com/alibaba/feathub/flink/udf/processfunction/SlidingWindowExpiredRowHandler.class
--rw-r--r--  2.0 unx     4374 b- defN 23-Apr-12 16:18 com/alibaba/feathub/flink/udf/SlidingWindowUtils$SlidingWindowPreprocessAggregateFunction.class
--rw-r--r--  2.0 unx      289 b- defN 23-Apr-12 16:18 com/alibaba/feathub/flink/udf/AggregationFieldsDescriptor$1.class
--rw-r--r--  2.0 unx     4861 b- defN 23-Apr-12 16:18 com/alibaba/feathub/flink/udf/TimeWindowedAvgAggFunc.class
--rw-r--r--  2.0 unx      937 b- defN 23-Apr-12 16:18 com/alibaba/feathub/flink/udf/SlidingWindowUtils$2.class
--rw-r--r--  2.0 unx     5517 b- defN 23-Apr-12 16:18 com/alibaba/feathub/flink/udf/ValueCountsAggFunc.class
--rw-r--r--  2.0 unx     1275 b- defN 23-Apr-12 16:18 com/alibaba/feathub/flink/udf/TimeWindowedRowNumberAggFunc.class
--rw-r--r--  2.0 unx    25166 b- defN 23-Apr-12 16:18 com/alibaba/feathub/flink/udf/SlidingWindowUtils.class
--rw-r--r--  2.0 unx     2121 b- defN 23-Apr-12 16:18 com/alibaba/feathub/flink/udf/AggregationFieldsDescriptor$AggregationFieldDescriptor.class
--rw-r--r--  2.0 unx     1469 b- defN 23-Apr-12 16:18 com/alibaba/feathub/flink/udf/SlidingWindowDescriptor.class
--rw-r--r--  2.0 unx      947 b- defN 23-Apr-12 16:18 com/alibaba/feathub/flink/udf/SlidingWindowUtils$1.class
--rw-r--r--  2.0 unx     4926 b- defN 23-Apr-12 16:18 com/alibaba/feathub/flink/udf/TimeWindowedMaxAggFunc.class
--rw-r--r--  2.0 unx     3360 b- defN 23-Apr-12 16:18 com/alibaba/feathub/flink/udf/TimeWindowedFirstValueAggFunc.class
--rw-r--r--  2.0 unx     3400 b- defN 23-Apr-12 16:18 com/alibaba/feathub/flink/udf/aggregation/CountAggFunc.class
--rw-r--r--  2.0 unx     3297 b- defN 23-Apr-12 16:18 com/alibaba/feathub/flink/udf/aggregation/SumAggFunc$LongSumAggFunc.class
--rw-r--r--  2.0 unx     5608 b- defN 23-Apr-12 16:18 com/alibaba/feathub/flink/udf/aggregation/MinMaxAggFunc.class
--rw-r--r--  2.0 unx     3315 b- defN 23-Apr-12 16:18 com/alibaba/feathub/flink/udf/aggregation/SumAggFunc$FloatSumAggFunc.class
--rw-r--r--  2.0 unx     3335 b- defN 23-Apr-12 16:18 com/alibaba/feathub/flink/udf/aggregation/SumAggFunc$DoubleSumAggFunc.class
--rw-r--r--  2.0 unx     7325 b- defN 23-Apr-12 16:18 com/alibaba/feathub/flink/udf/aggregation/AvgAggFunc.class
--rw-r--r--  2.0 unx     6019 b- defN 23-Apr-12 16:18 com/alibaba/feathub/flink/udf/aggregation/AggFuncUtils.class
--rw-r--r--  2.0 unx     3335 b- defN 23-Apr-12 16:18 com/alibaba/feathub/flink/udf/aggregation/SumAggFunc$IntSumAggFunc.class
--rw-r--r--  2.0 unx     7164 b- defN 23-Apr-12 16:18 com/alibaba/feathub/flink/udf/aggregation/FirstLastValueAggFunc.class
--rw-r--r--  2.0 unx     4589 b- defN 23-Apr-12 16:18 com/alibaba/feathub/flink/udf/aggregation/FirstLastValueAggFuncWithoutRetract.class
--rw-r--r--  2.0 unx     4205 b- defN 23-Apr-12 16:18 com/alibaba/feathub/flink/udf/aggregation/MinMaxAggFuncWithoutRetract.class
--rw-r--r--  2.0 unx      960 b- defN 23-Apr-12 16:18 com/alibaba/feathub/flink/udf/aggregation/AggFunc.class
--rw-r--r--  2.0 unx     5164 b- defN 23-Apr-12 16:18 com/alibaba/feathub/flink/udf/aggregation/ValueCountsAggFunc.class
--rw-r--r--  2.0 unx      606 b- defN 23-Apr-12 16:18 com/alibaba/feathub/flink/udf/aggregation/CountAggFunc$CountAccumulator.class
--rw-r--r--  2.0 unx      838 b- defN 23-Apr-12 16:18 com/alibaba/feathub/flink/udf/aggregation/MinMaxAggFunc$MinMaxAccumulator.class
--rw-r--r--  2.0 unx      956 b- defN 23-Apr-12 16:18 com/alibaba/feathub/flink/udf/aggregation/FirstLastValueAggFunc$FirstLastValueAccumulator.class
--rw-r--r--  2.0 unx      903 b- defN 23-Apr-12 16:18 com/alibaba/feathub/flink/udf/aggregation/AggFuncWithLimit$RawDataAccumulator.class
--rw-r--r--  2.0 unx     2682 b- defN 23-Apr-12 16:18 com/alibaba/feathub/flink/udf/aggregation/SumAggFunc.class
--rw-r--r--  2.0 unx      709 b- defN 23-Apr-12 16:18 com/alibaba/feathub/flink/udf/aggregation/SumAggFunc$SumAccumulator.class
--rw-r--r--  2.0 unx     7606 b- defN 23-Apr-12 16:18 com/alibaba/feathub/flink/udf/aggregation/AggFuncWithLimit.class
--rw-r--r--  2.0 unx     4501 b- defN 23-Apr-12 16:18 com/alibaba/feathub/flink/udf/AggregationFieldsDescriptor.class
-?rwsrwsrwt  2.0 unx        0 b- stor 23-Apr-12 16:18 META-INF/maven/
-?rwsrwsrwt  2.0 unx        0 b- stor 23-Apr-12 16:18 META-INF/maven/com.alibaba.feathub/
-?rwsrwsrwt  2.0 unx        0 b- stor 23-Apr-12 16:18 META-INF/maven/com.alibaba.feathub/flink-udf/
--rw-r--r--  2.0 unx     3277 b- defN 23-Apr-12 16:18 META-INF/maven/com.alibaba.feathub/flink-udf/pom.xml
--rw-r--r--  2.0 unx      120 b- defN 23-Apr-12 16:18 META-INF/maven/com.alibaba.feathub/flink-udf/pom.properties
-60 files, 196223 bytes uncompressed, 71670 bytes compressed:  63.5%
+Zip file size: 84318 bytes, number of entries: 61
+drwxr-xr-x  2.0 unx        0 b- stor 23-Apr-13 16:19 META-INF/
+-rw-r--r--  2.0 unx      132 b- defN 23-Apr-13 16:19 META-INF/MANIFEST.MF
+drwxr-xr-x  2.0 unx        0 b- stor 23-Apr-13 16:19 com/
+drwxr-xr-x  2.0 unx        0 b- stor 23-Apr-13 16:19 com/alibaba/
+drwxr-xr-x  2.0 unx        0 b- stor 23-Apr-13 16:19 com/alibaba/feathub/
+drwxr-xr-x  2.0 unx        0 b- stor 23-Apr-13 16:19 com/alibaba/feathub/flink/
+drwxr-xr-x  2.0 unx        0 b- stor 23-Apr-13 16:19 com/alibaba/feathub/flink/udf/
+drwxr-xr-x  2.0 unx        0 b- stor 23-Apr-13 16:19 com/alibaba/feathub/flink/udf/processfunction/
+drwxr-xr-x  2.0 unx        0 b- stor 23-Apr-13 16:19 com/alibaba/feathub/flink/udf/aggregation/
+-rw-r--r--  2.0 unx     1994 b- defN 23-Apr-13 16:19 com/alibaba/feathub/flink/udf/UnixTimestampMillis.class
+-rw-r--r--  2.0 unx     2535 b- defN 23-Apr-13 16:19 com/alibaba/feathub/flink/udf/TimeWindowedLastValueAggFunc.class
+-rw-r--r--  2.0 unx     3789 b- defN 23-Apr-13 16:19 com/alibaba/feathub/flink/udf/SlidingWindowUtils$SingleDataToPreAggResultMapFunction.class
+-rw-r--r--  2.0 unx     4674 b- defN 23-Apr-13 16:19 com/alibaba/feathub/flink/udf/TimeWindowedSumAggFunc.class
+-rw-r--r--  2.0 unx     2051 b- defN 23-Apr-13 16:19 com/alibaba/feathub/flink/udf/TimeWindowedValueCountsAggFunc.class
+-rw-r--r--  2.0 unx     2850 b- defN 23-Apr-13 16:19 com/alibaba/feathub/flink/udf/AbstractTimeWindowedAggFunc$TimeWindowedAccumulator.class
+-rw-r--r--  2.0 unx     2015 b- defN 23-Apr-13 16:19 com/alibaba/feathub/flink/udf/AggregationFieldsDescriptor$Builder.class
+-rw-r--r--  2.0 unx     7656 b- defN 23-Apr-13 16:19 com/alibaba/feathub/flink/udf/AbstractTimeWindowedAggFunc.class
+-rw-r--r--  2.0 unx     4926 b- defN 23-Apr-13 16:19 com/alibaba/feathub/flink/udf/TimeWindowedMinAggFunc.class
+-rw-r--r--  2.0 unx     1307 b- defN 23-Apr-13 16:19 com/alibaba/feathub/flink/udf/TimeWindowedCountAggFunc.class
+-rw-r--r--  2.0 unx    14242 b- defN 23-Apr-13 16:19 com/alibaba/feathub/flink/udf/processfunction/SlidingWindowKeyedProcessFunction$SlidingWindowState.class
+-rw-r--r--  2.0 unx    11860 b- defN 23-Apr-13 16:19 com/alibaba/feathub/flink/udf/processfunction/SlidingWindowKeyedProcessFunction.class
+-rw-r--r--  2.0 unx     1915 b- defN 23-Apr-13 16:19 com/alibaba/feathub/flink/udf/processfunction/SlidingWindowZeroValuedRowExpiredRowHandler.class
+-rw-r--r--  2.0 unx      428 b- defN 23-Apr-13 16:19 com/alibaba/feathub/flink/udf/processfunction/SlidingWindowExpiredRowHandler.class
+-rw-r--r--  2.0 unx     4374 b- defN 23-Apr-13 16:19 com/alibaba/feathub/flink/udf/SlidingWindowUtils$SlidingWindowPreprocessAggregateFunction.class
+-rw-r--r--  2.0 unx      289 b- defN 23-Apr-13 16:19 com/alibaba/feathub/flink/udf/AggregationFieldsDescriptor$1.class
+-rw-r--r--  2.0 unx     4861 b- defN 23-Apr-13 16:19 com/alibaba/feathub/flink/udf/TimeWindowedAvgAggFunc.class
+-rw-r--r--  2.0 unx      937 b- defN 23-Apr-13 16:19 com/alibaba/feathub/flink/udf/SlidingWindowUtils$2.class
+-rw-r--r--  2.0 unx     5517 b- defN 23-Apr-13 16:19 com/alibaba/feathub/flink/udf/ValueCountsAggFunc.class
+-rw-r--r--  2.0 unx     1275 b- defN 23-Apr-13 16:19 com/alibaba/feathub/flink/udf/TimeWindowedRowNumberAggFunc.class
+-rw-r--r--  2.0 unx    25166 b- defN 23-Apr-13 16:19 com/alibaba/feathub/flink/udf/SlidingWindowUtils.class
+-rw-r--r--  2.0 unx     2121 b- defN 23-Apr-13 16:19 com/alibaba/feathub/flink/udf/AggregationFieldsDescriptor$AggregationFieldDescriptor.class
+-rw-r--r--  2.0 unx     1469 b- defN 23-Apr-13 16:19 com/alibaba/feathub/flink/udf/SlidingWindowDescriptor.class
+-rw-r--r--  2.0 unx      947 b- defN 23-Apr-13 16:19 com/alibaba/feathub/flink/udf/SlidingWindowUtils$1.class
+-rw-r--r--  2.0 unx     4926 b- defN 23-Apr-13 16:19 com/alibaba/feathub/flink/udf/TimeWindowedMaxAggFunc.class
+-rw-r--r--  2.0 unx     3360 b- defN 23-Apr-13 16:19 com/alibaba/feathub/flink/udf/TimeWindowedFirstValueAggFunc.class
+-rw-r--r--  2.0 unx     3400 b- defN 23-Apr-13 16:19 com/alibaba/feathub/flink/udf/aggregation/CountAggFunc.class
+-rw-r--r--  2.0 unx     3297 b- defN 23-Apr-13 16:19 com/alibaba/feathub/flink/udf/aggregation/SumAggFunc$LongSumAggFunc.class
+-rw-r--r--  2.0 unx     5608 b- defN 23-Apr-13 16:19 com/alibaba/feathub/flink/udf/aggregation/MinMaxAggFunc.class
+-rw-r--r--  2.0 unx     3315 b- defN 23-Apr-13 16:19 com/alibaba/feathub/flink/udf/aggregation/SumAggFunc$FloatSumAggFunc.class
+-rw-r--r--  2.0 unx     3335 b- defN 23-Apr-13 16:19 com/alibaba/feathub/flink/udf/aggregation/SumAggFunc$DoubleSumAggFunc.class
+-rw-r--r--  2.0 unx     7325 b- defN 23-Apr-13 16:19 com/alibaba/feathub/flink/udf/aggregation/AvgAggFunc.class
+-rw-r--r--  2.0 unx     6019 b- defN 23-Apr-13 16:19 com/alibaba/feathub/flink/udf/aggregation/AggFuncUtils.class
+-rw-r--r--  2.0 unx     3335 b- defN 23-Apr-13 16:19 com/alibaba/feathub/flink/udf/aggregation/SumAggFunc$IntSumAggFunc.class
+-rw-r--r--  2.0 unx     7164 b- defN 23-Apr-13 16:19 com/alibaba/feathub/flink/udf/aggregation/FirstLastValueAggFunc.class
+-rw-r--r--  2.0 unx     4589 b- defN 23-Apr-13 16:19 com/alibaba/feathub/flink/udf/aggregation/FirstLastValueAggFuncWithoutRetract.class
+-rw-r--r--  2.0 unx     4205 b- defN 23-Apr-13 16:19 com/alibaba/feathub/flink/udf/aggregation/MinMaxAggFuncWithoutRetract.class
+-rw-r--r--  2.0 unx      960 b- defN 23-Apr-13 16:19 com/alibaba/feathub/flink/udf/aggregation/AggFunc.class
+-rw-r--r--  2.0 unx     5164 b- defN 23-Apr-13 16:19 com/alibaba/feathub/flink/udf/aggregation/ValueCountsAggFunc.class
+-rw-r--r--  2.0 unx      606 b- defN 23-Apr-13 16:19 com/alibaba/feathub/flink/udf/aggregation/CountAggFunc$CountAccumulator.class
+-rw-r--r--  2.0 unx      838 b- defN 23-Apr-13 16:19 com/alibaba/feathub/flink/udf/aggregation/MinMaxAggFunc$MinMaxAccumulator.class
+-rw-r--r--  2.0 unx      956 b- defN 23-Apr-13 16:19 com/alibaba/feathub/flink/udf/aggregation/FirstLastValueAggFunc$FirstLastValueAccumulator.class
+-rw-r--r--  2.0 unx      903 b- defN 23-Apr-13 16:19 com/alibaba/feathub/flink/udf/aggregation/AggFuncWithLimit$RawDataAccumulator.class
+-rw-r--r--  2.0 unx     2682 b- defN 23-Apr-13 16:19 com/alibaba/feathub/flink/udf/aggregation/SumAggFunc.class
+-rw-r--r--  2.0 unx      709 b- defN 23-Apr-13 16:19 com/alibaba/feathub/flink/udf/aggregation/SumAggFunc$SumAccumulator.class
+-rw-r--r--  2.0 unx     7606 b- defN 23-Apr-13 16:19 com/alibaba/feathub/flink/udf/aggregation/AggFuncWithLimit.class
+-rw-r--r--  2.0 unx     4501 b- defN 23-Apr-13 16:19 com/alibaba/feathub/flink/udf/AggregationFieldsDescriptor.class
+?rwsrwsrwt  2.0 unx        0 b- stor 23-Apr-13 16:19 META-INF/maven/
+?rwsrwsrwt  2.0 unx        0 b- stor 23-Apr-13 16:19 META-INF/maven/com.alibaba.feathub/
+?rwsrwsrwt  2.0 unx        0 b- stor 23-Apr-13 16:19 META-INF/maven/com.alibaba.feathub/flink-udf/
+-rw-r--r--  2.0 unx     3277 b- defN 23-Apr-13 16:19 META-INF/maven/com.alibaba.feathub/flink-udf/pom.xml
+-rw-r--r--  2.0 unx      120 b- defN 23-Apr-13 16:19 META-INF/maven/com.alibaba.feathub/flink-udf/pom.properties
+61 files, 197530 bytes uncompressed, 72260 bytes compressed:  63.4%
```

### zipnote TEMP/diffoscope_59ggxh_3_/tmp43hzuw4q_.zip

```diff
@@ -48,14 +48,17 @@
 
 Filename: com/alibaba/feathub/flink/udf/AbstractTimeWindowedAggFunc.class
 Comment: 
 
 Filename: com/alibaba/feathub/flink/udf/TimeWindowedMinAggFunc.class
 Comment: 
 
+Filename: com/alibaba/feathub/flink/udf/TimeWindowedCountAggFunc.class
+Comment: 
+
 Filename: com/alibaba/feathub/flink/udf/processfunction/SlidingWindowKeyedProcessFunction$SlidingWindowState.class
 Comment: 
 
 Filename: com/alibaba/feathub/flink/udf/processfunction/SlidingWindowKeyedProcessFunction.class
 Comment: 
 
 Filename: com/alibaba/feathub/flink/udf/processfunction/SlidingWindowZeroValuedRowExpiredRowHandler.class
```

### META-INF/maven/com.alibaba.feathub/flink-udf/pom.properties

```diff
@@ -1,5 +1,5 @@
 #Generated by Maven
-#Wed Apr 12 16:18:26 UTC 2023
+#Thu Apr 13 16:19:54 UTC 2023
 version=0.1-SNAPSHOT
 groupId=com.alibaba.feathub
 artifactId=flink-udf
```

## feathub/processors/flink/table_builder/flink_table_builder.py

```diff
@@ -663,15 +663,18 @@
             )
         return table
 
     def _get_output_fields(
         self, feature_view: FeatureView, source_fields: List[str]
     ) -> List[str]:
         output_fields = feature_view.get_output_fields(source_fields)
-        if EVENT_TIME_ATTRIBUTE_NAME not in output_fields:
+        if (
+            EVENT_TIME_ATTRIBUTE_NAME not in output_fields
+            and feature_view.timestamp_field is not None
+        ):
             output_fields.append(EVENT_TIME_ATTRIBUTE_NAME)
         return output_fields
 
     @staticmethod
     def _get_feature_valid_time(
         table_descriptor: TableDescriptor, feature_name: str
     ) -> Optional[timedelta]:
```

## feathub/processors/flink/table_builder/over_window_utils.py

```diff
@@ -225,14 +225,16 @@
             interval_expr,
             expr,
             native_flink_expr.col(EVENT_TIME_ATTRIBUTE_NAME),
         ).over(native_flink_expr.col(window_alias))
 
     if agg_func == AggFunc.AVG:
         result = expr.avg
+    elif agg_func == AggFunc.COUNT:
+        result = expr.count
     elif agg_func == AggFunc.MIN:
         result = expr.min
     elif agg_func == AggFunc.MAX:
         result = expr.max
     elif agg_func == AggFunc.SUM:
         result = expr.sum
     elif agg_func == AggFunc.VALUE_COUNTS:
```

## feathub/processors/flink/table_builder/udf.py

```diff
@@ -64,14 +64,17 @@
     )
 }
 
 ROW_AND_TIME_BASED_OVER_WINDOW_JAVA_UDF: Dict[AggFunc, JavaUDFDescriptor] = {
     AggFunc.AVG: JavaUDFDescriptor(
         "TIME_WINDOWED_AVG", "com.alibaba.feathub.flink.udf.TimeWindowedAvgAggFunc"
     ),
+    AggFunc.COUNT: JavaUDFDescriptor(
+        "TIME_WINDOWED_COUNT", "com.alibaba.feathub.flink.udf.TimeWindowedCountAggFunc"
+    ),
     AggFunc.SUM: JavaUDFDescriptor(
         "TIME_WINDOWED_SUM", "com.alibaba.feathub.flink.udf.TimeWindowedSumAggFunc"
     ),
     AggFunc.MIN: JavaUDFDescriptor(
         "TIME_WINDOWED_MIN", "com.alibaba.feathub.flink.udf.TimeWindowedMinAggFunc"
     ),
     AggFunc.MAX: JavaUDFDescriptor(
```

## feathub/processors/spark/spark_processor.py

```diff
@@ -16,29 +16,30 @@
 from typing import Union, Optional, Dict
 
 import pandas as pd
 from pyspark.sql import DataFrame as NativeSparkDataFrame
 from pyspark.sql import SparkSession
 
 from feathub.common.config import TIMEZONE_CONFIG
-from feathub.common.exceptions import FeathubException
+from feathub.common.exceptions import FeathubException, FeathubConfigurationException
 from feathub.feature_tables.feature_table import FeatureTable
 from feathub.feature_views.feature_view import FeatureView
 from feathub.processors.processor import Processor
 from feathub.processors.spark.dataframe_builder.source_sink_utils import (
     insert_into_sink,
 )
 from feathub.processors.spark.dataframe_builder.spark_dataframe_builder import (
     SparkDataFrameBuilder,
 )
 from feathub.processors.spark.spark_job import SparkJob
 from feathub.processors.spark.spark_processor_config import (
     SparkProcessorConfig,
     MASTER_CONFIG,
     NATIVE_CONFIG_PREFIX,
+    NATIVE_CONFIG_PROCESSOR_CONFIG_MAP,
 )
 from feathub.processors.spark.spark_table import SparkTable
 from feathub.registries.registry import Registry
 from feathub.table.table_descriptor import TableDescriptor
 
 
 class SparkProcessor(Processor):
@@ -68,18 +69,29 @@
         config = SparkProcessorConfig(props)
 
         spark_session_builder = SparkSession.builder
         spark_session_builder = spark_session_builder.master(config.get(MASTER_CONFIG))
         spark_session_builder = spark_session_builder.config(
             "spark.sql.session.timeZone", config.get(TIMEZONE_CONFIG)
         )
+
+        prefix_len = len(NATIVE_CONFIG_PREFIX)
         for k, v in config.original_props_with_prefix(
-            NATIVE_CONFIG_PREFIX, True
+            NATIVE_CONFIG_PREFIX, False
         ).items():
-            spark_session_builder = spark_session_builder.config(k, v)
+            if (
+                k in NATIVE_CONFIG_PROCESSOR_CONFIG_MAP
+                and NATIVE_CONFIG_PROCESSOR_CONFIG_MAP[k] in config.config_values
+                and v != config.config_values[NATIVE_CONFIG_PROCESSOR_CONFIG_MAP[k]]
+            ):
+                raise FeathubConfigurationException(
+                    f"Native config: {k} is conflict with processor config: "
+                    f"{NATIVE_CONFIG_PROCESSOR_CONFIG_MAP[k]}."
+                )
+            spark_session_builder = spark_session_builder.config(k[prefix_len:], v)
         spark_session = spark_session_builder.getOrCreate()
 
         self._dataframe_builder = SparkDataFrameBuilder(spark_session, self._registry)
 
         self._executor = ThreadPoolExecutor()
 
     def get_table(
```

## feathub/processors/spark/spark_processor_config.py

```diff
@@ -9,32 +9,38 @@
 #  Unless required by applicable law or agreed to in writing, software
 #  distributed under the License is distributed on an "AS IS" BASIS,
 #  WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
 #  See the License for the specific language governing permissions and
 #  limitations under the License.
 from typing import List, Dict, Any
 
-from feathub.common.config import ConfigDef
+from feathub.common.config import ConfigDef, TIMEZONE_CONFIG
+from feathub.common.validators import not_none
 from feathub.processors.processor_config import ProcessorConfig, PROCESSOR_PREFIX
 
 SPARK_PROCESSOR_PREFIX = PROCESSOR_PREFIX + "spark."
 
 MASTER_CONFIG = SPARK_PROCESSOR_PREFIX + "master"
 MASTER_DOC = "The Spark master URL to connect to."
 
 NATIVE_CONFIG_PREFIX = SPARK_PROCESSOR_PREFIX + "native."
 
-# TODO: Add a validator class that are used to validate the legality of
-#  configuration values, and validate that spark master is not None.
 spark_processor_config_defs: List[ConfigDef] = [
     ConfigDef(
         name=MASTER_CONFIG,
         value_type=str,
         description=MASTER_DOC,
+        validator=not_none(),
     ),
 ]
 
+# Map from native Spark configs to the corresponding FeatHub processor configs
+NATIVE_CONFIG_PROCESSOR_CONFIG_MAP = {
+    NATIVE_CONFIG_PREFIX + "spark.master": MASTER_CONFIG,
+    NATIVE_CONFIG_PREFIX + "spark.sql.session.timeZone": TIMEZONE_CONFIG,
+}
+
 
 class SparkProcessorConfig(ProcessorConfig):
     def __init__(self, props: Dict[str, Any]) -> None:
         super().__init__(props)
         self.update_config_values(spark_processor_config_defs)
```

## Comparing `feathub_nightly-0.1.dev20230412.dist-info/METADATA` & `feathub_nightly-0.1.dev20230413.dist-info/METADATA`

 * *Files 2% similar despite different names*

```diff
@@ -1,10 +1,10 @@
 Metadata-Version: 2.1
 Name: feathub-nightly
-Version: 0.1.dev20230412
+Version: 0.1.dev20230413
 Summary: A stream-batch unified feature store for real-time machine learning
 Home-page: https://github.com/alibaba/feathub
 Author: FeatHub Authors
 License: https://www.apache.org/licenses/LICENSE-2.0
 Requires-Python: >=3.6
 Requires-Dist: scikit-learn
 Requires-Dist: ply (>=3.11)
```

## Comparing `feathub_nightly-0.1.dev20230412.dist-info/RECORD` & `feathub_nightly-0.1.dev20230413.dist-info/RECORD`

 * *Files 3% similar despite different names*

```diff
@@ -1,27 +1,29 @@
 feathub/__init__.py,sha256=fvVsQBNJAiCaTMxIn_toKCsehRAmMNzTuOv0enkmbXk,584
 feathub/feathub_client.py,sha256=5D_wPmaKSyM-TSuJyAXVKMoktK2ok_IDskI8a7xAQLI,7406
 feathub/version.py,sha256=G_00bytUfZ1JSWdG8sHhM_cER61k0Y8_3Jph1u0A-Sk,700
 feathub/common/__init__.py,sha256=fvVsQBNJAiCaTMxIn_toKCsehRAmMNzTuOv0enkmbXk,584
-feathub/common/config.py,sha256=W5VbvOrkVfff00IH1QzqfZInj92Z0RgdlESSacwyHkA,5943
+feathub/common/config.py,sha256=2UIW87RD7JCXsJDykf3mIQlIu4_Ajm33m0IKWvv7QwA,5931
 feathub/common/exceptions.py,sha256=t3AItgKwKgpCjykFouHhg1G0Dv5S_nleZ5WjW_hTGu4,1176
 feathub/common/test_utils.py,sha256=qOYPgwiPGJdRDYdGRbaSiqxbTaDf04fu5Cml86V5vkI,1168
-feathub/common/types.py,sha256=J0b3kfRYxENmq81-kMwDX5Jyt-I_lL0tzd6kMLKTHlM,4724
+feathub/common/types.py,sha256=ZHUbLiJoKcFFRCJWJN_txTFrbfkhV6_3WO9KQZUphJQ,4789
 feathub/common/utils.py,sha256=CAENkHgafpZOTLSgC4mUPnhV221du-igSMiNa6wdkEs,6950
-feathub/common/validators.py,sha256=Epvnp9WKedh3Mq8oibniB-fDsEBpy7h5PCt2qd0H9Eg,2431
+feathub/common/validators.py,sha256=GrqSllvKR_iRbGo1uj9iVLL4Caq6Mq8s50uP3DTKcq8,2702
 feathub/common/protobuf/__init__.py,sha256=fvVsQBNJAiCaTMxIn_toKCsehRAmMNzTuOv0enkmbXk,584
 feathub/common/protobuf/value_pb2.py,sha256=aLg0OEHajhvghKanI1V8PuEz_vYBPXr6AQ9AZ3pGNEM,12527
 feathub/dsl/__init__.py,sha256=fvVsQBNJAiCaTMxIn_toKCsehRAmMNzTuOv0enkmbXk,584
 feathub/dsl/abstract_ast_evaluator.py,sha256=s2qFnmDpq-Q0d7Dg3pkRNsxwChJE2tuTaUamI0zbRBU,4257
-feathub/dsl/ast.py,sha256=hnP-ROBbS3SUOFmRFINGPfLzzzWNq5CzBUyEluzFWpc,11411
+feathub/dsl/ast.py,sha256=BhTpIhaWJd-1JPL_n9ayJQpxscSMY40mISbq9g99qYk,10819
+feathub/dsl/built_in_func.py,sha256=QEVG555Kv7E-HotkJ2OMPCEpdgtV2s7mjo7mEUPFJcU,1587
 feathub/dsl/expr_lexer_rules.py,sha256=Nh69SLwK9v4OneFvwE5UeymnEuy9WNuMRrX7JRUrTec,3653
 feathub/dsl/expr_parser.py,sha256=5wSFFCsCAAss3J5o69DLCMGaFEUsAh592ELmEaQhfp4,6283
+feathub/dsl/expr_utils.py,sha256=QRSr5GgTN2SBEJmZZTYz3INliZewBqVr9VujE2MolZ0,1182
 feathub/examples/__init__.py,sha256=fvVsQBNJAiCaTMxIn_toKCsehRAmMNzTuOv0enkmbXk,584
 feathub/examples/nyc_taxi.py,sha256=ZYLdGXfXHhOV5adzdjUC_6WD0Zl2o-HBcViE5uBvqFE,8975
-feathub/examples/nyc_taxi_flink_session.py,sha256=SF4eU-XErAXJXBvj-EUqTmFgiBT-31k-TN3iRdsOdmI,1550
+feathub/examples/nyc_taxi_flink_session.py,sha256=fH5Bo_5ZLFiB6Y6acmdzZqcGvcorbnKnaPYs06-AFDg,1510
 feathub/examples/nyc_taxi_spark_client.py,sha256=eKl474UheAZZVLOZFeSpHtMKO1mG1GS7AAzrrLaO4g0,1262
 feathub/examples/sample_data.csv,sha256=RayfpUI60-vXj6WAo9mCTvYbbCF4SUm9O-DZFgpgzPk,885
 feathub/examples/streaming_average_flink_cli.py,sha256=TEJRFx6YyisdmEbWifYWEFoRKD1qSdlMnkYLDZGsSt8,2825
 feathub/feature_service/__init__.py,sha256=fvVsQBNJAiCaTMxIn_toKCsehRAmMNzTuOv0enkmbXk,584
 feathub/feature_service/feature_service.py,sha256=ntPVluWvYUknQI6A25eL1yMwtg-9iQYRg7lZ_Ru3ZLQ,3264
 feathub/feature_service/feature_service_config.py,sha256=zv8EiaVdabfN1Pxoegd4QlROKLG0Zto9jvcEtfvZKHM,1440
 feathub/feature_service/local_feature_service.py,sha256=LMkcwf7_wd4_fUv_RnWcTlFtklh050rzo2E96GySEBc,6396
@@ -40,25 +42,25 @@
 feathub/feature_tables/sources/datagen_source.py,sha256=voeSq3fCE5w3hEiYFJEOEvCQ_xNF3DXqtIhRhpH5ljo,7977
 feathub/feature_tables/sources/file_system_source.py,sha256=SnWvOqkDe3QGTw5ZhmPD2THBEMt09GEgs-DvOR5rlZM,3525
 feathub/feature_tables/sources/kafka_source.py,sha256=OvUM6zYv46QSjgqSOewZnoXAXCB47Aw30JQddRwcZ_c,7819
 feathub/feature_tables/sources/memory_store_source.py,sha256=djxkqqn5CiR5vZ4tXwF1H3sH0TZvYU-mKgU34Ze2Iy0,2219
 feathub/feature_tables/sources/mysql_source.py,sha256=D-XkLYeEhVoAd9zVC85aOdYsBGabKzjRGJuCdpCyV-w,4018
 feathub/feature_tables/sources/redis_source.py,sha256=0UflnW3xjUWtxh7D9xV8euTuHGg-LQ0-WytRXdf-4bU,3466
 feathub/feature_views/__init__.py,sha256=fvVsQBNJAiCaTMxIn_toKCsehRAmMNzTuOv0enkmbXk,584
-feathub/feature_views/derived_feature_view.py,sha256=pgzA9YFtgtaqfQpPfBTJAn8fcEBndnxpvIsE9Yd0Xz8,6900
-feathub/feature_views/feature.py,sha256=fXQD6AHwqeBsvoPbisg9BEl0cTtpYEbrMg_J4jiBBFY,4263
-feathub/feature_views/feature_view.py,sha256=6i-X-rjflx6iuxRKua8uuF34or1TB7bIsxyI9SNivBQ,11082
-feathub/feature_views/on_demand_feature_view.py,sha256=7WcqRoqvPjrTqmZ7IL3m1kjcCgfLeOx72q8-pF3bXZo,6549
-feathub/feature_views/sliding_feature_view.py,sha256=zj3_mSgxY1hYwxdJ22DXuwWUlcLziU-Xlfh8QUMFoYw,15520
-feathub/feature_views/sql_feature_view.py,sha256=1GA2_RvBXwFeaLEwqdkVKPSxL2W4mlxXOn1vk-sjIrY,5572
+feathub/feature_views/derived_feature_view.py,sha256=9GTrjNtoLvjHKC_CRCKo7cNGUQ6ixsOYmhPxCZL5w1M,8600
+feathub/feature_views/feature.py,sha256=9U4t_ZQ6OOw-XFzWxl5Y7wFfMy6Fw0xWxK9yfDbWNEk,4422
+feathub/feature_views/feature_view.py,sha256=ZKrkLJy0pQuBiWjviowI1iKw2meXDBJjAcemTL3oelc,10955
+feathub/feature_views/on_demand_feature_view.py,sha256=peGUqc4b8iJb8YUkOsGQLkOuHTsqcDxCilmYTse5EGU,6531
+feathub/feature_views/sliding_feature_view.py,sha256=iqM051Z6nhTeKDQ0EykBW97Dl7QAwVpvgHO8l6e_kyM,19810
+feathub/feature_views/sql_feature_view.py,sha256=7psSNe-hioTw8EKLHXY9cwqKVZgYDTYdAHxxf6BL3kc,5667
 feathub/feature_views/transforms/__init__.py,sha256=fvVsQBNJAiCaTMxIn_toKCsehRAmMNzTuOv0enkmbXk,584
 feathub/feature_views/transforms/agg_func.py,sha256=qnUYYLhO_2MRg9-56OfeTOC61xiwf-qfMWNvPTRAAXY,1649
 feathub/feature_views/transforms/expression_transform.py,sha256=Xdd51d7bviYbnsnE_oqnbkf4mwJbIKzJNIc0BGtFNkM,1214
 feathub/feature_views/transforms/join_transform.py,sha256=Igf0w1XacOUfyC4eCiGVZ1EnbSizcaPf-kUtrDfiark,1349
-feathub/feature_views/transforms/over_window_transform.py,sha256=YpCfN_43NMiUUIqHdZD608aXyHrPP_9uMNAa_3yia3U,3633
+feathub/feature_views/transforms/over_window_transform.py,sha256=plWpFHKtZPeKfXH7tOwmvD0L2og2BKZahHm4vd_4GUc,3665
 feathub/feature_views/transforms/python_udf_transform.py,sha256=wv3uTpGwYd3iRc4VfRjqqGoXba_irKxcNhdRVkl4SjU,1279
 feathub/feature_views/transforms/sliding_window_transform.py,sha256=hjZpn0NBzmfKp_SlcDXRNycTQc41KE0h6os32lByWfY,2973
 feathub/feature_views/transforms/transformation.py,sha256=t1GtNFlYIUkInjmOIqPiqeh0Qgdmc1h_m32ZgI_28MM,1099
 feathub/online_stores/__init__.py,sha256=qM9qwkokBFEmrO8pQrXAgpfz6aG97eW3YEetP_4fCVI,545
 feathub/online_stores/memory_online_store.py,sha256=FidvhiWsl3kAJtde7M9Pk1khJDulQIJVF3fsc8wJJsQ,7568
 feathub/online_stores/mysql_client.py,sha256=7tZazSto8NygYpwxxkguhXmFNoe0cFCVzgDfoH5nQTU,3631
 feathub/online_stores/online_store_client.py,sha256=lMATqDprPWhEDZ4ayaodhajDl1WFLCmfvStwBPPFd_0,3291
@@ -68,72 +70,72 @@
 feathub/processors/processor.py,sha256=vb6hVpwfTZ7Q-ELJI9KJi184cznEHaJsfwFTQZOr7qc,6027
 feathub/processors/processor_config.py,sha256=9zn3aeDlUmBrb8X2K04scsave68lNJMTA3UFy1b5ajY,1404
 feathub/processors/processor_job.py,sha256=xXNscH0_F1uoK-KAD0kLldnMdud7P84bGsG2j27P8-k,1678
 feathub/processors/type_utils.py,sha256=fpnp83zRhDqlKiSuMJ_lja8s8pJ32rjq3YrIQfx1MkE,1808
 feathub/processors/flink/__init__.py,sha256=SIne6c7qilEN5W5uo6EtOnWGCf8Kdbnug3U7BZHleeU,594
 feathub/processors/flink/flink_deployment_mode.py,sha256=qvtKQwFIRudyHufsXaaC2mYVPrp_99V9TL39Br95EbE,775
 feathub/processors/flink/flink_jar_utils.py,sha256=wkjX8saLML6mNF-u2Yqyf1Hvm3JITUPm7383sqVpoyg,2513
-feathub/processors/flink/flink_processor.py,sha256=gqYBqtrYta6ukPx5nNzFoiGTmQagem2VeBYdMGmMTQU,11040
-feathub/processors/flink/flink_processor_config.py,sha256=gysObF89vL7rvrBbn1gmDgshx8GKZleGTGQSVo2HteU,3491
+feathub/processors/flink/flink_processor.py,sha256=q2qBoX8w5Kg5m1xUQkyeEDA-ZEphzNfR_9RArRvqpXw,12308
+feathub/processors/flink/flink_processor_config.py,sha256=vCZKLS-huhNwzqXgbtj7GOUpjt0FqCJaWgGGu9WoVsI,3770
 feathub/processors/flink/flink_table.py,sha256=0BQYDB-LCYZ3aCvblqIN19nOlEmA7MvbBIIDNVfWGMw,7579
 feathub/processors/flink/flink_types_utils.py,sha256=LzJG62PP5rIY7juybDsDjT4ScpUScou4FgBGTi6uBck,5313
 feathub/processors/flink/ast_evaluator/__init__.py,sha256=SIne6c7qilEN5W5uo6EtOnWGCf8Kdbnug3U7BZHleeU,594
 feathub/processors/flink/ast_evaluator/flink_ast_evaluator.py,sha256=Q7P4tcNmjoMR2NRXoocJR__aJVQ40olCutDeVDCKA8M,4179
 feathub/processors/flink/ast_evaluator/functions.py,sha256=5NRuhx4p__a5RQWHuQ4XQ1Xp8liAzgpzqWz9mt6n2pQ,1240
 feathub/processors/flink/job_submitter/__init__.py,sha256=DFjRrB1Wfhl3vbfRjZz_TbV3UxYm8DC1IdHD0PHKpE4,863
 feathub/processors/flink/job_submitter/feathub_job_descriptor.py,sha256=TcdjEmNtzPJpvpmoYbJkmMMa8l-trB3CHKCGGkGRoM4,3905
 feathub/processors/flink/job_submitter/flink_application_cluster_job_entry.py,sha256=yc0KjVs1R0sPWQ1nuOMMTSLNRkVz4a1tmJ2u0AqP1RY,2951
 feathub/processors/flink/job_submitter/flink_job_submitter.py,sha256=3LXRbqYHCgPXE1PPs1K1Wjet1tlXx3xGVJsngGidu2A,3277
 feathub/processors/flink/job_submitter/flink_kubernetes_application_cluster_job_submitter.py,sha256=nV4DG8u3Eq30Hd2SHxi6PbSElhhRj--LUCvgOcm-RdU,10326
 feathub/processors/flink/job_submitter/flink_session_cluster_job_submitter.py,sha256=sdWJYTXvLrBNWOfgkqviA6eo2W37ruAh4G-F4_aOLGA,5428
 feathub/processors/flink/lib/flink-connector-jdbc-1.15.2.jar,sha256=tBlAfNWxaedYcfbymXbnnDgiGSWl6FjZJqTJVbgeFgc,250072
-feathub/processors/flink/lib/flink-connector-kafka-0.1-SNAPSHOT.jar,sha256=WwgIlpI41PHFX35LcmJaAjE1KagBwgD3YLNiTZJff30,13536
-feathub/processors/flink/lib/flink-connector-redis-0.1-SNAPSHOT.jar,sha256=hg19vfChzlAwGB9QBALmaYPGNOLtpCZT0lKpNdbFqFo,13223
+feathub/processors/flink/lib/flink-connector-kafka-0.1-SNAPSHOT.jar,sha256=OvMLlZPa9zo2gOcdqNUV-b-tGPVHRO27srJZpqTP7Cc,13537
+feathub/processors/flink/lib/flink-connector-redis-0.1-SNAPSHOT.jar,sha256=rKyKuSvtD89xuETzTSfW8KlZAbLzhS_EOVEVtDYFyw8,13224
 feathub/processors/flink/lib/flink-shaded-force-shading-15.0.jar,sha256=r_J1ifRuSlCJb8ZKdodAYX3WDqiqHqIgmOAZNRH5m98,6776
 feathub/processors/flink/lib/flink-sql-connector-kafka-1.15.2.jar,sha256=eHrROWeitjQEJnZbaY8hqkHM1QMOm7uksP2qUxupU1I,5179853
-feathub/processors/flink/lib/flink-udf-0.1-SNAPSHOT.jar,sha256=baJFZyZgiWxzKKV0NP-2YhvutrAwEas-wx2qds0k6os,83532
+feathub/processors/flink/lib/flink-udf-0.1-SNAPSHOT.jar,sha256=LPoaV5PoV6g0D8-JrCZ7LV6QDHaazg4C9gUhBWVkf-A,84318
 feathub/processors/flink/lib/gson-2.8.9.jar,sha256=05mSkYVd5JXJTHQ3YbirUXbP6r4oGlqw2OjUUyb9cD4,258075
 feathub/processors/flink/lib/jedis-4.3.0.jar,sha256=5a4-2FsXwB7BT1MBVLK8tX9m2ciD8ldCuXsHelkwpy8,792882
 feathub/processors/flink/lib/mysql-connector-j-8.0.32.jar,sha256=UiMp_pJZgPAuXribWdInJF00VBX_DAiTKmjJdlwTrMU,2480823
 feathub/processors/flink/lib/protobuf-java-3.21.9.jar,sha256=G3i0p2pxUS3r_f-Pj8Wu9r_UWfZXWP7Pev8kXm5jAeQ,1671409
 feathub/processors/flink/table_builder/__init__.py,sha256=SIne6c7qilEN5W5uo6EtOnWGCf8Kdbnug3U7BZHleeU,594
 feathub/processors/flink/table_builder/aggregation_utils.py,sha256=1v7L98RghH0QSGv5Ii7hLODgX2H_tcABbpXJToMXnZ8,3399
 feathub/processors/flink/table_builder/black_hole_utils.py,sha256=PGgpt9hnpdv0uoCiPNIwkgN9FRHwU6t9rgWY3ZPYSF8,907
 feathub/processors/flink/table_builder/datagen_utils.py,sha256=RwJdt6F1AvzHB39ZQDytUd6ZczXYLjh0N42YcfOYgsk,3892
 feathub/processors/flink/table_builder/file_system_utils.py,sha256=dnxtWVY5BW8PD6hVfee04sLDGmRrsgw6AV4-FzdELng,2932
 feathub/processors/flink/table_builder/flink_sql_expr_utils.py,sha256=NxLlyCB7eCd_mAAKZjwLg3fFtRed7KpmzplQEjbQOkk,1129
-feathub/processors/flink/table_builder/flink_table_builder.py,sha256=0j42EgVGLSiOQ2iydBPinIeIOP6--CeZXsc4RN2uYtU,29158
+feathub/processors/flink/table_builder/flink_table_builder.py,sha256=Dghdh_MkKyiTTjHURSXntYf8m4XamH-XD83gIpLJ80s,29239
 feathub/processors/flink/table_builder/join_utils.py,sha256=cWUyKiS0diJt0sSecWHlupXxhOVj7qZVMyYDZ1XnhZU,11454
 feathub/processors/flink/table_builder/kafka_utils.py,sha256=QZNWiGW3FyT96IcEHcqICWHhsOByZgZIa9cd6zyd2Dk,8725
 feathub/processors/flink/table_builder/mysql_utils.py,sha256=6yS8R7Y0_Nsn6E2HP0a3-hJY7KMR6uhUUvFnfaOl_4g,2900
-feathub/processors/flink/table_builder/over_window_utils.py,sha256=iMn5Ht9SzPcdH5ElBPvg6U3JiBVk-DfOkLyJq06_EyY,8585
+feathub/processors/flink/table_builder/over_window_utils.py,sha256=gPNmNU87jYWbwTWhTMXS4vBZo_j3-r0xMXIQNXdlTcs,8649
 feathub/processors/flink/table_builder/print_utils.py,sha256=Ga4I9Y8IDuioMBd8ahVqSZj_h9KVLbAeMB7tjiP93OE,1061
 feathub/processors/flink/table_builder/python_udf_utils.py,sha256=N6m5r_3ZmJmq8CtV5wMoJVXpadAZBkEb6MjTijsIhBQ,2928
 feathub/processors/flink/table_builder/redis_utils.py,sha256=cKUNhGCG904LKNsOzluOd_OheH6EmS0RdgcWm_3FQ-M,6258
 feathub/processors/flink/table_builder/sliding_window_utils.py,sha256=hSBHqKT4HwihCc2UC4L7iYLXyDKxr8SV_oYNsj4wx9c,6987
 feathub/processors/flink/table_builder/source_sink_utils.py,sha256=5Mfbixk_VdsGV_VJ7ax1IFSEe1_SPe5Syjb18ll0GZw,3954
 feathub/processors/flink/table_builder/source_sink_utils_common.py,sha256=daKTh5lTCAHTm-PGbK0x64Yio05VvS8OkLV07hANnSI,4051
 feathub/processors/flink/table_builder/time_utils.py,sha256=AEVCWyIz7Nvt-Odj-x7vXCCYSYwD7t9iPqbftfbbZww,1605
-feathub/processors/flink/table_builder/udf.py,sha256=JAKkLypZg1IM_WtvH7L6ScFNlHU1nif35UBriiwq-ts,3979
+feathub/processors/flink/table_builder/udf.py,sha256=3Pct26F8ZZjsy07rO_4hNBOhNjApzhRZJKXeFA1yhnE,4112
 feathub/processors/local/__init__.py,sha256=SIne6c7qilEN5W5uo6EtOnWGCf8Kdbnug3U7BZHleeU,594
 feathub/processors/local/aggregation_utils.py,sha256=jmWt-S2XGvk7xIWfWQCqVBj_kirZ4uu7IHNKCEeBmXc,1327
 feathub/processors/local/file_system_utils.py,sha256=5HOmU1sXOSJsJqcKAQ7PUrNdaRIDZwCGb6uxvpUWflk,2565
 feathub/processors/local/local_job.py,sha256=SEi0x-dJIGl5EfiieaRuGqhlo6G4NXE9b9fqPV8xWA8,1011
 feathub/processors/local/local_processor.py,sha256=9Zpizb3f2STMnDAh_DfH5PCWDx3bu2xLTJIpD1QnL7I,25001
 feathub/processors/local/local_processor_config.py,sha256=kJqoFGTFJayA-8EFsmZhWQzPsBJ8jeGdIKDDCgJ2X4M,715
 feathub/processors/local/local_table.py,sha256=1zs6jqk4M10k9kd0FcTqZP0h9CEsYinHBckQv08q3Ys,2337
 feathub/processors/local/sliding_window_utils.py,sha256=xIbmx1EzIIo1BN959-N11h6X_BS29lYmAGF6JIqakq8,11599
 feathub/processors/local/time_utils.py,sha256=IbWLOgPK8RxAc9X_VQj3XxGkKg5rsiSs2pF8xTJ8aaY,1531
 feathub/processors/local/ast_evaluator/__init__.py,sha256=SIne6c7qilEN5W5uo6EtOnWGCf8Kdbnug3U7BZHleeU,594
 feathub/processors/local/ast_evaluator/local_ast_evaluator.py,sha256=-poiKchNPQ0Mhmu4neIzy4CS_sEdIjF_Y9fc8ZCOiyA,7203
 feathub/processors/local/ast_evaluator/local_func_evaluator.py,sha256=elm2f0HbgHBbOsK0Ftuk4NfF0BpVrbV1GuEm_xHRQxI,1293
 feathub/processors/spark/__init__.py,sha256=SIne6c7qilEN5W5uo6EtOnWGCf8Kdbnug3U7BZHleeU,594
 feathub/processors/spark/spark_job.py,sha256=SToO1oP35_ec-ptXIB179nf5ekmDUaeg_W7TTs-BX-Y,1872
-feathub/processors/spark/spark_processor.py,sha256=8DkdGqmXrb3vTm-5UKDEZb8xINXyU6oJWzE7QcnNaXo,5602
-feathub/processors/spark/spark_processor_config.py,sha256=pfxukSscHwmtKEkrwM2HM_HV0OH2YME20iiinDeYA6s,1467
+feathub/processors/spark/spark_processor.py,sha256=YhbmMQAOc6RC-W6SDY0NgYTBdRdUPcvZk-J1zKUdalU,6203
+feathub/processors/spark/spark_processor_config.py,sha256=vVuypDQSZsEVJbiKUIDouaAGHd_Xoa3rk6iN8SFPKNA,1673
 feathub/processors/spark/spark_table.py,sha256=kdqQk3opVCfBxEYEe7vqM8hJBNaBWBUaR5i23k6kmiQ,5315
 feathub/processors/spark/spark_types_utils.py,sha256=peQhJwMOG_4OnwMGm5DJkbe7hzM23cMbTXtTsyipaoU,5787
 feathub/processors/spark/ast_evaluator/__init__.py,sha256=fvVsQBNJAiCaTMxIn_toKCsehRAmMNzTuOv0enkmbXk,584
 feathub/processors/spark/ast_evaluator/functions.py,sha256=Ij2mkP2Jf-Ecy2UoqBDcexoZMXZ6LOZ0I9vS4J5jOow,1246
 feathub/processors/spark/ast_evaluator/spark_ast_evaluator.py,sha256=tPrPwzwNb5DkECcQyOGa-KN5xyD2VFTp-8rfS44V6CI,4179
 feathub/processors/spark/dataframe_builder/__init__.py,sha256=SIne6c7qilEN5W5uo6EtOnWGCf8Kdbnug3U7BZHleeU,594
 feathub/processors/spark/dataframe_builder/aggregation_utils.py,sha256=5hU6ZY5mZUlHbyObuOiYuq5s0Dd72FsEE6Yi76qK3Yk,2296
@@ -149,12 +151,12 @@
 feathub/registries/local_registry.py,sha256=6_ZbtMCcxA0Y9nBwlQwuOgsmb2cccdrJGuL7rVRSztc,3583
 feathub/registries/registry.py,sha256=T8_LGvllx3xHY5mk8Rj719-dXAsyaaqF7VVuBR0TnoU,4636
 feathub/registries/registry_config.py,sha256=7C34zjnuGatR7vddlYNRqSvaxbD8E2ay_-AUQzHVLwk,1351
 feathub/table/__init__.py,sha256=fvVsQBNJAiCaTMxIn_toKCsehRAmMNzTuOv0enkmbXk,584
 feathub/table/schema.py,sha256=BjPDlDhzrd9TULn47bgLa1UhiuTKQERpeZ_w8lom7zg,3508
 feathub/table/table.py,sha256=yvkIWJ35vVSJ3VAy44dsow7uW9q87w4cuRoUuoV30nQ,2800
 feathub/table/table_descriptor.py,sha256=D2lJYWKxrHFgydoEi_fHBoZXRAsPeUqpI2HHDP7UAfo,5237
-feathub_nightly-0.1.dev20230412.dist-info/METADATA,sha256=5Ei1fCOBxdyokXz6YxP8U1tkjloe_15umXDK3UjixPQ,792
-feathub_nightly-0.1.dev20230412.dist-info/WHEEL,sha256=pkctZYzUS4AYVn6dJ-7367OJZivF2e8RA9b_ZBjif18,92
-feathub_nightly-0.1.dev20230412.dist-info/top_level.txt,sha256=NWOlHcZJJalZhUStdSeC5GUiwRhNoX8hzDvwxfBE7R4,8
-feathub_nightly-0.1.dev20230412.dist-info/zip-safe,sha256=AbpHGcgLb-kRsJGnwFEktk7uzpZOCcBY74-YBdrKVGs,1
-feathub_nightly-0.1.dev20230412.dist-info/RECORD,,
+feathub_nightly-0.1.dev20230413.dist-info/METADATA,sha256=kWPze46MLMxCzMmNhyCwpziLV35DvelQcilZMtj4V60,792
+feathub_nightly-0.1.dev20230413.dist-info/WHEEL,sha256=pkctZYzUS4AYVn6dJ-7367OJZivF2e8RA9b_ZBjif18,92
+feathub_nightly-0.1.dev20230413.dist-info/top_level.txt,sha256=NWOlHcZJJalZhUStdSeC5GUiwRhNoX8hzDvwxfBE7R4,8
+feathub_nightly-0.1.dev20230413.dist-info/zip-safe,sha256=AbpHGcgLb-kRsJGnwFEktk7uzpZOCcBY74-YBdrKVGs,1
+feathub_nightly-0.1.dev20230413.dist-info/RECORD,,
```

