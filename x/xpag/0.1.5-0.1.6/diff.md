# Comparing `tmp/xpag-0.1.5-py3-none-any.whl.zip` & `tmp/xpag-0.1.6-py3-none-any.whl.zip`

## zipinfo {}

```diff
@@ -1,42 +1,42 @@
-Zip file size: 55006 bytes, number of entries: 40
--rw-r--r--  2.0 unx      211 b- defN 23-Mar-29 20:01 xpag/__init__.py
--rw-r--r--  2.0 unx      204 b- defN 23-Mar-29 20:01 xpag/agents/__init__.py
--rw-r--r--  2.0 unx     1098 b- defN 23-Mar-29 20:01 xpag/agents/agent.py
--rw-r--r--  2.0 unx        0 b- defN 23-Mar-29 20:01 xpag/agents/sac/__init__.py
--rw-r--r--  2.0 unx     5554 b- defN 23-Mar-29 20:01 xpag/agents/sac/sac.py
--rw-r--r--  2.0 unx    18817 b- defN 23-Mar-29 20:01 xpag/agents/sac/sac_from_jaxrl.py
--rw-r--r--  2.0 unx        0 b- defN 23-Mar-29 20:01 xpag/agents/sdqn/__init__.py
--rw-r--r--  2.0 unx    22063 b- defN 23-Mar-29 20:01 xpag/agents/sdqn/sdqn.py
--rw-r--r--  2.0 unx        0 b- defN 23-Mar-29 20:01 xpag/agents/td3/__init__.py
--rw-r--r--  2.0 unx    15221 b- defN 23-Mar-29 20:01 xpag/agents/td3/td3.py
--rw-r--r--  2.0 unx        0 b- defN 23-Mar-29 20:01 xpag/agents/tqc/__init__.py
--rw-r--r--  2.0 unx    12988 b- defN 23-Mar-29 20:01 xpag/agents/tqc/tqc.py
--rw-r--r--  2.0 unx      160 b- defN 23-Mar-29 20:01 xpag/buffers/__init__.py
--rw-r--r--  2.0 unx    11221 b- defN 23-Mar-29 20:01 xpag/buffers/buffer.py
--rw-r--r--  2.0 unx     5236 b- defN 23-Mar-29 20:01 xpag/buffers/jax_buffer.py
--rw-r--r--  2.0 unx       55 b- defN 23-Mar-29 20:01 xpag/plotting/__init__.py
--rw-r--r--  2.0 unx     4124 b- defN 23-Mar-29 20:01 xpag/plotting/plotting.py
--rw-r--r--  2.0 unx     2841 b- defN 23-Mar-29 20:01 xpag/samplers/HER.py
--rw-r--r--  2.0 unx      182 b- defN 23-Mar-29 20:01 xpag/samplers/__init__.py
--rw-r--r--  2.0 unx     2941 b- defN 23-Mar-29 20:01 xpag/samplers/jax_sampler.py
--rw-r--r--  2.0 unx     1829 b- defN 23-Mar-29 20:01 xpag/samplers/sampler.py
--rw-r--r--  2.0 unx       71 b- defN 23-Mar-29 20:01 xpag/setters/__init__.py
--rw-r--r--  2.0 unx     3734 b- defN 23-Mar-29 20:01 xpag/setters/setter.py
--rw-r--r--  2.0 unx      438 b- defN 23-Mar-29 20:01 xpag/tools/__init__.py
--rw-r--r--  2.0 unx     5609 b- defN 23-Mar-29 20:01 xpag/tools/eval.py
--rw-r--r--  2.0 unx     7611 b- defN 23-Mar-29 20:01 xpag/tools/learn.py
--rw-r--r--  2.0 unx     3225 b- defN 23-Mar-29 20:01 xpag/tools/logging.py
--rw-r--r--  2.0 unx     5063 b- defN 23-Mar-29 20:01 xpag/tools/replay.py
--rw-r--r--  2.0 unx      899 b- defN 23-Mar-29 20:01 xpag/tools/timing.py
--rw-r--r--  2.0 unx     4836 b- defN 23-Mar-29 20:01 xpag/tools/utils.py
--rw-r--r--  2.0 unx      179 b- defN 23-Mar-29 20:01 xpag/wrappers/__init__.py
--rw-r--r--  2.0 unx     9130 b- defN 23-Mar-29 20:01 xpag/wrappers/brax_vec_env.py
--rw-r--r--  2.0 unx     6071 b- defN 23-Mar-29 20:01 xpag/wrappers/goalenv_wrapper.py
--rw-r--r--  2.0 unx    10125 b- defN 23-Mar-29 20:01 xpag/wrappers/gym_vec_env.py
--rw-r--r--  2.0 unx      936 b- defN 23-Mar-29 20:01 xpag/wrappers/reset_done.py
--rw-r--r--  2.0 unx     1517 b- defN 23-Mar-29 20:01 xpag-0.1.5.dist-info/LICENSE
--rw-r--r--  2.0 unx    15081 b- defN 23-Mar-29 20:01 xpag-0.1.5.dist-info/METADATA
--rw-r--r--  2.0 unx       92 b- defN 23-Mar-29 20:01 xpag-0.1.5.dist-info/WHEEL
--rw-r--r--  2.0 unx        5 b- defN 23-Mar-29 20:01 xpag-0.1.5.dist-info/top_level.txt
--rw-rw-r--  2.0 unx     3184 b- defN 23-Mar-29 20:01 xpag-0.1.5.dist-info/RECORD
-40 files, 182551 bytes uncompressed, 49984 bytes compressed:  72.6%
+Zip file size: 54964 bytes, number of entries: 40
+-rw-r--r--  2.0 unx      211 b- defN 23-Apr-14 14:32 xpag/__init__.py
+-rw-r--r--  2.0 unx      204 b- defN 23-Apr-14 14:32 xpag/agents/__init__.py
+-rw-r--r--  2.0 unx     1098 b- defN 23-Apr-14 14:32 xpag/agents/agent.py
+-rw-r--r--  2.0 unx        0 b- defN 23-Apr-14 14:32 xpag/agents/sac/__init__.py
+-rw-r--r--  2.0 unx     5554 b- defN 23-Apr-14 14:32 xpag/agents/sac/sac.py
+-rw-r--r--  2.0 unx    18817 b- defN 23-Apr-14 14:32 xpag/agents/sac/sac_from_jaxrl.py
+-rw-r--r--  2.0 unx        0 b- defN 23-Apr-14 14:32 xpag/agents/sdqn/__init__.py
+-rw-r--r--  2.0 unx    22063 b- defN 23-Apr-14 14:32 xpag/agents/sdqn/sdqn.py
+-rw-r--r--  2.0 unx        0 b- defN 23-Apr-14 14:32 xpag/agents/td3/__init__.py
+-rw-r--r--  2.0 unx    15221 b- defN 23-Apr-14 14:32 xpag/agents/td3/td3.py
+-rw-r--r--  2.0 unx        0 b- defN 23-Apr-14 14:32 xpag/agents/tqc/__init__.py
+-rw-r--r--  2.0 unx    12988 b- defN 23-Apr-14 14:32 xpag/agents/tqc/tqc.py
+-rw-r--r--  2.0 unx      160 b- defN 23-Apr-14 14:32 xpag/buffers/__init__.py
+-rw-r--r--  2.0 unx    11221 b- defN 23-Apr-14 14:32 xpag/buffers/buffer.py
+-rw-r--r--  2.0 unx     5236 b- defN 23-Apr-14 14:32 xpag/buffers/jax_buffer.py
+-rw-r--r--  2.0 unx       55 b- defN 23-Apr-14 14:32 xpag/plotting/__init__.py
+-rw-r--r--  2.0 unx     4124 b- defN 23-Apr-14 14:32 xpag/plotting/plotting.py
+-rw-r--r--  2.0 unx     2841 b- defN 23-Apr-14 14:32 xpag/samplers/HER.py
+-rw-r--r--  2.0 unx      182 b- defN 23-Apr-14 14:32 xpag/samplers/__init__.py
+-rw-r--r--  2.0 unx     2941 b- defN 23-Apr-14 14:32 xpag/samplers/jax_sampler.py
+-rw-r--r--  2.0 unx     1829 b- defN 23-Apr-14 14:32 xpag/samplers/sampler.py
+-rw-r--r--  2.0 unx       71 b- defN 23-Apr-14 14:32 xpag/setters/__init__.py
+-rw-r--r--  2.0 unx     3734 b- defN 23-Apr-14 14:32 xpag/setters/setter.py
+-rw-r--r--  2.0 unx      438 b- defN 23-Apr-14 14:32 xpag/tools/__init__.py
+-rw-r--r--  2.0 unx     5065 b- defN 23-Apr-14 14:32 xpag/tools/eval.py
+-rw-r--r--  2.0 unx     7611 b- defN 23-Apr-14 14:32 xpag/tools/learn.py
+-rw-r--r--  2.0 unx     3225 b- defN 23-Apr-14 14:32 xpag/tools/logging.py
+-rw-r--r--  2.0 unx     4694 b- defN 23-Apr-14 14:32 xpag/tools/replay.py
+-rw-r--r--  2.0 unx      899 b- defN 23-Apr-14 14:32 xpag/tools/timing.py
+-rw-r--r--  2.0 unx     5273 b- defN 23-Apr-14 14:32 xpag/tools/utils.py
+-rw-r--r--  2.0 unx      179 b- defN 23-Apr-14 14:32 xpag/wrappers/__init__.py
+-rw-r--r--  2.0 unx     8833 b- defN 23-Apr-14 14:32 xpag/wrappers/brax_vec_env.py
+-rw-r--r--  2.0 unx     6071 b- defN 23-Apr-14 14:32 xpag/wrappers/goalenv_wrapper.py
+-rw-r--r--  2.0 unx    10125 b- defN 23-Apr-14 14:32 xpag/wrappers/gym_vec_env.py
+-rw-r--r--  2.0 unx      936 b- defN 23-Apr-14 14:32 xpag/wrappers/reset_done.py
+-rw-r--r--  2.0 unx     1517 b- defN 23-Apr-14 14:32 xpag-0.1.6.dist-info/LICENSE
+-rw-r--r--  2.0 unx    15079 b- defN 23-Apr-14 14:32 xpag-0.1.6.dist-info/METADATA
+-rw-r--r--  2.0 unx       92 b- defN 23-Apr-14 14:32 xpag-0.1.6.dist-info/WHEEL
+-rw-r--r--  2.0 unx        5 b- defN 23-Apr-14 14:32 xpag-0.1.6.dist-info/top_level.txt
+-rw-rw-r--  2.0 unx     3184 b- defN 23-Apr-14 14:32 xpag-0.1.6.dist-info/RECORD
+40 files, 181776 bytes uncompressed, 49942 bytes compressed:  72.5%
```

## zipnote {}

```diff
@@ -99,23 +99,23 @@
 
 Filename: xpag/wrappers/gym_vec_env.py
 Comment: 
 
 Filename: xpag/wrappers/reset_done.py
 Comment: 
 
-Filename: xpag-0.1.5.dist-info/LICENSE
+Filename: xpag-0.1.6.dist-info/LICENSE
 Comment: 
 
-Filename: xpag-0.1.5.dist-info/METADATA
+Filename: xpag-0.1.6.dist-info/METADATA
 Comment: 
 
-Filename: xpag-0.1.5.dist-info/WHEEL
+Filename: xpag-0.1.6.dist-info/WHEEL
 Comment: 
 
-Filename: xpag-0.1.5.dist-info/top_level.txt
+Filename: xpag-0.1.6.dist-info/top_level.txt
 Comment: 
 
-Filename: xpag-0.1.5.dist-info/RECORD
+Filename: xpag-0.1.6.dist-info/RECORD
 Comment: 
 
 Zip file comment:
```

## xpag/__init__.py

```diff
@@ -2,8 +2,8 @@
 from xpag import plotting
 from xpag import wrappers
 from xpag import buffers
 from xpag import samplers
 from xpag import agents
 from xpag import setters
 
-__version__ = "0.1.5"  # -version-
+__version__ = "0.1.6"  # -version-
```

## xpag/tools/eval.py

```diff
@@ -7,33 +7,30 @@
 import numpy as np
 from xpag.agents.agent import Agent
 from xpag.setters.setter import Setter
 from xpag.tools.utils import DataType, datatype_convert, hstack, logical_or
 from xpag.tools.timing import timing
 from xpag.tools.logging import eval_log
 from xpag.plotting.plotting import single_episode_plot
+import joblib
 
 
 class SaveEpisode:
     """To save episodes in Brax or Mujoco environments"""
 
     def __init__(self, env, env_info):
         self.env = env
         self.env_info = env_info
         self.qpos = []
-        self.qrot = []
         self.qvel = []
-        self.qang = []
+        self.states = []
 
     def update(self):
         if self.env_info["env_type"] == "Brax":
-            self.qpos.append(np.asarray(self.env.unwrapped._state.qp.pos))
-            self.qrot.append(np.asarray(self.env.unwrapped._state.qp.rot))
-            self.qvel.append(np.asarray(self.env.unwrapped._state.qp.vel))
-            self.qang.append(np.asarray(self.env.unwrapped._state.qp.ang))
+            self.states.append(self.env.unwrapped._state)
         elif self.env_info["env_type"] == "Mujoco":
             posvel = np.split(
                 np.array(self.env.call("state_vector")),
                 [self.env.call("init_qpos")[0].shape[-1]],
                 axis=1,
             )
             self.qpos.append(posvel[0])
@@ -42,44 +39,33 @@
             pass
 
     def save(self, i: int, save_dir: str):
         os.makedirs(os.path.join(save_dir, "episode"), exist_ok=True)
         if self.env_info["env_type"] == "Brax":
             with open(os.path.join(save_dir, "episode", "env_name.txt"), "w") as f:
                 print(self.env_info["name"], file=f)
-            np.save(
-                os.path.join(save_dir, "episode", "qp_pos"),
-                [pos[i] for pos in self.qpos],
-            )
-            np.save(
-                os.path.join(save_dir, "episode", "qp_rot"),
-                [rot[i] for rot in self.qrot],
-            )
-            np.save(
-                os.path.join(save_dir, "episode", "qp_vel"),
-                [vel[i] for vel in self.qvel],
-            )
-            np.save(
-                os.path.join(save_dir, "episode", "qp_ang"),
-                [ang[i] for ang in self.qang],
-            )
+            with open(
+                os.path.join(save_dir, "episode", "episode_length.txt"), "w"
+            ) as f:
+                print(len(self.states), file=f)
+            with open(os.path.join(save_dir, "episode", "states.joblib"), "wb") as f:
+                joblib.dump(self.states, f)
         elif self.env_info["env_type"] == "Mujoco":
             with open(os.path.join(save_dir, "episode", "env_name.txt"), "w") as f:
                 print(self.env_info["name"], file=f)
             np.save(
                 os.path.join(save_dir, "episode", "qpos"), [pos[i] for pos in self.qpos]
             )
             np.save(
                 os.path.join(save_dir, "episode", "qvel"), [vel[i] for vel in self.qvel]
             )
 
         self.qpos = []
-        self.qrot = []
         self.qvel = []
-        self.qang = []
+        self.states = []
 
 
 def single_rollout_eval(
     steps: int,
     eval_env: Any,
     env_info: Dict[str, Any],
     agent: Agent,
```

## xpag/tools/replay.py

```diff
@@ -1,12 +1,17 @@
 import os
 import numpy as np
 import gymnasium as gym
 import mediapy as media
 from typing import Callable
+import joblib
+from brax import envs
+from brax.io import html
+from IPython import display
+from IPython.display import HTML
 
 
 def mujoco_notebook_replay(load_dir: str):
     """
     Episode replay for mujoco environments.
     """
     from IPython import display  # lazy import
@@ -125,26 +130,15 @@
     )
 
 
 def brax_notebook_replay(load_dir: str):
     """
     Episode replay for brax environments.
     """
-    from brax import envs  # lazy import
-    from brax.physics.base import QP  # lazy import
-    from brax.io import html  # lazy import
-    from IPython import display  # lazy import
-    from IPython.display import HTML  # lazy import
-
     env_name = str(
         np.loadtxt(os.path.join(load_dir, "episode", "env_name.txt"), dtype="str")
     )
-    qp_pos = np.load(os.path.join(load_dir, "episode", "qp_pos.npy"))
-    qp_rot = np.load(os.path.join(load_dir, "episode", "qp_rot.npy"))
-    qp_vel = np.load(os.path.join(load_dir, "episode", "qp_vel.npy"))
-    qp_ang = np.load(os.path.join(load_dir, "episode", "qp_ang.npy"))
     env = envs.create(env_name=env_name)
-    episode_length = len(qp_pos)
-    episode = [
-        QP(qp_pos[i], qp_rot[i], qp_vel[i], qp_ang[i]) for i in range(episode_length)
-    ]
+    with open(os.path.join(load_dir, "episode", "states.joblib"), "rb") as f:
+        states = joblib.load(f)
+    episode = [state.pipeline_state for state in states]
     display.display(HTML(html.render(env.sys, episode)))
```

## xpag/tools/utils.py

```diff
@@ -3,14 +3,15 @@
 # Licensed under the BSD 3-Clause License.
 
 from enum import Enum
 from typing import Tuple, Union, Dict, Any
 import numpy as np
 import jax
 import jax.numpy as jnp
+from gymnasium import spaces
 
 
 class DataType(Enum):
     NUMPY = "data represented as numpy arrays"
     JAX = "data represented as jax.numpy arrays"
 
 
@@ -115,14 +116,18 @@
     is_goalenv = is_goalenv
     if hasattr(env, "is_vector_env"):
         gymvecenv = env.is_vector_env
     else:
         gymvecenv = False
     dims = {}
     if gymvecenv:
+        assert isinstance(env.single_observation_space, spaces.box.Box) and isinstance(
+            env.single_action_space, spaces.box.Box
+        ), "xpag only allows spaces of type gymnasium.spaces.box.Box"
+
         info["action_dim"] = env.single_action_space.shape[-1]
         info["observation_dim"] = (
             env.single_observation_space["observation"].shape[-1]
             if is_goalenv
             else env.single_observation_space.shape[-1]
         )
         info["achieved_goal_dim"] = (
@@ -132,14 +137,18 @@
         )
         info["desired_goal_dim"] = (
             env.single_observation_space["desired_goal"].shape[-1]
             if is_goalenv
             else None
         )
     else:
+        assert isinstance(env.observation_space, spaces.box.Box) and isinstance(
+            env.action_space, spaces.box.Box
+        ), "xpag only allows spaces of type gymnasium.spaces.box.Box"
+
         info["action_dim"] = env.action_space.shape[-1]
         info["observation_dim"] = (
             env.observation_space["observation"].shape[-1]
             if is_goalenv
             else env.observation_space.shape[-1]
         )
         info["achieved_goal_dim"] = (
```

## xpag/wrappers/brax_vec_env.py

```diff
@@ -7,14 +7,16 @@
 import jax
 import jax.numpy as jnp
 import gymnasium as gym
 import numpy as np
 from gymnasium import spaces
 from gymnasium.vector import utils
 from xpag.tools.utils import get_env_dimensions
+from brax import envs
+from brax.envs import env as brax_env
 
 _envs_episode_length = {
     "acrobot": 1000,
     "ant": 1000,
     "fast": 1000,
     "fetch": 1000,
     "grasp": 1000,
@@ -35,50 +37,44 @@
 def brax_vec_env_(
     env_name: str,
     num_envs: int,
     wrap_function: Callable = None,
     *,
     force_cpu_backend=False,
 ):
-    from brax import envs  # lazy import
-    from brax import jumpy as jp  # lazy import
-    from brax.envs import env as brax_env  # lazy import
-
     class ResetDoneBraxWrapper(brax_env.Wrapper):
         """Adds reset_done() to Brax envs."""
 
-        def reset(self, rng: jp.ndarray) -> brax_env.State:
+        def reset(self, rng: jnp.ndarray) -> brax_env.State:
             state = self.env.reset(rng)
-            state.info["first_qp"] = state.qp
-            state.info["first_obs"] = state.obs
             return state
 
-        def step(self, state: brax_env.State, action: jp.ndarray) -> brax_env.State:
+        def step(self, state: brax_env.State, action: jnp.ndarray) -> brax_env.State:
             return self.env.step(state, action)
 
-        def reset_done(self, done: jp.ndarray, state: brax_env.State, rng: jp.ndarray):
+        def reset_done(
+            self, done: jnp.ndarray, state: brax_env.State, rng: jnp.ndarray
+        ):
             # done = state.done
             def where_done(x, y):
                 done_ = done
                 if done_.shape:
-                    done_ = jp.reshape(
+                    done_ = jnp.reshape(
                         done_, tuple([x.shape[0]] + [1] * (len(x.shape) - 1))
                     )  # type: ignore
-                return jp.where(done_, x, y)
+                return jnp.where(done_, x, y)
 
             if "steps" in state.info:
                 steps = state.info["steps"]
-                steps = where_done(jp.zeros_like(steps), steps)
+                steps = where_done(jnp.zeros_like(steps), steps)
                 state.info.update(steps=steps)
 
             reset_state = self.env.reset(rng)
-            qp = jp.tree_map(where_done, reset_state.qp, state.qp)
-            obs = where_done(reset_state.obs, state.obs)
-            state = state.replace(qp=qp, obs=obs)
-            return state.replace(done=where_done(jp.zeros_like(state.done), state.done))
+            new_state = jax.tree_util.tree_map(where_done, reset_state, state)
+            return new_state
 
     class ResetDoneBraxToGymWrapper(gym.vector.VectorEnv):
         """
         A wrapper that converts Brax Env to one that follows Gym VectorEnv API,
         with the additional reset_done() and reset_idxs() methods.
         """
 
@@ -92,73 +88,73 @@
             max_episode_steps: int,
             backend: Optional[str] = None,
         ):
             self.max_episode_steps = max_episode_steps
             self._env = env
             self.metadata = {
                 "render.modes": ["human", "rgb_array"],
-                "video.frames_per_second": 1 / self._env.sys.config.dt,
+                "video.frames_per_second": 1 / self._env.sys.dt,
             }
             if not hasattr(self._env, "batch_size"):
                 raise ValueError("underlying env must be batched")
 
             self.num_envs = self._env.batch_size
             self.backend = backend
             self._state = None
             self._key = None
 
-            obs_high = jp.inf * jp.ones(self._env.observation_size, dtype="float32")
+            obs_high = np.inf * np.ones(self._env.observation_size, dtype="float32")
             self.single_observation_space = spaces.Box(
                 -obs_high, obs_high, dtype=np.float32
             )
             self.observation_space = utils.batch_space(
                 self.single_observation_space, self.num_envs
             )
 
-            action_high = jp.ones(self._env.action_size, dtype="float32")
+            action_high = np.ones(self._env.action_size, dtype="float32")
             self.single_action_space = spaces.Box(
                 -action_high, action_high, dtype=np.float32
             )
             self.action_space = utils.batch_space(
                 self.single_action_space, self.num_envs
             )
 
             def reset(key):
-                key1, key2 = jp.random_split(key)
+                key1, key2 = jax.random.split(key)
                 state = self._env.reset(key2)
                 return state, state.obs, key1
 
             self._reset = jax.jit(reset, backend=self.backend)
 
             def step(state, action):
                 state = self._env.step(state, action)
-                info = state.metrics
+                info = state.metrics.copy()
                 info["steps"] = state.info["steps"]
                 terminated = jnp.logical_and(
                     state.done, jnp.logical_not(state.info["truncation"])
                 ).reshape((self.num_envs, -1))
+                # terminated has the wrong value here if the episode was both truncated
+                # and reached a terminal state. However, with the current API of brax
+                # envs, this information cannot be recovered.
                 truncated = (
                     state.info["truncation"].reshape((self.num_envs, -1)).astype("bool")
                 )
-                # terminated is wrong if the episode was both truncated and reached
-                # a terminal state. However, with the current API of brax envs,
-                # this information cannot be recovered.
                 return (
                     state,
                     state.obs.reshape((self.num_envs, -1)),
                     state.reward.reshape((self.num_envs, -1)),
                     terminated,
                     truncated,
                     info,
                 )
 
             self._step = jax.jit(step, backend=self.backend)
 
             def reset_done(done, state, key):
-                key1, key2 = jp.random_split(key)
+                key1, key2 = jax.random.split(key)
                 if state is None:
                     raise ValueError(
                         "Use reset() for the first reset, not reset_idxs()."
                     )
                 state = self._env.reset_done(done, state, key2)
                 return state, state.obs, key1
 
@@ -206,24 +202,23 @@
                 if self._key is None:
                     self._key = jax.random.PRNGKey(0)
             else:
                 self._key = jax.random.PRNGKey(seed)
             self._state, obs, self._key = self._reset_done(done, self._state, self._key)
             return obs, {}
 
-        def render(self, mode="human"):
-            # pylint:disable=g-import-not-at-top
-            from brax.io import image  # lazy import
-
-            if mode == "rgb_array":
-                sys = self._env.sys
-                qp = jp.take(self._state.qp, 0)
-                return image.render_array(sys, qp, 256, 256)
-            else:
-                return super().render(mode=mode)  # just raise an exception
+        # def render(self, mode="human"):
+        #     if mode == "rgb_array":
+        #         sys = self._env.sys
+        #         qp = jnp.take(self._state.qp, 0)
+        #         return html.render(
+        #             sys, qp, height='256vh', colab=False, base_url='/js/viewer.js'
+        #         )
+        #     else:
+        #         return super().render(mode=mode)  # just raise an exception
 
     if wrap_function is None:
 
         def wrap_function(x):
             return x
 
     assert env_name in _envs_episode_length, f"{env_name}: unknown environment."
```

## Comparing `xpag-0.1.5.dist-info/LICENSE` & `xpag-0.1.6.dist-info/LICENSE`

 * *Files identical despite different names*

## Comparing `xpag-0.1.5.dist-info/METADATA` & `xpag-0.1.6.dist-info/METADATA`

 * *Files 1% similar despite different names*

```diff
@@ -1,33 +1,33 @@
 Metadata-Version: 2.1
 Name: xpag
-Version: 0.1.5
+Version: 0.1.6
 Summary: xpag: Exploring Agents
 Home-page: https://github.com/perrin-isir/xpag
 Author: Nicolas Perrin-Gilbert
 License: LICENSE
 Description-Content-Type: text/markdown
 License-File: LICENSE
 Requires-Dist: psutil (>=5.8.0)
 Requires-Dist: numpy (>=1.21.5)
 Requires-Dist: matplotlib (>=3.1.3)
 Requires-Dist: joblib (>=1.1.0)
-Requires-Dist: gymnasium (>=0.26.0)
+Requires-Dist: gymnasium (>=0.28.1)
 Requires-Dist: Pillow (>=9.0.1)
 Requires-Dist: ipywidgets (>=7.6.5)
-Requires-Dist: jax (>=0.3.23)
-Requires-Dist: flax (>=0.6.3)
+Requires-Dist: jax (>=0.4.8)
 Requires-Dist: optax (>=0.1.2)
-Requires-Dist: brax (>=0.0.10)
+Requires-Dist: flax (>=0.6.3)
+Requires-Dist: brax (>=0.9.0)
 Requires-Dist: tensorflow-probability (>=0.15.0)
 Requires-Dist: mediapy (>=1.1.4)
 
 # ![alt text](https://raw.githubusercontent.com/perrin-isir/xpag/main/logo.png "xpag logo")
 
-![version](https://img.shields.io/badge/version-0.1.5-blue)
+![version](https://img.shields.io/badge/version-0.1.6-blue)
 [![codestyle](https://img.shields.io/badge/code%20style-black-000000.svg)](https://github.com/psf/black)
 [![Documentation](https://img.shields.io/github/actions/workflow/status/perrin-isir/xpag/docs.yml?branch=main&label=docs)](https://perrin-isir.github.io/xpag/)
 [![PyPI version](https://img.shields.io/pypi/v/xpag)](https://pypi.org/project/xpag/)
 
 
 *xpag* ("e**xp**loring **ag**ents") is a modular reinforcement learning library with JAX agents, currently in beta version.
```

## Comparing `xpag-0.1.5.dist-info/RECORD` & `xpag-0.1.6.dist-info/RECORD`

 * *Files 20% similar despite different names*

```diff
@@ -1,8 +1,8 @@
-xpag/__init__.py,sha256=QNh2p3xA9MZzjwvYkZO0kE20M02z2JO8k5fBFiK-TX0,211
+xpag/__init__.py,sha256=M72XofzWhBH_QxCOMx4q3VYI6GhcR4jgJEvQ-0Uwoik,211
 xpag/agents/__init__.py,sha256=qwWcvnIIALsfDemnUNkyQqZNAbRoNbBkS9ppu0BjjRc,204
 xpag/agents/agent.py,sha256=sMvWydFTU1f4kar6nnSbvXSi56tlEla6NJiwgVnM47s,1098
 xpag/agents/sac/__init__.py,sha256=47DEQpj8HBSa-_TImW-5JCeuQeRkm5NMpJWZG3hSuFU,0
 xpag/agents/sac/sac.py,sha256=xLKisxVIAmQ5FA4E4ppV3O7W8HyWgUu0VkVZzGJvsik,5554
 xpag/agents/sac/sac_from_jaxrl.py,sha256=2Nbr3jg96Ohbwcjom10WH0Pcu5ipH058KI66_LFZYUk,18817
 xpag/agents/sdqn/__init__.py,sha256=47DEQpj8HBSa-_TImW-5JCeuQeRkm5NMpJWZG3hSuFU,0
 xpag/agents/sdqn/sdqn.py,sha256=0CP9Se8S9QIpMUjHJmFAQBulGzAd6FQHKbkQWhCtLSY,22063
@@ -18,23 +18,23 @@
 xpag/samplers/HER.py,sha256=xmjKZv4eCOPudddqDnNW-Vqo5TEol_SToRSqzQ74P0k,2841
 xpag/samplers/__init__.py,sha256=fazYtUuLPWpbDxZxB40VRUZcYuE7P-LnRpFuoTHMSkE,182
 xpag/samplers/jax_sampler.py,sha256=iPLVriHQu_X-YbSxbYMTA1gV7TKYhS186rTpEbR2c40,2941
 xpag/samplers/sampler.py,sha256=77P_YLUfduAbn-zvUq5fp5M1MohgwTZ0RNgMjsC-Wiw,1829
 xpag/setters/__init__.py,sha256=gEEbf529oUwVHTpStUelg0Y7NQ8qQxbCK_Mnhv0pb6I,71
 xpag/setters/setter.py,sha256=Rey6VOm8T8gEhVql_2LhQIN6ZKC0lC5J6aAOizPq5Rs,3734
 xpag/tools/__init__.py,sha256=6PpnqZEtELXPQ_vWnyp-l6ZnIVFXFiaMWhaTZ7XEJoI,438
-xpag/tools/eval.py,sha256=8kxg4Ofs5WyQQcJEgwmjCA7tqvbWAVj6QQdlUQjd1ug,5609
+xpag/tools/eval.py,sha256=8ceSq-WiZTljQE1IE220iR1b1WodqgHsFfaxu88CK0k,5065
 xpag/tools/learn.py,sha256=Ow63UUpeW5g6vx1Hzz_wVggrCwQOfa24eyc18-_ct60,7611
 xpag/tools/logging.py,sha256=Ip3ETtLHYyqlmC8Z2BncuaI_y2RNBN99-UF1VoEWeuE,3225
-xpag/tools/replay.py,sha256=SDcmhk4aazM3bc4Xf-roXKGcgWbK00r4xrM2o-pOMhc,5063
+xpag/tools/replay.py,sha256=Afg3TLZU41yPVauyR2IYqtxbfC-HK41ksLG07IQf_FE,4694
 xpag/tools/timing.py,sha256=aihoZOw4xCML2hrgpqWs_TgFIOThPqJuyFG7weod9-Y,899
-xpag/tools/utils.py,sha256=vJhYOMnL86ONCe7EPdYBmpqEuQNnhhUiIK55NwD65cw,4836
+xpag/tools/utils.py,sha256=S0AQObm47diWYNgg3aP4SSz2UEZ5F_G2leGkBGV952I,5273
 xpag/wrappers/__init__.py,sha256=4tECDefZtReXVN3tUyIbfNeO-Q-hXA9Pm0e5vOMKwgA,179
-xpag/wrappers/brax_vec_env.py,sha256=Xm9m6ZTXci2315awsFoQg4w9iE6d3N-L6wv3IRNG41k,9130
+xpag/wrappers/brax_vec_env.py,sha256=rPIdFN3e879f4spt2wWFj6o8KEEYLKlGgOsXkrP9JG0,8833
 xpag/wrappers/goalenv_wrapper.py,sha256=wryWDyfQGneC6y1emTLUmtU0c0bB8VkXhFZCPdiZkls,6071
 xpag/wrappers/gym_vec_env.py,sha256=Ot43NfJTBOLGjvvXaaSjIFpZRwNGdbW8jySODxW_X4U,10125
 xpag/wrappers/reset_done.py,sha256=GJHmSIpJuQNkiO-rKg0oDG0np7_CbZkBPJ-4akSpypY,936
-xpag-0.1.5.dist-info/LICENSE,sha256=g85jiSLf3DU-cU426LLpqKUqjFwcnfYF8qpyms8R9p8,1517
-xpag-0.1.5.dist-info/METADATA,sha256=dJ9798EBtVIE9Q-jurl6qpd4M1cLZdbeyqrv7INtlrI,15081
-xpag-0.1.5.dist-info/WHEEL,sha256=pkctZYzUS4AYVn6dJ-7367OJZivF2e8RA9b_ZBjif18,92
-xpag-0.1.5.dist-info/top_level.txt,sha256=CUClY4Z7dB5zr_iqoqBK479ZNT9uDDCD7hWIHgQTDpc,5
-xpag-0.1.5.dist-info/RECORD,,
+xpag-0.1.6.dist-info/LICENSE,sha256=g85jiSLf3DU-cU426LLpqKUqjFwcnfYF8qpyms8R9p8,1517
+xpag-0.1.6.dist-info/METADATA,sha256=bYJYft1Z1galGRItQOygq1x1t6sZGVA9cEySWRBiM3w,15079
+xpag-0.1.6.dist-info/WHEEL,sha256=pkctZYzUS4AYVn6dJ-7367OJZivF2e8RA9b_ZBjif18,92
+xpag-0.1.6.dist-info/top_level.txt,sha256=CUClY4Z7dB5zr_iqoqBK479ZNT9uDDCD7hWIHgQTDpc,5
+xpag-0.1.6.dist-info/RECORD,,
```

