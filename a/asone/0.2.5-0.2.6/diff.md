# Comparing `tmp/asone-0.2.5-py3-none-any.whl.zip` & `tmp/asone-0.2.6-py3-none-any.whl.zip`

## zipinfo {}

```diff
@@ -1,24 +1,24 @@
-Zip file size: 367344 bytes, number of entries: 212
--rw-rw-r--  2.0 unx     2117 b- defN 23-Apr-10 06:23 asone/__init__.py
--rw-rw-r--  2.0 unx     7408 b- defN 23-Apr-10 07:04 asone/asone.py
--rw-rw-r--  2.0 unx     2715 b- defN 23-Apr-10 06:15 asone/demo_detector.py
--rw-rw-r--  2.0 unx     2149 b- defN 23-Apr-10 07:59 asone/demo_ocr.py
--rw-rw-r--  2.0 unx     3139 b- defN 23-Apr-10 06:15 asone/demo_tracker.py
+Zip file size: 368403 bytes, number of entries: 212
+-rw-rw-r--  2.0 unx     2603 b- defN 23-Apr-14 07:37 asone/__init__.py
+-rw-rw-r--  2.0 unx     7408 b- defN 23-Apr-12 09:28 asone/asone.py
+-rw-rw-r--  2.0 unx     2715 b- defN 23-Apr-14 12:15 asone/demo_detector.py
+-rw-rw-r--  2.0 unx     2149 b- defN 23-Apr-14 11:36 asone/demo_ocr.py
+-rw-rw-r--  2.0 unx     1713 b- defN 23-Apr-14 05:36 asone/demo_tracker.py
 -rw-rw-r--  2.0 unx      543 b- defN 23-Apr-10 06:15 asone/detectors/__init__.py
--rw-rw-r--  2.0 unx     4234 b- defN 23-Apr-10 06:23 asone/detectors/detector.py
+-rw-rw-r--  2.0 unx     4911 b- defN 23-Apr-11 06:32 asone/detectors/detector.py
 -rw-rw-r--  2.0 unx       66 b- defN 23-Apr-10 06:15 asone/detectors/easyocr_detector/__init__.py
--rw-rw-r--  2.0 unx     1921 b- defN 23-Apr-10 06:23 asone/detectors/easyocr_detector/text_detector.py
+-rw-rw-r--  2.0 unx     2094 b- defN 23-Apr-12 09:04 asone/detectors/easyocr_detector/text_detector.py
 -rw-rw-r--  2.0 unx        0 b- defN 23-Apr-10 06:15 asone/detectors/utils/__init__.py
 -rw-rw-r--  2.0 unx      533 b- defN 23-Apr-10 06:15 asone/detectors/utils/cfg_path.py
 -rw-rw-r--  2.0 unx     1545 b- defN 23-Apr-10 06:15 asone/detectors/utils/coreml_utils.py
 -rw-rw-r--  2.0 unx     1478 b- defN 23-Apr-10 06:15 asone/detectors/utils/exp_name.py
--rw-rw-r--  2.0 unx     6694 b- defN 23-Apr-10 06:15 asone/detectors/utils/weights_path.py
+-rw-rw-r--  2.0 unx     8748 b- defN 23-Apr-14 07:37 asone/detectors/utils/weights_path.py
 -rw-rw-r--  2.0 unx       69 b- defN 23-Apr-10 06:15 asone/detectors/yolor/__init__.py
--rw-rw-r--  2.0 unx     5315 b- defN 23-Apr-10 06:23 asone/detectors/yolor/yolor_detector.py
+-rw-rw-r--  2.0 unx     5315 b- defN 23-Apr-11 06:11 asone/detectors/yolor/yolor_detector.py
 -rw-rw-r--  2.0 unx    14241 b- defN 23-Apr-10 06:15 asone/detectors/yolor/cfg/yolor_csp.cfg
 -rw-rw-r--  2.0 unx    16338 b- defN 23-Apr-10 06:15 asone/detectors/yolor/cfg/yolor_csp_x.cfg
 -rw-rw-r--  2.0 unx    18330 b- defN 23-Apr-10 06:15 asone/detectors/yolor/cfg/yolor_p6.cfg
 -rw-rw-r--  2.0 unx        1 b- defN 23-Apr-10 06:15 asone/detectors/yolor/models/__init__.py
 -rw-rw-r--  2.0 unx    38971 b- defN 23-Apr-10 06:15 asone/detectors/yolor/models/common.py
 -rw-rw-r--  2.0 unx     2733 b- defN 23-Apr-10 06:15 asone/detectors/yolor/models/export.py
 -rw-rw-r--  2.0 unx    36694 b- defN 23-Apr-10 06:15 asone/detectors/yolor/models/models.py
@@ -33,26 +33,26 @@
 -rw-rw-r--  2.0 unx     7443 b- defN 23-Apr-10 06:15 asone/detectors/yolor/utils/loss.py
 -rw-rw-r--  2.0 unx     5137 b- defN 23-Apr-10 06:15 asone/detectors/yolor/utils/metrics.py
 -rw-rw-r--  2.0 unx     2995 b- defN 23-Apr-10 06:15 asone/detectors/yolor/utils/parse_config.py
 -rw-rw-r--  2.0 unx    15468 b- defN 23-Apr-10 06:15 asone/detectors/yolor/utils/plots.py
 -rw-rw-r--  2.0 unx     9396 b- defN 23-Apr-10 06:15 asone/detectors/yolor/utils/torch_utils.py
 -rw-rw-r--  2.0 unx     9267 b- defN 23-Apr-10 06:15 asone/detectors/yolor/utils/yolor_utils.py
 -rw-rw-r--  2.0 unx       72 b- defN 23-Apr-10 06:15 asone/detectors/yolov5/__init__.py
--rw-rw-r--  2.0 unx     6323 b- defN 23-Apr-10 06:23 asone/detectors/yolov5/yolov5_detector.py
+-rw-rw-r--  2.0 unx     6417 b- defN 23-Apr-11 06:32 asone/detectors/yolov5/yolov5_detector.py
 -rw-rw-r--  2.0 unx        0 b- defN 23-Apr-10 06:15 asone/detectors/yolov5/yolov5/__init__.py
 -rw-rw-r--  2.0 unx       64 b- defN 23-Apr-10 06:15 asone/detectors/yolov5/yolov5/models/__init__.py
 -rw-rw-r--  2.0 unx    36615 b- defN 23-Apr-10 06:15 asone/detectors/yolov5/yolov5/models/common.py
 -rw-rw-r--  2.0 unx     2340 b- defN 23-Apr-10 06:15 asone/detectors/yolov5/yolov5/models/experimental.py
 -rw-rw-r--  2.0 unx    42725 b- defN 23-Apr-10 06:15 asone/detectors/yolov5/yolov5/models/general.py
 -rw-rw-r--  2.0 unx    15923 b- defN 23-Apr-10 06:15 asone/detectors/yolov5/yolov5/models/yolo.py
 -rw-rw-r--  2.0 unx        0 b- defN 23-Apr-10 06:15 asone/detectors/yolov5/yolov5/utils/__init__.py
 -rw-rw-r--  2.0 unx    15973 b- defN 23-Apr-10 06:15 asone/detectors/yolov5/yolov5/utils/torch_utils.py
 -rw-rw-r--  2.0 unx     8854 b- defN 23-Apr-10 06:15 asone/detectors/yolov5/yolov5/utils/yolov5_utils.py
 -rw-rw-r--  2.0 unx       72 b- defN 23-Apr-10 06:15 asone/detectors/yolov6/__init__.py
--rw-rw-r--  2.0 unx     5640 b- defN 23-Apr-10 06:23 asone/detectors/yolov6/yolov6_detector.py
+-rw-rw-r--  2.0 unx     5640 b- defN 23-Apr-11 06:11 asone/detectors/yolov6/yolov6_detector.py
 -rw-rw-r--  2.0 unx        0 b- defN 23-Apr-10 06:15 asone/detectors/yolov6/yolov6/__init__.py
 -rw-rw-r--  2.0 unx       85 b- defN 23-Apr-10 06:15 asone/detectors/yolov6/yolov6/assigners/__init__.py
 -rw-rw-r--  2.0 unx     2372 b- defN 23-Apr-10 06:15 asone/detectors/yolov6/yolov6/assigners/anchor_generator.py
 -rw-rw-r--  2.0 unx     3682 b- defN 23-Apr-10 06:15 asone/detectors/yolov6/yolov6/assigners/assigner_utils.py
 -rw-rw-r--  2.0 unx     7099 b- defN 23-Apr-10 06:15 asone/detectors/yolov6/yolov6/assigners/atss_assigner.py
 -rw-rw-r--  2.0 unx     9211 b- defN 23-Apr-10 06:15 asone/detectors/yolov6/yolov6/assigners/iou2d_calculator.py
 -rw-rw-r--  2.0 unx     6143 b- defN 23-Apr-10 06:15 asone/detectors/yolov6/yolov6/assigners/tal_assigner.py
@@ -69,29 +69,29 @@
 -rw-rw-r--  2.0 unx     3951 b- defN 23-Apr-10 06:15 asone/detectors/yolov6/yolov6/models/yolo.py
 -rw-rw-r--  2.0 unx        0 b- defN 23-Apr-10 06:15 asone/detectors/yolov6/yolov6/utils/__init__.py
 -rw-rw-r--  2.0 unx     1880 b- defN 23-Apr-10 06:15 asone/detectors/yolov6/yolov6/utils/events.py
 -rw-rw-r--  2.0 unx     2674 b- defN 23-Apr-10 06:15 asone/detectors/yolov6/yolov6/utils/general.py
 -rw-rw-r--  2.0 unx     3373 b- defN 23-Apr-10 06:15 asone/detectors/yolov6/yolov6/utils/torch_utils.py
 -rw-rw-r--  2.0 unx     9628 b- defN 23-Apr-10 06:15 asone/detectors/yolov6/yolov6/utils/yolov6_utils.py
 -rw-rw-r--  2.0 unx       72 b- defN 23-Apr-10 06:15 asone/detectors/yolov7/__init__.py
--rw-rw-r--  2.0 unx     4932 b- defN 23-Apr-10 06:23 asone/detectors/yolov7/yolov7_detector.py
+-rw-rw-r--  2.0 unx     6904 b- defN 23-Apr-14 07:37 asone/detectors/yolov7/yolov7_detector.py
 -rw-rw-r--  2.0 unx        0 b- defN 23-Apr-10 06:15 asone/detectors/yolov7/yolov7/__init__.py
 -rw-rw-r--  2.0 unx       64 b- defN 23-Apr-10 06:15 asone/detectors/yolov7/yolov7/models/__init__.py
 -rw-rw-r--  2.0 unx    84188 b- defN 23-Apr-10 06:15 asone/detectors/yolov7/yolov7/models/common.py
 -rw-rw-r--  2.0 unx     1603 b- defN 23-Apr-10 06:15 asone/detectors/yolov7/yolov7/models/experimental.py
 -rw-rw-r--  2.0 unx    41743 b- defN 23-Apr-10 06:15 asone/detectors/yolov7/yolov7/models/yolo.py
 -rw-rw-r--  2.0 unx        0 b- defN 23-Apr-10 06:15 asone/detectors/yolov7/yolov7/utils/__init__.py
 -rw-rw-r--  2.0 unx    15467 b- defN 23-Apr-10 06:15 asone/detectors/yolov7/yolov7/utils/torch_utils.py
--rw-rw-r--  2.0 unx     8208 b- defN 23-Apr-10 06:15 asone/detectors/yolov7/yolov7/utils/yolov7_utils.py
+-rw-rw-r--  2.0 unx     8212 b- defN 23-Apr-11 06:32 asone/detectors/yolov7/yolov7/utils/yolov7_utils.py
 -rw-rw-r--  2.0 unx       72 b- defN 23-Apr-10 06:15 asone/detectors/yolov8/__init__.py
--rw-rw-r--  2.0 unx     4306 b- defN 23-Apr-10 06:23 asone/detectors/yolov8/yolov8_detector.py
+-rw-rw-r--  2.0 unx     5911 b- defN 23-Apr-11 06:32 asone/detectors/yolov8/yolov8_detector.py
 -rw-rw-r--  2.0 unx        0 b- defN 23-Apr-10 06:15 asone/detectors/yolov8/utils/__init__.py
--rw-rw-r--  2.0 unx     1919 b- defN 23-Apr-10 06:15 asone/detectors/yolov8/utils/yolov8_utils.py
+-rw-rw-r--  2.0 unx     2043 b- defN 23-Apr-11 06:32 asone/detectors/yolov8/utils/yolov8_utils.py
 -rw-rw-r--  2.0 unx       69 b- defN 23-Apr-10 06:15 asone/detectors/yolox/__init__.py
--rw-rw-r--  2.0 unx     6573 b- defN 23-Apr-10 06:23 asone/detectors/yolox/yolox_detector.py
+-rw-rw-r--  2.0 unx     6573 b- defN 23-Apr-11 06:11 asone/detectors/yolox/yolox_detector.py
 -rw-rw-r--  2.0 unx     4277 b- defN 23-Apr-10 06:15 asone/detectors/yolox/yolox_utils.py
 -rw-rw-r--  2.0 unx       95 b- defN 23-Apr-10 06:15 asone/detectors/yolox/exps/__init__.py
 -rw-rw-r--  2.0 unx     1042 b- defN 23-Apr-10 06:15 asone/detectors/yolox/exps/yolov3.py
 -rw-rw-r--  2.0 unx      377 b- defN 23-Apr-10 06:15 asone/detectors/yolox/exps/yolox_l.py
 -rw-rw-r--  2.0 unx      379 b- defN 23-Apr-10 06:15 asone/detectors/yolox/exps/yolox_m.py
 -rw-rw-r--  2.0 unx     1561 b- defN 23-Apr-10 06:15 asone/detectors/yolox/exps/yolox_nano.py
 -rw-rw-r--  2.0 unx      379 b- defN 23-Apr-10 06:15 asone/detectors/yolox/exps/yolox_s.py
@@ -125,19 +125,19 @@
 -rw-rw-r--  2.0 unx     3256 b- defN 23-Apr-10 06:15 asone/detectors/yolox/yolox/utils/metric.py
 -rw-rw-r--  2.0 unx     5614 b- defN 23-Apr-10 06:15 asone/detectors/yolox/yolox/utils/model_utils.py
 -rw-rw-r--  2.0 unx     2675 b- defN 23-Apr-10 06:15 asone/detectors/yolox/yolox/utils/setup_env.py
 -rw-rw-r--  2.0 unx     3599 b- defN 23-Apr-10 06:15 asone/detectors/yolox/yolox/utils/visualize.py
 -rw-rw-r--  2.0 unx      182 b- defN 23-Apr-10 06:15 asone/recognizers/__init__.py
 -rw-rw-r--  2.0 unx      933 b- defN 23-Apr-10 06:15 asone/recognizers/recognizer.py
 -rw-rw-r--  2.0 unx       81 b- defN 23-Apr-10 06:15 asone/recognizers/easyocr_recognizer/__init__.py
--rw-rw-r--  2.0 unx     1721 b- defN 23-Apr-10 06:15 asone/recognizers/easyocr_recognizer/easyocr_recognizer.py
+-rw-rw-r--  2.0 unx     1721 b- defN 23-Apr-11 06:11 asone/recognizers/easyocr_recognizer/easyocr_recognizer.py
 -rw-rw-r--  2.0 unx        0 b- defN 23-Apr-10 06:15 asone/recognizers/utils/__init__.py
 -rw-rw-r--  2.0 unx      196 b- defN 23-Apr-10 06:15 asone/recognizers/utils/recognizer_name.py
--rw-rw-r--  2.0 unx      458 b- defN 23-Apr-10 06:23 asone/trackers/__init__.py
--rw-rw-r--  2.0 unx     1157 b- defN 23-Apr-10 06:23 asone/trackers/tracker.py
+-rw-rw-r--  2.0 unx      458 b- defN 23-Apr-11 06:11 asone/trackers/__init__.py
+-rw-rw-r--  2.0 unx     1157 b- defN 23-Apr-11 06:11 asone/trackers/tracker.py
 -rw-rw-r--  2.0 unx        0 b- defN 23-Apr-10 06:15 asone/trackers/byte_track/__init__.py
 -rw-rw-r--  2.0 unx     2252 b- defN 23-Apr-10 06:15 asone/trackers/byte_track/bytetracker.py
 -rw-rw-r--  2.0 unx        0 b- defN 23-Apr-10 06:15 asone/trackers/byte_track/tracker/__init__.py
 -rw-rw-r--  2.0 unx      950 b- defN 23-Apr-10 06:15 asone/trackers/byte_track/tracker/basetrack.py
 -rw-rw-r--  2.0 unx    11950 b- defN 23-Apr-10 06:15 asone/trackers/byte_track/tracker/byte_tracker.py
 -rw-rw-r--  2.0 unx     9547 b- defN 23-Apr-10 06:15 asone/trackers/byte_track/tracker/kalman_filter.py
 -rw-rw-r--  2.0 unx     6208 b- defN 23-Apr-10 06:15 asone/trackers/byte_track/tracker/matching.py
@@ -159,56 +159,56 @@
 -rw-rw-r--  2.0 unx     7787 b- defN 23-Apr-10 06:15 asone/trackers/deep_sort/tracker/sort/kalman_filter.py
 -rw-rw-r--  2.0 unx     7894 b- defN 23-Apr-10 06:15 asone/trackers/deep_sort/tracker/sort/linear_assignment.py
 -rw-rw-r--  2.0 unx     5469 b- defN 23-Apr-10 06:15 asone/trackers/deep_sort/tracker/sort/nn_matching.py
 -rw-rw-r--  2.0 unx     1914 b- defN 23-Apr-10 06:15 asone/trackers/deep_sort/tracker/sort/preprocessing.py
 -rw-rw-r--  2.0 unx     5063 b- defN 23-Apr-10 06:15 asone/trackers/deep_sort/tracker/sort/track.py
 -rw-rw-r--  2.0 unx     5605 b- defN 23-Apr-10 06:15 asone/trackers/deep_sort/tracker/sort/tracker.py
 -rw-rw-r--  2.0 unx        0 b- defN 23-Apr-10 06:15 asone/trackers/motpy/__init__.py
--rw-rw-r--  2.0 unx     1844 b- defN 23-Apr-10 06:23 asone/trackers/motpy/motpy.py
+-rw-rw-r--  2.0 unx     1844 b- defN 23-Apr-11 06:11 asone/trackers/motpy/motpy.py
 -rw-rw-r--  2.0 unx        0 b- defN 23-Apr-10 06:15 asone/trackers/nor_fair/__init__.py
 -rw-rw-r--  2.0 unx     1909 b- defN 23-Apr-10 06:15 asone/trackers/nor_fair/norfair.py
--rw-rw-r--  2.0 unx       56 b- defN 23-Apr-10 06:23 asone/trackers/oc_sort/__init__.py
--rw-rw-r--  2.0 unx     1026 b- defN 23-Apr-10 06:23 asone/trackers/oc_sort/ocsort.py
--rw-rw-r--  2.0 unx        0 b- defN 23-Apr-10 06:23 asone/trackers/oc_sort/tracker/__init__.py
--rw-rw-r--  2.0 unx    14315 b- defN 23-Apr-10 06:23 asone/trackers/oc_sort/tracker/association.py
--rw-rw-r--  2.0 unx    59022 b- defN 23-Apr-10 06:23 asone/trackers/oc_sort/tracker/kalmanfilter.py
--rw-rw-r--  2.0 unx    13155 b- defN 23-Apr-10 06:23 asone/trackers/oc_sort/tracker/ocsort.py
--rw-rw-r--  2.0 unx        0 b- defN 23-Apr-10 06:23 asone/trackers/strong_sort/__init__.py
--rw-rw-r--  2.0 unx     1226 b- defN 23-Apr-10 06:23 asone/trackers/strong_sort/strongsort.py
--rw-rw-r--  2.0 unx      510 b- defN 23-Apr-10 06:23 asone/trackers/strong_sort/tracker/__init__.py
--rw-rw-r--  2.0 unx     5178 b- defN 23-Apr-10 06:23 asone/trackers/strong_sort/tracker/strong_sort.py
--rw-rw-r--  2.0 unx        0 b- defN 23-Apr-10 06:23 asone/trackers/strong_sort/tracker/deep/__init__.py
--rw-rw-r--  2.0 unx     4858 b- defN 23-Apr-10 06:23 asone/trackers/strong_sort/tracker/deep/reid_model_factory.py
--rw-rw-r--  2.0 unx        0 b- defN 23-Apr-10 06:23 asone/trackers/strong_sort/tracker/sort/__init__.py
--rw-rw-r--  2.0 unx     1439 b- defN 23-Apr-10 06:23 asone/trackers/strong_sort/tracker/sort/detection.py
--rw-rw-r--  2.0 unx     2843 b- defN 23-Apr-10 06:23 asone/trackers/strong_sort/tracker/sort/iou_matching.py
--rw-rw-r--  2.0 unx     8114 b- defN 23-Apr-10 06:23 asone/trackers/strong_sort/tracker/sort/kalman_filter.py
--rw-rw-r--  2.0 unx     7624 b- defN 23-Apr-10 06:23 asone/trackers/strong_sort/tracker/sort/linear_assignment.py
--rw-rw-r--  2.0 unx     5770 b- defN 23-Apr-10 06:23 asone/trackers/strong_sort/tracker/sort/nn_matching.py
--rw-rw-r--  2.0 unx     1914 b- defN 23-Apr-10 06:23 asone/trackers/strong_sort/tracker/sort/preprocessing.py
--rw-rw-r--  2.0 unx    10653 b- defN 23-Apr-10 06:23 asone/trackers/strong_sort/tracker/sort/track.py
--rw-rw-r--  2.0 unx     7684 b- defN 23-Apr-10 06:23 asone/trackers/strong_sort/tracker/sort/tracker.py
--rw-rw-r--  2.0 unx        0 b- defN 23-Apr-10 06:23 asone/trackers/strong_sort/tracker/utils/__init__.py
--rw-rw-r--  2.0 unx      316 b- defN 23-Apr-10 06:23 asone/trackers/strong_sort/tracker/utils/asserts.py
--rw-rw-r--  2.0 unx     1125 b- defN 23-Apr-10 06:23 asone/trackers/strong_sort/tracker/utils/draw.py
--rw-rw-r--  2.0 unx     3532 b- defN 23-Apr-10 06:23 asone/trackers/strong_sort/tracker/utils/evaluation.py
--rw-rw-r--  2.0 unx     4357 b- defN 23-Apr-10 06:23 asone/trackers/strong_sort/tracker/utils/io.py
--rw-rw-r--  2.0 unx    11762 b- defN 23-Apr-10 06:23 asone/trackers/strong_sort/tracker/utils/json_logger.py
--rw-rw-r--  2.0 unx      463 b- defN 23-Apr-10 06:23 asone/trackers/strong_sort/tracker/utils/log.py
--rw-rw-r--  2.0 unx     1078 b- defN 23-Apr-10 06:23 asone/trackers/strong_sort/tracker/utils/parser.py
--rw-rw-r--  2.0 unx      734 b- defN 23-Apr-10 06:23 asone/trackers/strong_sort/tracker/utils/tools.py
--rw-rw-r--  2.0 unx      430 b- defN 23-Apr-10 06:15 asone/utils/__init__.py
+-rw-rw-r--  2.0 unx       56 b- defN 23-Apr-11 06:11 asone/trackers/oc_sort/__init__.py
+-rw-rw-r--  2.0 unx     1026 b- defN 23-Apr-11 06:11 asone/trackers/oc_sort/ocsort.py
+-rw-rw-r--  2.0 unx        0 b- defN 23-Apr-11 06:11 asone/trackers/oc_sort/tracker/__init__.py
+-rw-rw-r--  2.0 unx    14315 b- defN 23-Apr-11 06:11 asone/trackers/oc_sort/tracker/association.py
+-rw-rw-r--  2.0 unx    59022 b- defN 23-Apr-11 06:11 asone/trackers/oc_sort/tracker/kalmanfilter.py
+-rw-rw-r--  2.0 unx    13155 b- defN 23-Apr-11 06:11 asone/trackers/oc_sort/tracker/ocsort.py
+-rw-rw-r--  2.0 unx        0 b- defN 23-Apr-11 06:11 asone/trackers/strong_sort/__init__.py
+-rw-rw-r--  2.0 unx     1181 b- defN 23-Apr-12 09:02 asone/trackers/strong_sort/strongsort.py
+-rw-rw-r--  2.0 unx      510 b- defN 23-Apr-11 06:11 asone/trackers/strong_sort/tracker/__init__.py
+-rw-rw-r--  2.0 unx     5178 b- defN 23-Apr-11 06:11 asone/trackers/strong_sort/tracker/strong_sort.py
+-rw-rw-r--  2.0 unx        0 b- defN 23-Apr-11 06:11 asone/trackers/strong_sort/tracker/deep/__init__.py
+-rw-rw-r--  2.0 unx     4858 b- defN 23-Apr-11 06:11 asone/trackers/strong_sort/tracker/deep/reid_model_factory.py
+-rw-rw-r--  2.0 unx        0 b- defN 23-Apr-11 06:11 asone/trackers/strong_sort/tracker/sort/__init__.py
+-rw-rw-r--  2.0 unx     1439 b- defN 23-Apr-11 06:11 asone/trackers/strong_sort/tracker/sort/detection.py
+-rw-rw-r--  2.0 unx     2843 b- defN 23-Apr-11 06:11 asone/trackers/strong_sort/tracker/sort/iou_matching.py
+-rw-rw-r--  2.0 unx     8114 b- defN 23-Apr-11 06:11 asone/trackers/strong_sort/tracker/sort/kalman_filter.py
+-rw-rw-r--  2.0 unx     7624 b- defN 23-Apr-11 06:11 asone/trackers/strong_sort/tracker/sort/linear_assignment.py
+-rw-rw-r--  2.0 unx     5770 b- defN 23-Apr-11 06:11 asone/trackers/strong_sort/tracker/sort/nn_matching.py
+-rw-rw-r--  2.0 unx     1914 b- defN 23-Apr-11 06:11 asone/trackers/strong_sort/tracker/sort/preprocessing.py
+-rw-rw-r--  2.0 unx    10653 b- defN 23-Apr-11 06:11 asone/trackers/strong_sort/tracker/sort/track.py
+-rw-rw-r--  2.0 unx     7684 b- defN 23-Apr-11 06:11 asone/trackers/strong_sort/tracker/sort/tracker.py
+-rw-rw-r--  2.0 unx        0 b- defN 23-Apr-11 06:11 asone/trackers/strong_sort/tracker/utils/__init__.py
+-rw-rw-r--  2.0 unx      316 b- defN 23-Apr-11 06:11 asone/trackers/strong_sort/tracker/utils/asserts.py
+-rw-rw-r--  2.0 unx     1125 b- defN 23-Apr-11 06:11 asone/trackers/strong_sort/tracker/utils/draw.py
+-rw-rw-r--  2.0 unx     3532 b- defN 23-Apr-11 06:11 asone/trackers/strong_sort/tracker/utils/evaluation.py
+-rw-rw-r--  2.0 unx     4357 b- defN 23-Apr-11 06:11 asone/trackers/strong_sort/tracker/utils/io.py
+-rw-rw-r--  2.0 unx    11762 b- defN 23-Apr-11 06:11 asone/trackers/strong_sort/tracker/utils/json_logger.py
+-rw-rw-r--  2.0 unx      463 b- defN 23-Apr-11 06:11 asone/trackers/strong_sort/tracker/utils/log.py
+-rw-rw-r--  2.0 unx     1078 b- defN 23-Apr-11 06:11 asone/trackers/strong_sort/tracker/utils/parser.py
+-rw-rw-r--  2.0 unx      734 b- defN 23-Apr-11 06:11 asone/trackers/strong_sort/tracker/utils/tools.py
+-rw-rw-r--  2.0 unx      430 b- defN 23-Apr-14 11:19 asone/utils/__init__.py
 -rw-rw-r--  2.0 unx     1066 b- defN 23-Apr-10 06:15 asone/utils/classes.py
 -rw-rw-r--  2.0 unx      697 b- defN 23-Apr-10 06:15 asone/utils/colors.py
 -rw-rw-r--  2.0 unx      558 b- defN 23-Apr-10 06:15 asone/utils/counting.py
 -rw-rw-r--  2.0 unx      358 b- defN 23-Apr-10 06:15 asone/utils/default_cfg.py
--rw-rw-r--  2.0 unx     4278 b- defN 23-Apr-10 06:15 asone/utils/download.py
+-rw-rw-r--  2.0 unx     4927 b- defN 23-Apr-14 11:59 asone/utils/download.py
 -rw-rw-r--  2.0 unx     4941 b- defN 23-Apr-10 06:15 asone/utils/draw.py
 -rw-rw-r--  2.0 unx      864 b- defN 23-Apr-10 06:15 asone/utils/ponits_conversion.py
 -rw-rw-r--  2.0 unx      796 b- defN 23-Apr-10 06:15 asone/utils/temp_loader.py
--rw-rw-r--  2.0 unx    35148 b- defN 23-Apr-10 08:01 asone-0.2.5.dist-info/LICENCE
--rw-rw-r--  2.0 unx    12219 b- defN 23-Apr-10 08:01 asone-0.2.5.dist-info/METADATA
--rw-rw-r--  2.0 unx       92 b- defN 23-Apr-10 08:01 asone-0.2.5.dist-info/WHEEL
--rw-rw-r--  2.0 unx       72 b- defN 23-Apr-10 08:01 asone-0.2.5.dist-info/dependency_links.txt
--rw-rw-r--  2.0 unx        6 b- defN 23-Apr-10 08:01 asone-0.2.5.dist-info/top_level.txt
--rw-rw-r--  2.0 unx    20895 b- defN 23-Apr-10 08:01 asone-0.2.5.dist-info/RECORD
-212 files, 1241122 bytes uncompressed, 333260 bytes compressed:  73.1%
+-rw-rw-r--  2.0 unx    35148 b- defN 23-Apr-14 12:20 asone-0.2.6.dist-info/LICENCE
+-rw-rw-r--  2.0 unx    12880 b- defN 23-Apr-14 12:20 asone-0.2.6.dist-info/METADATA
+-rw-rw-r--  2.0 unx       92 b- defN 23-Apr-14 12:20 asone-0.2.6.dist-info/WHEEL
+-rw-rw-r--  2.0 unx       72 b- defN 23-Apr-14 12:20 asone-0.2.6.dist-info/dependency_links.txt
+-rw-rw-r--  2.0 unx        6 b- defN 23-Apr-14 12:20 asone-0.2.6.dist-info/top_level.txt
+-rw-rw-r--  2.0 unx    20895 b- defN 23-Apr-14 12:20 asone-0.2.6.dist-info/RECORD
+212 files, 1248150 bytes uncompressed, 334319 bytes compressed:  73.2%
```

## zipnote {}

```diff
@@ -612,26 +612,26 @@
 
 Filename: asone/utils/ponits_conversion.py
 Comment: 
 
 Filename: asone/utils/temp_loader.py
 Comment: 
 
-Filename: asone-0.2.5.dist-info/LICENCE
+Filename: asone-0.2.6.dist-info/LICENCE
 Comment: 
 
-Filename: asone-0.2.5.dist-info/METADATA
+Filename: asone-0.2.6.dist-info/METADATA
 Comment: 
 
-Filename: asone-0.2.5.dist-info/WHEEL
+Filename: asone-0.2.6.dist-info/WHEEL
 Comment: 
 
-Filename: asone-0.2.5.dist-info/dependency_links.txt
+Filename: asone-0.2.6.dist-info/dependency_links.txt
 Comment: 
 
-Filename: asone-0.2.5.dist-info/top_level.txt
+Filename: asone-0.2.6.dist-info/top_level.txt
 Comment: 
 
-Filename: asone-0.2.5.dist-info/RECORD
+Filename: asone-0.2.6.dist-info/RECORD
 Comment: 
 
 Zip file comment:
```

## asone/__init__.py

```diff
@@ -109,19 +109,42 @@
 YOLOV8S_ONNX = 75
 YOLOV8M_PYTORCH = 76
 YOLOV8M_ONNX = 77
 YOLOV8L_PYTORCH = 78
 YOLOV8L_ONNX = 79
 YOLOV8X_PYTORCH = 80
 YOLOV8X_ONNX = 81
+YOLOV8N_MLMODEL = 139
+YOLOV8S_MLMODEL = 140
+YOLOV8M_MLMODEL = 141
+YOLOV8L_MLMODEL = 142
+YOLOV8X_MLMODEL = 143
+
 
 # coreml
 
 YOLOV5N_MLMODEL = 120
-
+YOLOV5S_MLMODEL = 121
+YOLOV5X6_MLMODEL = 122
+YOLOV5M_MLMODEL = 123
+YOLOV5L_MLMODEL = 124
+YOLOV5X_MLMODEL = 125
+YOLOV5N6_MLMODEL = 126
+YOLOV5S6_MLMODEL = 127
+YOLOV5M6_MLMODEL = 128
+YOLOV5L6_MLMODEL = 129
+    
+
+YOLOV7_TINY_MLMODEL = 130
+YOLOV7_MLMODEL = 131
+YOLOV7_X_MLMODEL = 132
+YOLOV7_W6_MLMODEL = 133
+YOLOV7_E6_MLMODEL = 134
+YOLOV7_D6_MLMODEL = 135
+YOLOV7_E6E_MLMODEL = 136
 
 
 # Text Detectors
 # easyocr
 CRAFT = 82
 DBNET18 = 83
```

## asone/demo_tracker.py

```diff
@@ -1,101 +1,44 @@
-import argparse
-from .trackers import Tracker
-import argparse
 import asone
+from asone import ASOne
 from .utils import draw_boxes
-from .detectors import Detector
 import cv2
-import os
-from loguru import logger
+import argparse
 import time
-import copy
+import os
+
 
 def main(args):
     filter_classes = args.filter_classes
+    video_path = args.video
+
+    os.makedirs(args.output_path, exist_ok=True)
 
     if filter_classes:
         filter_classes = filter_classes.split(',')
-    
-    detector = Detector(asone.YOLOV7_E6_ONNX, weights=args.weights, use_cuda=args.use_cuda).get_detector()
-    tracker = Tracker(asone.BYTETRACK, detector, use_cuda=args.use_cuda).get_tracker()
-
-    cap = cv2.VideoCapture(args.video_path)
-    width = cap.get(cv2.CAP_PROP_FRAME_WIDTH)
-    height = cap.get(cv2.CAP_PROP_FRAME_HEIGHT)
-    fps = cap.get(cv2.CAP_PROP_FPS)
-    frame_count = cap.get(cv2.CAP_PROP_FRAME_COUNT)
-    output_dir = 'data/results'
-    if args.save_results:
-        os.makedirs(output_dir, exist_ok=True)
-        save_path = os.path.join(output_dir, os.path.basename(args.video_path))
-        logger.info(f"video save path is {save_path}")
-
-        video_writer = cv2.VideoWriter(
-            save_path,
-            cv2.VideoWriter_fourcc(*"mp4v"),
-            fps,
-            (int(width), int(height)),
-        )
-
-    frame_id = 1
-    tic = time.time()
-
-    prevTime = 0
-
-    while True:
-        start_time = time.time()
 
-        ret, frame = cap.read()
-        if not ret:
-            break
-        im0 = copy.deepcopy(frame)
 
-        bboxes_xyxy, ids, scores, class_ids = tracker.detect_and_track(
-            frame, filter_classes=filter_classes)
+    detect = ASOne(tracker=asone.BYTETRACK, detector=asone.YOLOV7_PYTORCH, 
+                   use_cuda=True)
 
-        elapsed_time = time.time() - start_time
+    track = detect.track_video(video_path, output_dir=args.output_path, 
+                               save_result=args.save, display=args.display,
+                               filter_classes=filter_classes)
+ 
+    for bbox_details, frame_details in track:
+        bbox_xyxy, ids, scores, class_ids = bbox_details
+        frame, frame_num, fps = frame_details
 
-        logger.info(
-            f'frame {frame_id}/{int(frame_count)} {elapsed_time * 1000:.2f} ms')
 
-        im0 = draw_boxes(im0, bboxes_xyxy, class_ids, identities=ids)
-
-        currTime = time.time()
-        fps = 1 / (currTime - prevTime)
-        prevTime = currTime
-        cv2.line(im0, (20, 25), (127, 25), [85, 45, 255], 30)
-        cv2.putText(im0, f'FPS: {int(fps)}', (11, 35), 0, 1, [
-                    225, 255, 255], thickness=2, lineType=cv2.LINE_AA)
-
-        if args.display:
-            cv2.imshow(' Sample', im0)
-        if args.save_results:
-            video_writer.write(im0)
-
-        frame_id += 1
-
-        if cv2.waitKey(25) & 0xFF == ord('q'):
-            break
-
-    tac = time.time()
-    print(f'Total Time Taken: {tac - tic:.2f}')
-
-
-
-if __name__ == '__main__':
+if __name__=='__main__':
+    
     parser = argparse.ArgumentParser()
-
-    parser.add_argument('video_path', help='Path to input video')
-    parser.add_argument('--cpu', default=True,
-                        action='store_false', dest='use_cuda', help='run on cpu')
-    parser.add_argument('--no_display', default=True,
-                        action='store_false', dest='display', help='Disable display')
-    parser.add_argument('--no_save', default=True,
-                        action='store_false', dest='save_results', help='Disable result saving')
-
+    parser.add_argument("video", help="Path of video")
+    parser.add_argument('--cpu', default=True, action='store_false', dest='use_cuda', help='If provided the model will run on cpu otherwise it will run on gpu')
     parser.add_argument('--filter_classes', default=None, help='Class names seperated by comma (,). e.g. person,car ')
     parser.add_argument('-w', '--weights', default=None, help='Path of trained weights')
+    parser.add_argument('-o', '--output_path', default='data/results', help='path of output file')
+    parser.add_argument('--no_display', action='store_false', default=True, dest='display', help='if provided video will not be displayed')
+    parser.add_argument('--no_save', action='store_false', default=True, dest='save', help='if provided video will not be saved')
 
     args = parser.parse_args()
-
-    main(args)
+    main(args)
```

## asone/detectors/detector.py

```diff
@@ -31,16 +31,16 @@
             onnx = False
             weight = weights
             mlmodel = True    
         elif weights:
             onnx = False
             weight = weights
         else:
-            onnx, weight = get_weight_path(model_flag)
-
+            mlmodel, onnx, weight = get_weight_path(model_flag)
+        
         if model_flag in range(0, 20):
             _detector = YOLOv5Detector(weights=weight,
                                        use_onnx=onnx,
                                        use_cuda=cuda)
         elif model_flag in range(20, 34):
             _detector = YOLOv6Detector(weights=weight,
                                        use_onnx=onnx,
@@ -82,14 +82,26 @@
         
         elif model_flag in range(120, 131):
             # Get exp file and corresponding model for coreml only
             _detector = YOLOv5Detector(weights=weight,
                                        use_onnx=onnx,
                                        mlmodel=mlmodel,
                                        use_cuda=cuda)
+        elif model_flag in range(131, 139):
+            # Get exp file and corresponding model for coreml only
+            _detector = YOLOv7Detector(weights=weight,
+                                       use_onnx=onnx,
+                                       mlmodel=mlmodel,
+                                       use_cuda=cuda)
+        elif model_flag in range(139, 144):
+            # Get exp file and corresponding model for coreml only
+            _detector = YOLOv8Detector(weights=weight,
+                                       use_onnx=onnx,
+                                       mlmodel=mlmodel,
+                                       use_cuda=cuda)
         return _detector
 
     def get_detector(self):
         return self.model
 
     def detect(self,
                image: list,
```

## asone/detectors/easyocr_detector/text_detector.py

```diff
@@ -4,27 +4,29 @@
 
 class TextDetector:
     def __init__(self, detect_network, languages: list = ['en'], use_cuda=True):
         self.use_cuda = use_cuda
         self.detect_network = detect_network
         self.reader = easyocr.Reader(languages, detect_network=self.detect_network ,gpu=self.use_cuda)
         
-    def detect(self, image: list,  freelist: bool = False, **config) -> list:
+    def detect(self, image: list,  freelist: bool=False, return_image=False, **config) -> list:
         """_summary_
         Args:
             image : Image 
             languages (list, optional): List of languages. Defaults to ['en'].
         Returns:
             list: numpy array of extracted text and img info(heigh, width)
         """
         
         h, w = image.shape[0:2]
         horizontal_list, free_list = self.reader.detect(image) 
 
         if horizontal_list[0] == [] and free_list[0] == []:
+            if return_image:
+                return horizontal_list, image
             return np.empty((0, 6)), {'width': w, 'height': h}
         
         if freelist:
             return horizontal_list, free_list, {'width': w, 'height': h}
         
         x_list = []
         y_list = []
@@ -42,8 +44,11 @@
         else:
             horizontal_list = [horizontal_list[0] + new_points]
 
         horizontal_list = np.array(horizontal_list[0])
         horizontal_list[:, [1, 2]] = horizontal_list[:, [2, 1]]
         horizontal_list = np.hstack((horizontal_list, np.array([[0.7, 80]]*len(horizontal_list))))
         
+        if return_image:
+            return horizontal_list, image
+            
         return  horizontal_list, {'width': w, 'height': h}
```

## asone/detectors/utils/weights_path.py

```diff
@@ -16,14 +16,26 @@
             '13': os.path.join('yolov5','weights','yolov5n6.onnx'),
             '14': os.path.join('yolov5','weights','yolov5s6.pt'),
             '15': os.path.join('yolov5','weights','yolov5s6.onnx'),
             '16': os.path.join('yolov5','weights','yolov5m6.pt'),
             '17': os.path.join('yolov5','weights','yolov5m6.onnx'),
             '18': os.path.join('yolov5','weights','yolov5l6.pt'),
             '19': os.path.join('yolov5','weights','yolov5l6.onnx'),
+            
+            '120': os.path.join('yolov5','weights','yolov5n.mlmodel'),
+            '121': os.path.join('yolov5','weights','yolov5s.mlmodel'),
+            '122': os.path.join('yolov5','weights','yolov5x6.mlmodel'),
+            '123': os.path.join('yolov5','weights','yolov5m.mlmodel'),
+            '124': os.path.join('yolov5','weights','yolov5l.mlmodel'),
+            '125': os.path.join('yolov5','weights','yolov5x.mlmodel'),
+            '126': os.path.join('yolov5','weights','yolov5n6.mlmodel'),
+            '127': os.path.join('yolov5','weights','yolov5s6.mlmodel'),
+            '128': os.path.join('yolov5','weights','yolov5m6.mlmodel'),
+            '129': os.path.join('yolov5','weights','yolov5l6.mlmodel'),
+            
             # YOLOv6
             '20': os.path.join('yolov6','weights','yolov6n.pt'),
             '21': os.path.join('yolov6','weights','yolov6n.onnx'),
             '22': os.path.join('yolov6','weights','yolov6t.pt'),
             '23': os.path.join('yolov6','weights','yolov6t.onnx'),
             '24': os.path.join('yolov6','weights','yolov6s.pt'),
             '25': os.path.join('yolov6','weights','yolov6s.onnx'),
@@ -46,14 +58,22 @@
             '41': os.path.join('yolov7','weights','yolov7-w6.onnx'),
             '42': os.path.join('yolov7','weights','yolov7-e6.pt'),
             '43': os.path.join('yolov7','weights','yolov7-e6.onnx'),
             '44': os.path.join('yolov7','weights','yolov7-d6.pt'),
             '45': os.path.join('yolov7','weights','yolov7-d6.onnx'),
             '46': os.path.join('yolov7','weights','yolov7-e6e.pt'),
             '47': os.path.join('yolov7','weights','yolov7-e6e.onnx'),
+            
+            '130': os.path.join('yolov7','weights','yolov7-tiny.mlmodel'),
+            '131': os.path.join('yolov7','weights','yolov7.mlmodel'),
+            '132': os.path.join('yolov7','weights','yolov7x.mlmodel'),
+            '133': os.path.join('yolov7','weights','yolov7-w6.mlmodel'),
+            '134': os.path.join('yolov7','weights','yolov7-e6.mlmodel'),
+            '135': os.path.join('yolov7','weights','yolov7-d6.mlmodel'),
+            '136': os.path.join('yolov7','weights','yolov7-e6e.mlmodel'),
             # YOLOR
             '48': os.path.join('yolor','weights','yolor_csp_x.pt'),
             '49': os.path.join('yolor','weights','yolor_csp_x.onnx'),
             '50': os.path.join('yolor','weights','yolor_csp_x_star.pt'),
             '51': os.path.join('yolor','weights','yolor_csp_x_star.onnx'),
             '52': os.path.join('yolor','weights','yolor_csp_star.pt'),
             '53': os.path.join('yolor','weights','yolor_csp_star.onnx'),
@@ -83,20 +103,28 @@
             '75': os.path.join('yolov8','weights','yolov8s.onnx'),
             '76': os.path.join('yolov8','weights','yolov8m.pt'),
             '77': os.path.join('yolov8','weights','yolov8m.onnx'),
             '78': os.path.join('yolov8','weights','yolov8l.pt'),
             '79': os.path.join('yolov8','weights','yolov8l.onnx'),
             '80': os.path.join('yolov8','weights','yolov8x.pt'),
             '81': os.path.join('yolov8','weights','yolov8x.onnx'),
+            '139': os.path.join('yolov8','weights','yolov8n.mlmodel'),
+            '140': os.path.join('yolov8','weights','yolov8s.mlmodel'),
+            '141': os.path.join('yolov8','weights','yolov8m.mlmodel'),
+            '142': os.path.join('yolov8','weights','yolov8l.mlmodel'),
+            '143': os.path.join('yolov8','weights','yolov8x.mlmodel'),
+            
             # Text Detectors
             '82': 'craft',
-            '83': 'dbnet18'
+            '83': 'dbnet18',
+             
 }
 
 def get_weight_path(model_flag):
+    coreml= False
     if model_flag in range(0, 20):
         onnx = False if (model_flag % 2 == 0) else True
         weight = weights[str(model_flag)]
     elif model_flag in range(20, 34):
         onnx = False if (model_flag % 2 == 0) else True
         weight = weights[str(model_flag)]
     elif model_flag in range(34, 48):
@@ -110,9 +138,22 @@
         weight = weights[str(model_flag)]
     elif model_flag in range(72, 82):
         onnx = False if (model_flag % 2 == 0) else True
         weight = weights[str(model_flag)]
     elif model_flag in range(82, 85):
         onnx = False
         weight = weights[str(model_flag)]
-    return onnx, weight
+        
+    elif model_flag in range(120, 130):
+        weight = weights[str(model_flag)]
+        onnx=False
+        coreml = True
+    elif model_flag in range(130, 137):
+        weight = weights[str(model_flag)]
+        onnx=False
+        coreml = True    
+    elif model_flag in range(139, 145):
+        weight = weights[str(model_flag)]
+        onnx=False
+        coreml = True
+    return coreml, onnx, weight
```

## asone/detectors/yolov5/yolov5_detector.py

```diff
@@ -85,15 +85,18 @@
             # Run mlmodel   
         
         elif self.mlmodel:
             h ,w = image.shape[:2]
             pred = self.model.predict({"image":Image.fromarray(image).resize(input_shape)})
             xyxy = yolo_to_xyxy(pred['coordinates'], input_shape)
             out = generalize_output_format(xyxy, pred['confidence'], conf_thres)
-            detections = scale_bboxes(out, image.shape[:2], input_shape)
+            if out != []:
+                detections = scale_bboxes(out, image.shape[:2], input_shape)
+            else:
+                detections = np.empty((0, 6))
             
             if filter_classes:
                 class_names = get_names()
 
                 filter_class_idx = []
                 if filter_classes:
                     for _class in filter_classes:
```

## asone/detectors/yolov7/yolov7_detector.py

```diff
@@ -1,27 +1,42 @@
 import os
 import sys
 import onnxruntime
 import torch
+import coremltools as ct
 from asone.utils import get_names
 import numpy as np
 import warnings
 from asone.detectors.yolov7.yolov7.utils.yolov7_utils import (prepare_input,
                                  process_output,
                                  non_max_suppression)
 from asone.detectors.yolov7.yolov7.models.experimental import attempt_load
 from asone import utils
+from PIL import Image
+from asone.detectors.utils.coreml_utils import yolo_to_xyxy, generalize_output_format, scale_bboxes
+
+def xywh2xyxy(x):
+    # Convert nx4 boxes from [x, y, w, h] to [x1, y1, x2, y2] where xy1=top-left, xy2=bottom-right
+    y = x.clone() if isinstance(x, torch.Tensor) else np.copy(x)
+    y[:, 0] = x[:, 0] - x[:, 2] / 2  # top left x
+    y[:, 1] = x[:, 1] - x[:, 3] / 2  # top left y
+    y[:, 2] = x[:, 0] + x[:, 2] / 2  # bottom right x
+    y[:, 3] = x[:, 1] + x[:, 3] / 2  # bottom right y
+    return y
+
 
 sys.path.append(os.path.join(os.path.dirname(__file__), 'yolov7'))
 class YOLOv7Detector:
     def __init__(self,
                  weights=None,
                  use_onnx=False,
+                 mlmodel=False,
                  use_cuda=True):
         self.use_onnx = use_onnx
+        self.mlmodel = mlmodel
         self.device = 'cuda' if use_cuda else 'cpu'
 
         #If incase weighst is a list of paths then select path at first index
 
         weights = str(weights[0] if isinstance(weights, list) else weights)
 
         if not os.path.exists(weights):
@@ -38,14 +53,17 @@
         if self.use_onnx:            
             if use_cuda:
                 providers = ['CUDAExecutionProvider','CPUExecutionProvider']
             else:
                 providers = ['CPUExecutionProvider']
 
             model = onnxruntime.InferenceSession(weights, providers=providers)
+        # Load coreml
+        elif self.mlmodel:
+            model = ct.models.MLModel(weights)
         #Load Pytorch
         else: 
             model = attempt_load(weights, map_location=self.device)
             model.half() if self.fp16 else model.float()
         return model
 
 
@@ -66,38 +84,68 @@
         
         # Perform Inference on the Image
         if self.use_onnx:
         # Run ONNX model 
             input_name = self.model.get_inputs()[0].name
             prediction = self.model.run([self.model.get_outputs()[0].name], {
                                  input_name: processed_image})
+        # Run Coreml model 
+        elif self.mlmodel:
+            h ,w = image.shape[:2]
+            pred = self.model.predict({"image":Image.fromarray(image).resize(input_shape)})
+            xyxy = yolo_to_xyxy(pred['coordinates'], input_shape)
+            out = generalize_output_format(xyxy, pred['confidence'], conf_thres)
+            if out != []:
+                detections = scale_bboxes(out, image.shape[:2], input_shape)
+            else:
+                detections = np.empty((0, 6))
+            
+            if filter_classes:
+                class_names = get_names()
+
+                filter_class_idx = []
+                if filter_classes:
+                    for _class in filter_classes:
+                        if _class.lower() in class_names:
+                            filter_class_idx.append(class_names.index(_class.lower()))
+                        else:
+                            warnings.warn(f"class {_class} not found in model classes list.")
+
+                detections = detections[np.in1d(detections[:,5].astype(int), filter_class_idx)]
+            
+            return detections, {'width':w, 'height':h}
         # Run Pytorch model
         else:
             processed_image = torch.from_numpy(processed_image).to(self.device)
             # Change image floating point precision if fp16 set to true
             processed_image = processed_image.half() if self.fp16 else processed_image.float() 
 
             with torch.no_grad():
                 prediction = self.model(processed_image, augment=False)[0]
+
                 
         detection = []
         # Postprocess prediction
         if self.use_onnx:
+            
             detection = process_output(prediction,
                                        original_image.shape[:2],
                                        input_shape,
                                        conf_thres,
                                        iou_thres)
         else:
             detection = non_max_suppression(prediction,
                                             conf_thres,
                                             iou_thres,
                                             agnostic=agnostic_nms)[0]
             
             detection = detection.detach().cpu().numpy()
+            # detection = yolo_to_xyxy(detection, input_shape)
+            # print(detection)
+            
             # Rescaling Bounding Boxes
             detection[:, :4] /= np.array([input_shape[1], input_shape[0], input_shape[1], input_shape[0]])
             detection[:, :4] *= np.array([img_width, img_height, img_width, img_height])
 
         image_info = {
             'width': original_image.shape[1],
             'height': original_image.shape[0],
```

## asone/detectors/yolov7/yolov7/utils/yolov7_utils.py

```diff
@@ -147,14 +147,15 @@
     max_nms = 30000  # maximum number of boxes into torchvision.ops.nms()
     time_limit = 10.0  # seconds to quit after
     redundant = True  # require redundant detections
     multi_label &= nc > 1  # multiple labels per box (adds 0.5ms/img)
     merge = False  # use merge-NMS
 
     t = time.time()
+   
     output = [torch.zeros((0, 6), device=prediction.device)] * prediction.shape[0]
     for xi, x in enumerate(prediction):  # image index, image inference
         # Apply constraints
         # x[((x[..., 2:4] < min_wh) | (x[..., 2:4] > max_wh)).any(1), 4] = 0  # width-height
         x = x[xc[xi]]  # confidence
 
         # Cat apriori labels if autolabelling
```

## asone/detectors/yolov8/yolov8_detector.py

```diff
@@ -4,22 +4,27 @@
 import onnxruntime
 import torch
 from .utils.yolov8_utils import prepare_input, process_output
 import numpy as np
 import warnings
 from ultralytics.nn.autobackend import AutoBackend
 from ultralytics.nn.tasks import DetectionModel, attempt_load_one_weight
+import coremltools as ct
+from PIL import Image
+from asone.detectors.utils.coreml_utils import yolo_to_xyxy, generalize_output_format, scale_bboxes
 
 
 class YOLOv8Detector:
     def __init__(self,
                  weights=None,
                  use_onnx=False,
+                 mlmodel=False,
                  use_cuda=True):
 
+        self.mlmodel = mlmodel
         self.use_onnx = use_onnx
         self.device = 'cuda' if use_cuda else 'cpu'
 
         # If incase weighst is a list of paths then select path at first index
         weights = str(weights[0] if isinstance(weights, list) else weights)
 
         if not os.path.exists(weights):
@@ -38,14 +43,18 @@
         if self.use_onnx:
             if use_cuda:
                 providers = ['CUDAExecutionProvider', 'CPUExecutionProvider']
             else:
                 providers = ['CPUExecutionProvider']
 
             model = onnxruntime.InferenceSession(weights, providers=providers)
+        # Load coreml
+        elif self.mlmodel:
+            model = ct.models.MLModel(weights)
+            
         # Load Pytorch
         else:
             model, ckpt = attempt_load_one_weight(weights)
             model = AutoBackend(model, fp16=False, dnn=False).to(self.device)
             model.half() if self.fp16 else model.float()
         return model
 
@@ -68,32 +77,59 @@
         # Perform Inference on the Image
         if self.use_onnx:
             # Run ONNX model
             input_name = self.model.get_inputs()[0].name
             prediction = self.model.run([self.model.get_outputs()[0].name], {
                 input_name: processed_image})[0]
             prediction = torch.from_numpy(prediction)
+        # Run Coreml model
+        elif self.mlmodel:
+            im = Image.fromarray(image).resize(input_shape)
+            y = self.model.predict({"image":im})
+            
+            if 'confidence' in y:
+                box = xywh2xyxy(y['coordinates'] * [[w, h, w, h]])  # xyxy pixels
+                conf, cls = y['confidence'].max(1), y['confidence'].argmax(1).astype(np.float)
+                y = np.concatenate((box, conf.reshape(-1, 1), cls.reshape(-1, 1)), 1)
+            else:
+                k = 'var_' + str(sorted(int(k.replace('var_', '')) for k in y)[-1])  # output key
+                y = y[k]  # output
+            width, height = im.size
+            prediction = torch.from_numpy(y)
         # Run Pytorch model
         else:
             processed_image = torch.from_numpy(processed_image).to(self.device)
             # Change image floating point precision if fp16 set to true
             processed_image = processed_image.half() if self.fp16 else processed_image.float()
 
             with torch.no_grad():
                 prediction = self.model(processed_image, augment=False)
-
+                
         detection = []
         # Postprocess prediction
-        detection = process_output(prediction,
+        
+        if self.mlmodel:
+            detection = process_output(prediction,
                                    original_image.shape[:2],
-                                   processed_image.shape[2:],
+                                   [640, 640],
                                    conf_thres,
                                    iou_thres,
+                                   mlmodel=True,
                                    agnostic=agnostic_nms,
                                    max_det=max_det)
+        
+            detection = scale_bboxes(detection, original_image.shape[:2], input_shape)
+        else:
+            detection = process_output(prediction,
+                                    original_image.shape[:2],
+                                    processed_image.shape[2:],
+                                    conf_thres,
+                                    iou_thres,
+                                    agnostic=agnostic_nms,
+                                    max_det=max_det)
 
         image_info = {
             'width': original_image.shape[1],
             'height': original_image.shape[0],
         }
 
         if filter_classes:
```

## asone/detectors/yolov8/utils/yolov8_utils.py

```diff
@@ -15,25 +15,30 @@
 
 def process_output(detections, 
                    ori_shape, 
                    input_shape, 
                    conf_threshold, 
                    iou_threshold,
                    classes=None,
+                   mlmodel=False,
                    agnostic=False,
                    max_det=300,
                    ):
     detections = ops.non_max_suppression(detections,
                                           conf_thres=conf_threshold,
                                           iou_thres=iou_threshold,
                                           classes=classes,
                                           agnostic=agnostic,
                                           max_det=max_det,
                                           )
 
+    if mlmodel:
+        detection = detections[0].cpu().numpy()
+        return detection
+
     for i in range(len(detections)): 
         # Extract boxes from predictions
         detections[i][:, :4] = ops.scale_boxes(input_shape, detections[i][:, :4], ori_shape).round()
 
     
     return detections[0].cpu().numpy()
```

## asone/trackers/strong_sort/strongsort.py

```diff
@@ -9,27 +9,28 @@
         self.detector = detector
         try:
             self.input_shape = tuple(detector.model.get_inputs()[0].shape[2:])
         except AttributeError as e:
             self.input_shape = (640, 640)
         
     def detect_and_track(self, image: np.ndarray, config: dict) -> tuple:
-                       
+           
         _dets_xyxy, img = self.detector.detect(
             image, **config, return_image=True
             )
         
         bbox_xyxy = _dets_xyxy[:, :4]
         conf = _dets_xyxy[:, 4]
         classes = _dets_xyxy[:, 5]
         
-        if isinstance(_dets_xyxy, np.ndarray) and len(_dets_xyxy) > 0:
-            dets = self.tracker.update(bbox_xyxy, conf, classes, img)
-            dets = np.array(dets)
-            if dets != []:
-                bbox_xyxy = dets[:, :4]
-                ids = dets[:, 4]
-                class_ids = dets[:, 5]
-                scores = dets[:, 6]
-                return bbox_xyxy, ids, scores, class_ids
-            else:
-                return [], [], [], []
+        # if isinstance(_dets_xyxy, np.ndarray) and len(_dets_xyxy) > 0:
+        dets = self.tracker.update(bbox_xyxy, conf, classes, img)
+        dets = np.array(dets)
+    
+        if dets != []:
+            bbox_xyxy = dets[:, :4]
+            ids = dets[:, 4]
+            class_ids = dets[:, 5]
+            scores = dets[:, 6]
+            return bbox_xyxy, ids, scores, class_ids
+        else:
+            return [], [], [], []
```

## asone/utils/download.py

```diff
@@ -10,34 +10,35 @@
 
 def download_weights(weights):
 
     outputpath = os.path.dirname(weights)
     model = os.path.splitext(os.path.basename(weights))[0]
     filename = f'{model}.zip'
 
+
     if model == 'yolov5s':
-        model_key = '1H7G8ryDXs6bKlK2Qot7-2uIkjEYoYook'
+        model_key = '1W5ypZmrYE4_Aqu3Jqsl-IDvLK6SOtJCK'
     elif model == 'yolov5x6':
-        model_key = '161bThpOB4HDqrh2FXvbFZJmiSKFwS_Wb'
+        model_key = '1CTYtGC8VFZD0uJbU4fcSPSjcYb8Be0jU'
     elif model == 'yolov5n':
-        model_key = '1zI4f0AUHAz-fTE_fP7UyiFSRGBYYXd7x'
+        model_key = '1q9_e76T_b353QmG5xGi3zkselGQrxuBk'
     elif model == 'yolov5m':
-        model_key = '1vy8S68wbUzKSHMhsTuLN-VA7lMzKchAa'
+        model_key = '1Vv3VEkgYd7WB-3e2MPo0QUKq_-F7biBP'
     elif model == 'yolov5l':
-        model_key = '1pQL9s0o3v6CycAgAX8SkxCfordUl5IxZ'
+        model_key = '1Wr4S7BTqqCOCP14T_aDgVxGV5h9pMM-n'
     elif model == 'yolov5x':
-        model_key = '1iB7MQ1IP3MVKLMF8TIJ44vtv9cjWC2qH'
+        model_key = '18g_pjpwsnOlBKbhApuaTsbQUIDO75BSt'
     elif model == 'yolov5n6':
-        model_key = '1YxnRYlPcCqXGbX20kPlfSimNfROKwoJH'
+        model_key = '1gOAZ90nKcvo7bhNZCZM-JRuY8FBeEkhl'
     elif model == 'yolov5s6':
-        model_key = '1mm5zY6IpPtM7IZh_X5x0kAxuO7INKyte'
+        model_key = '12W1Z0esjFc9UhiWWxCESjhm5KA3nzSwt'
     elif model == 'yolov5m6':
-        model_key = '1qv_uan5oNq9skcg1UThfaFs0xMs2mSE2'
+        model_key = '1O-bbJ8WcqLig40IUyJ8ulKwj-J_KXvHr'
     elif model == 'yolov5l6':
-        model_key = '1eaM51cIh8i_EXmg6Nf0Sx2uW53pT7wZR'
+        model_key = '1sPZ-YpenYojZSIB5G1SMv2hPWX5oRwlb'
     elif model == 'yolov6n':
         model_key = '1NA_u4BkPE_N8HcPmZrd7HyLmvFHOk8qd'
     elif model == 'yolov6t':
         model_key = '16OWncBp-vh-sLDMOR58th3WOGv4envQ1'
     elif model == 'yolov6s':
         model_key = '14BE0j654ClLxMq2ySWZNhTCmf48mLyXi'
     elif model == 'yolov6l_relu':
@@ -45,27 +46,27 @@
     elif model == 'yolov6l':
         model_key = '1HdRIs0uMPbqs5E2aEX8O3d3dJTh-KBTf'
     elif model == 'yolov6m':
         model_key = '1t_w9SCwbZAW7icwX_z97-SQz-plXzBgM'
     elif model == 'yolov6s_repopt':
         model_key = '1L_1Crxx-4059xDDUZEf_asWRBVd3PF05'
     elif model == 'yolov7-e6e':
-        model_key = '1rQR5KiSJiWtpHEniAyeBQdpXFb7Wv1UT'
+        model_key = '1PZwpKdHEP4Li3FkKNYn90HmGNiIjMMfi'
     elif model == 'yolov7-d6':
-        model_key = '1idAyjdq9pVsgkDCCfADbGOjxGq4TPulB'
+        model_key = '1_Ybtx7EAXnBwIZ59Vgo0FkXsCdjRuq2s'
     elif model == 'yolov7':
-        model_key = '10XNOpBAmMrYqmXOsJLl79MGtuGWY2zAl'
+        model_key = '17iFeNfq5hKZVpQLQEgZzxF9Da5o5llLG'
     elif model == 'yolov7-tiny':
-        model_key = '1ut2doFvtQSKGjiHGPBsEItZlTTj-7_rF'
+        model_key = '18Fels44wVJ1vG7yDuDPuWwuiAqeFxKI7'
     elif model == 'yolov7-e6':
-        model_key = '1E9pow2PFcvil0iqRx2tRCI4HLduh9gp0'
+        model_key = '1g_2nYpeJ28cLYcOAUeztHUA5R-stk3Cm'
     elif model == 'yolov7-w6':
-        model_key = '1B8j9XMZxGxz8kpsqJhKXuk1TE_244n6t'
+        model_key = '1wv3M23RFo0MhaujegBPY6gZ30IA894CO'
     elif model == 'yolov7x':
-        model_key = '1FiGLXG6_3He21ean4bFET471Wrj-3oc3'
+        model_key = '1zZskyvdgU45Ke8TtCA6csdCzqLrhmFYx'
     elif model == 'yolor_csp':
         model_key = '1G3FBZKrznW_64mGfs6b3nAJiJv6GmmV0'
     elif model == 'yolor_csp_star':
         model_key = '15WDl46ZthFGZfpOyI3qXx6gC9FQLH_wH'
     elif model == 'yolor_csp_x':
         model_key = '1LU2ckh7eSpVD0nyPSdq1n34lKmNAX39T'
     elif model == 'yolor_csp_x_star':
@@ -86,28 +87,50 @@
         model_key = '1ktHj8UEwl0V8Qz9G74E-yj-o13FLeD0-'
     elif model == 'yolox_x':
         model_key = '13HNnlILCx_XamNJWwJ1MG5x0XfP6HL1U'
     elif model == 'ckpt':
         model_key = '1VZ05gzg249Q1m8BJVQxl3iHoNIbjzJf8'
 
     elif model == 'yolov8s':
-        model_key = '1rokjGeiLlLSNugd6LuGQj6Yr_i5_XH3Y'
+        model_key = '1hUhjQWw1cJL7TtBG0zD3MO52iCYh0DEn'
     elif model == 'yolov8n':
-        model_key = '1JslnzKzY7bHRQWiLfvcINteIOgyOv_oU'
+        model_key = '1x6zHzsEcyhuyWy2xY3swAQ4vIQvBYrsr'
     elif model == 'yolov8l':
-        model_key = '1Zlp3e9gBQtgt76SHWpRNdEw4rXeT4GxE'
+        model_key = '1xQxHTEIpoiP4d73F6dtedU7hIZpFTqY2'
     elif model == 'yolov8m':
-        model_key = '1ijE_fou-U-UJb4xRspFK0OnPfsLcuw3U'
+        model_key = '1_FoKnqkaoWchVy4B24Hn2PanEKfh-eSp'
     elif model == 'yolov8x':
-        model_key = '1vtkXtgSLG49l-mh8zzgF9xZdM1ZuRldI'
+        model_key = '1s60fsjiyDlPQ1L5H_GAoWahHONLbvz7T'
         
     else:
         raise ValueError(f'No model named {model} found.')
 
     url = f'https://drive.google.com/uc?id={model_key}&confirm=t'
     gdown.download(url, output=filename, quiet=False)
 
     if not os.path.exists(outputpath):
         os.makedirs(outputpath)
 
     exractfile(filename, outputpath)
     os.remove(filename)
+
+# def download_weights(weights):
+    
+#     f = open('asone/utils/weights.json')
+#     data = json.load(f)
+    
+#     outputpath = os.path.dirname(weights)
+#     model = os.path.splitext(os.path.basename(weights))[0]
+#     filename = f'{model}.zip'
+#     if model in data:
+#         model_key = data[model]
+#     else:
+#         raise ValueError(f'No model named {model} found.')
+
+#     url = f'https://drive.google.com/uc?id={model_key}&confirm=t'
+#     gdown.download(url, output=filename, quiet=False)
+
+#     if not os.path.exists(outputpath):
+#         os.makedirs(outputpath)
+
+#     exractfile(filename, outputpath)
+#     os.remove(filename)
```

## Comparing `asone-0.2.5.dist-info/LICENCE` & `asone-0.2.6.dist-info/LICENCE`

 * *Files identical despite different names*

## Comparing `asone-0.2.5.dist-info/METADATA` & `asone-0.2.6.dist-info/METADATA`

 * *Files 4% similar despite different names*

```diff
@@ -1,10 +1,10 @@
 Metadata-Version: 2.1
 Name: asone
-Version: 0.2.5
+Version: 0.2.6
 Summary: UNKNOWN
 Home-page: https://github.com/axcelerateai/asone
 Author: AxcelerateAI
 Author-email: umair.imran@axcelerate.ai
 License: BSD 2-clause
 Keywords: asone bytetrack deepsort norfair yolo yolox yolor yolov5 yolov7 installation inferencing
 Platform: UNKNOWN
@@ -24,15 +24,15 @@
 Requires-Dist: easydict
 Requires-Dist: gdown
 Requires-Dist: lap
 Requires-Dist: loguru
 Requires-Dist: motpy
 Requires-Dist: norfair
 Requires-Dist: numpy (==1.23.3)
-Requires-Dist: onnxruntime-gpu (==1.12.1)
+Requires-Dist: onnxruntime
 Requires-Dist: opencv-python
 Requires-Dist: pandas
 Requires-Dist: pyyaml
 Requires-Dist: scipy
 Requires-Dist: tabulate
 Requires-Dist: tensorboard
 Requires-Dist: torch
@@ -95,15 +95,15 @@
 python3 -m venv .env
 source .env/bin/activate
 
 pip install numpy Cython
 pip install cython-bbox
 
 pip install asone
-
+pip install onnxruntime-gpu==1.12.1
 
 # for CPU
 pip install torch torchvision
 
 # for GPU
 pip install torch torchvision --extra-index-url https://download.pytorch.org/whl/cu113
 
@@ -116,24 +116,44 @@
 ```shell
 python -m venv .env
 .env\Scripts\activate
 pip install numpy Cython
 pip install -e git+https://github.com/samson-wang/cython_bbox.git#egg=cython-bbox
 
 pip install asone
-
+pip install onnxruntime-gpu==1.12.1
 # for CPU
 pip install torch torchvision
 
 # for GPU
 pip install torch torchvision --extra-index-url https://download.pytorch.org/whl/cu113
 or
 pip install torch==1.10.1+cu113 torchvision==0.11.2+cu113 torchaudio===0.10.1+cu113 -f https://download.pytorch.org/whl/cu113/torch_stable.html
 ```
 </details>
+<details>
+<summary>For macOS</summary>
+
+```shell
+python3 -m venv .env
+source .env/bin/activate
+
+pip install numpy Cython
+pip install cython-bbox
+
+pip install asone
+
+# for CPU
+pip install torch torchvision
+
+# for GPU
+pip install torch torchvision --extra-index-url https://download.pytorch.org/whl/cu113
+
+```
+</details>
 
 ## 5. Running AS-One
 
 Run `main.py` to test tracker on `data/sample_videos/test.mp4` video
 
 ```
 python main.py data/sample_videos/test.mp4
@@ -176,15 +196,14 @@
 
     cv2.imshow('result', frame)
 
     if cv2.waitKey(25) & 0xFF == ord('q'):
         break
 ```
 
-
 Run the `asone/demo_detector.py` to test detector.
 
 ```shell
 # run on gpu
 python -m asone.demo_detector data/sample_videos/test.mp4
 
 # run on cpu
@@ -231,18 +250,26 @@
 ```
 </details>
 
 <details>
 <summary>6.1.2. Changing Detector Models </summary>
 
 Change detector by simply changing detector flag. The flags are provided in [benchmark](asone/linux/Instructions/Benchmarking.md) tables.
-
+* Our library now supports YOLOv5, YOLOv7, and YOLOv8 on macOS.
 ```python
 # Change detector
 detector = ASOne(detector=asone.YOLOX_S_PYTORCH, use_cuda=True)
+
+# For macOs
+# YOLO5
+detector = ASOne(detector=asone.YOLOV5X_MLMODEL, use_cuda=True)
+# YOLO7
+detector = ASOne(detector=asone.YOLO7_MLMODEL, use_cuda=True)
+# YOLO8
+detector = ASOne(detector=asone.YOLOV8L_MLMODEL, use_cuda=True)
 ```
 
 </details>
 
 </details>
 
 <details>
@@ -295,15 +322,14 @@
     bbox_xyxy, ids, scores, class_ids = bbox_details
     frame, frame_num, fps = frame_details
     # Do anything with bboxes here
 ```
 
 [Note] Use can use custom weights for a detector model by simply providing path of the weights file. in `ASOne` class.
 
-
 <details>
 <summary>6.2.1 Changing Detector and Tracking Models</summary>
 
 <!-- ### Changing Detector and Tracking Models -->
 
 Change Tracker by simply changing the tracker flag.
 
@@ -356,15 +382,15 @@
 
 Use Tracker on Text
 ```python
 import asone
 from asone import ASOne
 
 # Instantiate Asone object
-detect = ASOne(tracker=asone.BYTETRACK, detector=asone.CRAFT, recognizer=asone.EASYOCR, use_cuda=True) #set use_cuda=False to use cpu
+detect = ASOne(tracker=asone.DEEPSORT, detector=asone.CRAFT, recognizer=asone.EASYOCR, use_cuda=True) #set use_cuda=False to use cpu
 
 # ##############################################
 #           To track using video file
 # ##############################################
 # Get tracking function
 track = detect.track_video('data/sample_videos/GTA_5-Unique_License_Plate.mp4', output_dir='data/results', save_result=True, display=True)
 
@@ -392,14 +418,14 @@
 # ToDo
 - [x] First Release
 - [x] Import trained models
 - [x] Simplify code even further
 - [x] Updated for YOLOv8
 - [x] OCR and Counting
 - [x] OCSORT, StrongSORT, MoTPy
-- [ ] M1/2 Apple Silicon Compatibility
+- [x] M1/2 Apple Silicon Compatibility
 
 |Offered By: |Maintained By:|
 |-------------|-------------|
 |[![AugmentedStarups](https://user-images.githubusercontent.com/107035454/195115263-d3271ef3-973b-40a4-83c8-0ade8727dd40.png)](https://augmentedstartups.com)|[![AxcelerateAI](https://user-images.githubusercontent.com/107035454/195114870-691c8a52-fcf0-462e-9e02-a720fc83b93f.png)](https://axcelerate.ai/)|
```

## Comparing `asone-0.2.5.dist-info/RECORD` & `asone-0.2.6.dist-info/RECORD`

 * *Files 2% similar despite different names*

```diff
@@ -1,21 +1,21 @@
-asone/__init__.py,sha256=yJEAKfShOaEmusERTIaJgnD393TBX1BZ3QDBCFvERhY,2117
+asone/__init__.py,sha256=7EVlBSwXavBH8PtQsFBqLR7zygcXuAfT74fwaQNky9w,2603
 asone/asone.py,sha256=UazrS9iJ8w4vRBI5wVjJPbpZFdSpVmrf59FaG2Ujdpw,7408
 asone/demo_detector.py,sha256=Va6ahBMHn8R5GA7hrXPvCJ-hcQe5laC52P4hFMNzLXE,2715
 asone/demo_ocr.py,sha256=W-pRUC_z52Wb-9_C8f12N25npc3jIy-l0sttn_ylE3M,2149
-asone/demo_tracker.py,sha256=6eOOUXlbQ2hyRQL7q6l6-I0v6j0n17A0xO1s158FtIw,3139
+asone/demo_tracker.py,sha256=e9QUI-DYL1LJv7SN6utCYmupCcRiSO5rt2Fv6DAQlqU,1713
 asone/detectors/__init__.py,sha256=VBuECYTWxrnHVMOW5txTnztTc1pVfASsK5tI8ZfaSFs,543
-asone/detectors/detector.py,sha256=95J5vqiDHHWWFnqxAFFyXqEibGH9TXvvCwANyyH7m0w,4234
+asone/detectors/detector.py,sha256=27fgnY-BwuckJCnGy8_ZRWeeRBvp1aClb4ifsCt3T8A,4911
 asone/detectors/easyocr_detector/__init__.py,sha256=s6CVaMCy-Y4-k7gxZ6jCg28mGp_YxrvweOICgMwbLzc,66
-asone/detectors/easyocr_detector/text_detector.py,sha256=pt3dZpk-itpItXHoYyzk4y0jHPXdeaP9QFAxiimnUGk,1921
+asone/detectors/easyocr_detector/text_detector.py,sha256=l_Ao5QIO39v2FoXKROrt0wezaToPE9IWGj-HwihfCOk,2094
 asone/detectors/utils/__init__.py,sha256=47DEQpj8HBSa-_TImW-5JCeuQeRkm5NMpJWZG3hSuFU,0
 asone/detectors/utils/cfg_path.py,sha256=meeJjd_Ici6Khmf7YjuTErq4mrJAE1qDqhtXPDFiSn0,533
 asone/detectors/utils/coreml_utils.py,sha256=G4qkahiEnLxHPT_nxI0SAZ7Qy34r3zf036ZSNhsF_Gc,1545
 asone/detectors/utils/exp_name.py,sha256=znQ0oMgfyFSEWI6YOgjekVsGdWOeOI-Uom9BLdL9YNY,1478
-asone/detectors/utils/weights_path.py,sha256=qHt_bCsVvNE527BAtUtxHMVHagc_DN42p3GtQiXbGUo,6694
+asone/detectors/utils/weights_path.py,sha256=p-rWdnBHSrGsj14c4yHAeQp3u178PEk72Am39zV4FjA,8748
 asone/detectors/yolor/__init__.py,sha256=rK6ZEZXSC091X3i_towa6w7-DC0ABVOMF3tsUZdqftA,69
 asone/detectors/yolor/yolor_detector.py,sha256=GPfszy9rdsv1F_8kdUScrQdrGcSRzLT6y41lHKiQ_3M,5315
 asone/detectors/yolor/cfg/yolor_csp.cfg,sha256=03194cNE7d-d3freWbD6Jfn1qIl6clliprVW8nHYj8E,14241
 asone/detectors/yolor/cfg/yolor_csp_x.cfg,sha256=jokGophucWBWc7YB5mnBffkUWmojxu-a4Z2aKa54FO8,16338
 asone/detectors/yolor/cfg/yolor_p6.cfg,sha256=4sEvW_-v-cZU9Azpx-oG9eU1RstD4Ni1Q2ZuElCo-6o,18330
 asone/detectors/yolor/models/__init__.py,sha256=AbpHGcgLb-kRsJGnwFEktk7uzpZOCcBY74-YBdrKVGs,1
 asone/detectors/yolor/models/common.py,sha256=e23HDO0VBXkT__m8Smgq-iY1XCPj7eR16bfDIBvPJjc,38971
@@ -32,15 +32,15 @@
 asone/detectors/yolor/utils/loss.py,sha256=sw3zUfj4lsER3qEllr0oz1P1UcfFYhjcWaQ0fhUUzss,7443
 asone/detectors/yolor/utils/metrics.py,sha256=vmxuZ9LKAHOVZ7L1AFG_xtJC_AYqo8Em2SlPZulAtC8,5137
 asone/detectors/yolor/utils/parse_config.py,sha256=VFeWMavkPpT6ddQW6HIGsdEDMkxWg7gOXlQEM-K0m3o,2995
 asone/detectors/yolor/utils/plots.py,sha256=19Z3Xk4Z28BnPruyoPpeyhKwasZfB4GQNxsIlrUAUdo,15468
 asone/detectors/yolor/utils/torch_utils.py,sha256=jNQVAq95mtTR4G2bRvAx4hczttGddxKtsY465e3IceI,9396
 asone/detectors/yolor/utils/yolor_utils.py,sha256=ABOlxvZM1JNYBiyI61aglpmfx6e8oQYN4pCG0Op8iOU,9267
 asone/detectors/yolov5/__init__.py,sha256=mVVYSOviSotOMReWcSP7Vq3iZWShB34altKnreF_nK0,72
-asone/detectors/yolov5/yolov5_detector.py,sha256=6AXLzjB7DtCfTZUUDZnStZp-PPGY_ggJxWLieH5yCHc,6323
+asone/detectors/yolov5/yolov5_detector.py,sha256=mdx_HJx0Jp08n9ATw6VD1hcaRzknDQg5k1A9VhLGSo4,6417
 asone/detectors/yolov5/yolov5/__init__.py,sha256=47DEQpj8HBSa-_TImW-5JCeuQeRkm5NMpJWZG3hSuFU,0
 asone/detectors/yolov5/yolov5/models/__init__.py,sha256=TkKpSkpmF4gQOK8yHwCN7-VqQqrNAEFyQHfoe88Labg,64
 asone/detectors/yolov5/yolov5/models/common.py,sha256=_r1B3ylrtS5hcY3ifzUXpRRpxl5bpE6ZeVTLb4nUiQ0,36615
 asone/detectors/yolov5/yolov5/models/experimental.py,sha256=tcQWn9XstiyE22Brmm950pJfgqcq1poO0nnf_-r9oOQ,2340
 asone/detectors/yolov5/yolov5/models/general.py,sha256=31jeYQ-flUCfGY5m9hS_7flMppHIgteOQoxYTFhHlao,42725
 asone/detectors/yolov5/yolov5/models/yolo.py,sha256=g7bU0exAXBU2O76Ov82VfhfeIqHQBN9jknVBviv8qzE,15923
 asone/detectors/yolov5/yolov5/utils/__init__.py,sha256=47DEQpj8HBSa-_TImW-5JCeuQeRkm5NMpJWZG3hSuFU,0
@@ -68,27 +68,27 @@
 asone/detectors/yolov6/yolov6/models/yolo.py,sha256=3yx72C8DlFWwIAOpVXD4Wl5Xe6_kNfIoKA_rooMvLnA,3951
 asone/detectors/yolov6/yolov6/utils/__init__.py,sha256=47DEQpj8HBSa-_TImW-5JCeuQeRkm5NMpJWZG3hSuFU,0
 asone/detectors/yolov6/yolov6/utils/events.py,sha256=CrXv7iKTeK9TPlfdeOsB1S1ZxGxLPy8KScBuB9R-gFw,1880
 asone/detectors/yolov6/yolov6/utils/general.py,sha256=3chdS9R10j2upvSybru0fhTgqO3jVP4Dk6uOdtRGXUM,2674
 asone/detectors/yolov6/yolov6/utils/torch_utils.py,sha256=uL9fUXbCmW1FNkELYHyOWIfuv8aTZP_u0zIvzJGqYx4,3373
 asone/detectors/yolov6/yolov6/utils/yolov6_utils.py,sha256=QArZQ3UEctSjBNR82Koau6kjDsXuGSMmy3kUIWrqDvk,9628
 asone/detectors/yolov7/__init__.py,sha256=Aykqp9f9UfvAQdGoKhoJv0Q_yb8DbxYEJ7TjUvzEE34,72
-asone/detectors/yolov7/yolov7_detector.py,sha256=FwZfdX_0ZghDeQGT0tS0vtIsQwZkGcEnwngrKQ-BExw,4932
+asone/detectors/yolov7/yolov7_detector.py,sha256=b4xz-pr48iw932Wzl4awJF5u-w2vBV_AVXFJhOrcf0E,6904
 asone/detectors/yolov7/yolov7/__init__.py,sha256=47DEQpj8HBSa-_TImW-5JCeuQeRkm5NMpJWZG3hSuFU,0
 asone/detectors/yolov7/yolov7/models/__init__.py,sha256=TkKpSkpmF4gQOK8yHwCN7-VqQqrNAEFyQHfoe88Labg,64
 asone/detectors/yolov7/yolov7/models/common.py,sha256=my6xnnGfHEE6sWlFnt1E_eGUsF5JvXKZu1vx8eC41PU,84188
 asone/detectors/yolov7/yolov7/models/experimental.py,sha256=7wh9oPcJtjP9RfFE5b-2uYohD85-dalCrGYkNRzTYYU,1603
 asone/detectors/yolov7/yolov7/models/yolo.py,sha256=zgs6pklpKOEaWMARPatJ5asTjXSuNinRUgG9sidRKRM,41743
 asone/detectors/yolov7/yolov7/utils/__init__.py,sha256=47DEQpj8HBSa-_TImW-5JCeuQeRkm5NMpJWZG3hSuFU,0
 asone/detectors/yolov7/yolov7/utils/torch_utils.py,sha256=7r4uhQSYmEChWUrNENskL0_ujH-DbEoFQEgoL32eqWw,15467
-asone/detectors/yolov7/yolov7/utils/yolov7_utils.py,sha256=eYl_rx3GOaZtkmDq4HC_ClMD-EmsnXpg13LdXUNZ1_U,8208
+asone/detectors/yolov7/yolov7/utils/yolov7_utils.py,sha256=nI3J_QQJ-r1EoQQ4pxDBCJQROh0if2YUZywam2hS7Xo,8212
 asone/detectors/yolov8/__init__.py,sha256=m1DxmLUVuMjSuiiP7p6VdQnm_3Mggf-eRuHfux0nWGs,72
-asone/detectors/yolov8/yolov8_detector.py,sha256=vnLQ6aawJmc3pe-l2DHrRVFfzjqvR9HIk-ruwkBapU4,4306
+asone/detectors/yolov8/yolov8_detector.py,sha256=EzulARy8olMhRVGivkyZ67dKJjXAsw6BTMFd4TOe7MI,5911
 asone/detectors/yolov8/utils/__init__.py,sha256=47DEQpj8HBSa-_TImW-5JCeuQeRkm5NMpJWZG3hSuFU,0
-asone/detectors/yolov8/utils/yolov8_utils.py,sha256=9zojjbIIBEXQ7AO2j5Uxe8t_UuhFepmxVn1LTsq3Il0,1919
+asone/detectors/yolov8/utils/yolov8_utils.py,sha256=zIwOOi5Rdf8JJMBmDn7vWL12sr9VP-ZJN21ve1FeHqo,2043
 asone/detectors/yolox/__init__.py,sha256=7WgNUuH6D8WFO3-Tq6UBCms5mHbxp-bj-TudcocFdIY,69
 asone/detectors/yolox/yolox_detector.py,sha256=-v9Y_In4rUrSYPHz-FyPvTJ0pFgUsrxGmTi3Ok68VII,6573
 asone/detectors/yolox/yolox_utils.py,sha256=Hnw0iRKDe_rG7ahEjthnmaEm9VAiLtQ06OoR4bqJscA,4277
 asone/detectors/yolox/exps/__init__.py,sha256=G_SRYxMk69Pprvwez5astCZqMghyh56hcN18Fzc2xDA,95
 asone/detectors/yolox/exps/yolov3.py,sha256=g-N5d6-5jWbGQYLARmuK2EbnQUbaFgjxOJjDIgoRF_A,1042
 asone/detectors/yolox/exps/yolox_l.py,sha256=WRMg9fU_5auZ3vUELR7_N7l1gcLkAOpQ8vZSn--3OdU,377
 asone/detectors/yolox/exps/yolox_m.py,sha256=wy3vIOIqZsWt-xXxnowKRbMxkXzjsox1sorAsj3txQ4,379
@@ -168,15 +168,15 @@
 asone/trackers/oc_sort/__init__.py,sha256=EU-t0zNBF2E57vNYM35QzCwx1WwYFG4uyF6teFaPgak,56
 asone/trackers/oc_sort/ocsort.py,sha256=ScsW_PTZxeBO45kJ2f7Ik2UELa451JHs7E5Jux2ulFY,1026
 asone/trackers/oc_sort/tracker/__init__.py,sha256=47DEQpj8HBSa-_TImW-5JCeuQeRkm5NMpJWZG3hSuFU,0
 asone/trackers/oc_sort/tracker/association.py,sha256=3vknTHCcmlZQk4un6buV27uMafM7YQBsiqbqMy5EFaw,14315
 asone/trackers/oc_sort/tracker/kalmanfilter.py,sha256=Yi-2kGHfI84JJdvTtBDHKxuFzqrkB7K1ceByhxG_Ha4,59022
 asone/trackers/oc_sort/tracker/ocsort.py,sha256=7ttqbx8ttNv-kGYR5d9o42xs70Udbr4QDf0mkwfynsQ,13155
 asone/trackers/strong_sort/__init__.py,sha256=47DEQpj8HBSa-_TImW-5JCeuQeRkm5NMpJWZG3hSuFU,0
-asone/trackers/strong_sort/strongsort.py,sha256=Reh0usqTquwyhRs5HUrN8qwX12sgvv82TZvQRBTWuu4,1226
+asone/trackers/strong_sort/strongsort.py,sha256=ykwbv0ppLjp93N3Q61D4yocb_HMbi2RTiAQmnxZRJ3A,1181
 asone/trackers/strong_sort/tracker/__init__.py,sha256=oZ3WSDlcfdFENEvhCycfonxhHyx80aToKCT9LIwIg5Q,510
 asone/trackers/strong_sort/tracker/strong_sort.py,sha256=EGvBPo6ssFo-nJfTQJ5e004Cjt59CLBS35rF4R19nUE,5178
 asone/trackers/strong_sort/tracker/deep/__init__.py,sha256=47DEQpj8HBSa-_TImW-5JCeuQeRkm5NMpJWZG3hSuFU,0
 asone/trackers/strong_sort/tracker/deep/reid_model_factory.py,sha256=kESnMMHCNbjbaTwFXxxSZ4zGSz9QGdxMog-rMqU7nMg,4858
 asone/trackers/strong_sort/tracker/sort/__init__.py,sha256=47DEQpj8HBSa-_TImW-5JCeuQeRkm5NMpJWZG3hSuFU,0
 asone/trackers/strong_sort/tracker/sort/detection.py,sha256=fSKnE9A1MVF1gBYeranhRoqakJYC5zy1lb-E9pftlME,1439
 asone/trackers/strong_sort/tracker/sort/iou_matching.py,sha256=58b5xzmPIFusvzdsgi4Kq3qLGhzXKyppVYTpSwDfGek,2843
@@ -196,17 +196,17 @@
 asone/trackers/strong_sort/tracker/utils/parser.py,sha256=N_Rsu_XjVL07YhmHaHXX8uSKNJ3Ahqy-EUH07ugxmUk,1078
 asone/trackers/strong_sort/tracker/utils/tools.py,sha256=AqR1I_jgJmFMcubeKEGX-fc96AKa-x4EnIM6QA4aSY8,734
 asone/utils/__init__.py,sha256=PEjGp-MJb1dLDaQmqZPZysX_v1w6hvb6NrT0tEVCb5o,430
 asone/utils/classes.py,sha256=ajXF6VM_0K1_9hmgb02zb1_wWM_OV4G-9Z8vtHQSoVY,1066
 asone/utils/colors.py,sha256=wfraLg9ULR0wLTz4UbAh2fkhXrvmRrODDEbbXNqHHIY,697
 asone/utils/counting.py,sha256=PThbapxvLFn6ftbEbV9kxHvWmBuXLglR33-athJa8EQ,558
 asone/utils/default_cfg.py,sha256=UzCAEVMGSLbeqYgmr3y5-F3rgXCVqdB8Hm7nPsOlMhU,358
-asone/utils/download.py,sha256=AiXJsOVKYR1iDFIbXAhyWTAh2H-bYhzYi6aD4Z3txmI,4278
+asone/utils/download.py,sha256=SsnLHvGj5Rba_LMg0y5_UBhtv3nIR7zLf5Ir8PcTqMM,4927
 asone/utils/draw.py,sha256=2Pa4DJ-2DyuF-p3kZBfSpbJTnZGI7ppJnfdC5wP2mRw,4941
 asone/utils/ponits_conversion.py,sha256=rlPuPNplz2WzsIQScS4xRvwxkDKr18WI2kr9HI3W-iY,864
 asone/utils/temp_loader.py,sha256=K8NRezJkFkB_XQbcgkl1-h1pTWRV528ntqMwXuABaCs,796
-asone-0.2.5.dist-info/LICENCE,sha256=ixuiBLtpoK3iv89l7ylKkg9rs2GzF9ukPH7ynZYzK5s,35148
-asone-0.2.5.dist-info/METADATA,sha256=9Q7_lugbL1CTbyZX34A8u-ajP0_fifPHWMvt5wbOemw,12219
-asone-0.2.5.dist-info/WHEEL,sha256=pkctZYzUS4AYVn6dJ-7367OJZivF2e8RA9b_ZBjif18,92
-asone-0.2.5.dist-info/dependency_links.txt,sha256=Yt-SL99DmwySbgxGwJLEZqCU9bLw-mgok8v_E4vqBlE,72
-asone-0.2.5.dist-info/top_level.txt,sha256=n-xJvkjLnGLv_U9fB26iIIWEXbTcOkw2hvrAPeWaPUE,6
-asone-0.2.5.dist-info/RECORD,,
+asone-0.2.6.dist-info/LICENCE,sha256=ixuiBLtpoK3iv89l7ylKkg9rs2GzF9ukPH7ynZYzK5s,35148
+asone-0.2.6.dist-info/METADATA,sha256=3VYQdM-CQUH69b6yhINe3cnlDjmB8b1ezwtdNZgKdDU,12880
+asone-0.2.6.dist-info/WHEEL,sha256=pkctZYzUS4AYVn6dJ-7367OJZivF2e8RA9b_ZBjif18,92
+asone-0.2.6.dist-info/dependency_links.txt,sha256=Yt-SL99DmwySbgxGwJLEZqCU9bLw-mgok8v_E4vqBlE,72
+asone-0.2.6.dist-info/top_level.txt,sha256=n-xJvkjLnGLv_U9fB26iIIWEXbTcOkw2hvrAPeWaPUE,6
+asone-0.2.6.dist-info/RECORD,,
```

